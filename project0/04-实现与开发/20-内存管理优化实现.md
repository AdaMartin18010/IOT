# 内存管理优化实现

## 目录

- [内存管理优化实现](#内存管理优化实现)
  - [目录](#目录)
  - [概述](#概述)
  - [核心实现](#核心实现)
    - [1. 内存池实现](#1-内存池实现)
    - [2. 对象池实现](#2-对象池实现)
    - [3. 内存泄漏检测](#3-内存泄漏检测)
    - [4. 智能指针优化](#4-智能指针优化)
    - [5. 内存压缩和碎片整理](#5-内存压缩和碎片整理)
  - [配置管理](#配置管理)
  - [性能测试](#性能测试)
  - [总结](#总结)

## 概述

IoT系统内存管理优化包含内存池、对象重用、内存泄漏检测、智能指针优化等技术。

## 核心实现

### 1. 内存池实现

```rust
use std::alloc::{alloc, dealloc, Layout};
use std::ptr::{self, NonNull};
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

pub struct MemoryPool {
    block_size: usize,
    blocks_per_chunk: usize,
    free_blocks: VecDeque<NonNull<u8>>,
    chunks: Vec<NonNull<u8>>,
    total_allocated: usize,
    total_freed: usize,
}

impl MemoryPool {
    pub fn new(block_size: usize, blocks_per_chunk: usize) -> Self {
        Self {
            block_size: block_size.max(std::mem::size_of::<usize>()),
            blocks_per_chunk,
            free_blocks: VecDeque::new(),
            chunks: Vec::new(),
            total_allocated: 0,
            total_freed: 0,
        }
    }

    pub fn allocate(&mut self) -> Option<NonNull<u8>> {
        if self.free_blocks.is_empty() {
            self.allocate_new_chunk()?;
        }

        let block = self.free_blocks.pop_front()?;
        self.total_allocated += 1;
        Some(block)
    }

    pub fn deallocate(&mut self, ptr: NonNull<u8>) {
        self.free_blocks.push_back(ptr);
        self.total_freed += 1;
    }

    fn allocate_new_chunk(&mut self) -> Option<()> {
        let chunk_size = self.block_size * self.blocks_per_chunk;
        let layout = Layout::from_size_align(chunk_size, std::mem::align_of::<u8>()).ok()?;
        
        let chunk_ptr = unsafe { alloc(layout) };
        if chunk_ptr.is_null() {
            return None;
        }

        let chunk = NonNull::new(chunk_ptr)?;
        self.chunks.push(chunk);

        // 将chunk分割为blocks并添加到free_blocks
        for i in 0..self.blocks_per_chunk {
            let block_ptr = unsafe { chunk_ptr.add(i * self.block_size) };
            self.free_blocks.push_back(NonNull::new(block_ptr)?);
        }

        Some(())
    }

    pub fn get_stats(&self) -> MemoryPoolStats {
        MemoryPoolStats {
            total_allocated: self.total_allocated,
            total_freed: self.total_freed,
            active_blocks: self.total_allocated - self.total_freed,
            free_blocks: self.free_blocks.len(),
            total_chunks: self.chunks.len(),
            chunk_utilization: if self.chunks.is_empty() {
                0.0
            } else {
                (self.total_allocated - self.total_freed) as f64 / 
                (self.chunks.len() * self.blocks_per_chunk) as f64
            },
        }
    }
}

impl Drop for MemoryPool {
    fn drop(&mut self) {
        for chunk in &self.chunks {
            let chunk_size = self.block_size * self.blocks_per_chunk;
            let layout = Layout::from_size_align(chunk_size, std::mem::align_of::<u8>()).unwrap();
            unsafe {
                dealloc(chunk.as_ptr(), layout);
            }
        }
    }
}

#[derive(Debug, Clone)]
pub struct MemoryPoolStats {
    pub total_allocated: usize,
    pub total_freed: usize,
    pub active_blocks: usize,
    pub free_blocks: usize,
    pub total_chunks: usize,
    pub chunk_utilization: f64,
}

// 线程安全的内存池
pub struct ThreadSafeMemoryPool {
    inner: Arc<Mutex<MemoryPool>>,
}

impl ThreadSafeMemoryPool {
    pub fn new(block_size: usize, blocks_per_chunk: usize) -> Self {
        Self {
            inner: Arc::new(Mutex::new(MemoryPool::new(block_size, blocks_per_chunk))),
        }
    }

    pub fn allocate(&self) -> Option<NonNull<u8>> {
        self.inner.lock().unwrap().allocate()
    }

    pub fn deallocate(&self, ptr: NonNull<u8>) {
        self.inner.lock().unwrap().deallocate(ptr);
    }

    pub fn get_stats(&self) -> MemoryPoolStats {
        self.inner.lock().unwrap().get_stats()
    }
}

unsafe impl Send for ThreadSafeMemoryPool {}
unsafe impl Sync for ThreadSafeMemoryPool {}
```

### 2. 对象池实现

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

pub trait Poolable: Default {
    fn reset(&mut self);
}

pub struct ObjectPool<T> {
    objects: Arc<Mutex<VecDeque<T>>>,
    factory: Arc<dyn Fn() -> T + Send + Sync>,
    max_size: usize,
    reset_on_return: bool,
}

impl<T> ObjectPool<T> 
where 
    T: Poolable + Send + 'static,
{
    pub fn new(max_size: usize, factory: impl Fn() -> T + Send + Sync + 'static) -> Self {
        Self {
            objects: Arc::new(Mutex::new(VecDeque::new())),
            factory: Arc::new(factory),
            max_size,
            reset_on_return: true,
        }
    }

    pub fn get(&self) -> PooledObject<T> {
        let mut objects = self.objects.lock().unwrap();
        let object = objects.pop_front().unwrap_or_else(|| (self.factory)());
        drop(objects);

        PooledObject {
            object: Some(object),
            pool: Arc::clone(&self.objects),
            reset_on_return: self.reset_on_return,
        }
    }

    pub fn size(&self) -> usize {
        self.objects.lock().unwrap().len()
    }

    pub fn shrink_to_fit(&self) {
        self.objects.lock().unwrap().shrink_to_fit();
    }
}

pub struct PooledObject<T> {
    object: Option<T>,
    pool: Arc<Mutex<VecDeque<T>>>,
    reset_on_return: bool,
}

impl<T> PooledObject<T> {
    pub fn take(mut self) -> T {
        self.object.take().unwrap()
    }
}

impl<T> std::ops::Deref for PooledObject<T> {
    type Target = T;

    fn deref(&self) -> &Self::Target {
        self.object.as_ref().unwrap()
    }
}

impl<T> std::ops::DerefMut for PooledObject<T> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.object.as_mut().unwrap()
    }
}

impl<T> Drop for PooledObject<T> 
where 
    T: Poolable,
{
    fn drop(&mut self) {
        if let Some(mut object) = self.object.take() {
            if self.reset_on_return {
                object.reset();
            }

            let mut pool = self.pool.lock().unwrap();
            pool.push_back(object);
        }
    }
}

// 示例：ByteBuffer对象池
#[derive(Default)]
pub struct ByteBuffer {
    data: Vec<u8>,
}

impl ByteBuffer {
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            data: Vec::with_capacity(capacity),
        }
    }

    pub fn write(&mut self, data: &[u8]) {
        self.data.extend_from_slice(data);
    }

    pub fn read(&self) -> &[u8] {
        &self.data
    }

    pub fn len(&self) -> usize {
        self.data.len()
    }

    pub fn capacity(&self) -> usize {
        self.data.capacity()
    }
}

impl Poolable for ByteBuffer {
    fn reset(&mut self) {
        self.data.clear();
    }
}

pub type ByteBufferPool = ObjectPool<ByteBuffer>;

impl ByteBufferPool {
    pub fn new_with_capacity(max_size: usize, buffer_capacity: usize) -> Self {
        Self::new(max_size, move || ByteBuffer::with_capacity(buffer_capacity))
    }
}
```

### 3. 内存泄漏检测

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex, Weak};
use std::thread::ThreadId;
use std::time::Instant;

#[derive(Debug, Clone)]
pub struct AllocationInfo {
    pub size: usize,
    pub timestamp: Instant,
    pub thread_id: ThreadId,
    pub stack_trace: Vec<String>,
}

pub struct MemoryTracker {
    allocations: Arc<Mutex<HashMap<usize, AllocationInfo>>>,
    total_allocated: Arc<std::sync::atomic::AtomicUsize>,
    total_freed: Arc<std::sync::atomic::AtomicUsize>,
    enabled: bool,
}

impl MemoryTracker {
    pub fn new() -> Self {
        Self {
            allocations: Arc::new(Mutex::new(HashMap::new())),
            total_allocated: Arc::new(std::sync::atomic::AtomicUsize::new(0)),
            total_freed: Arc::new(std::sync::atomic::AtomicUsize::new(0)),
            enabled: true,
        }
    }

    pub fn track_allocation(&self, ptr: usize, size: usize) {
        if !self.enabled {
            return;
        }

        let info = AllocationInfo {
            size,
            timestamp: Instant::now(),
            thread_id: std::thread::current().id(),
            stack_trace: self.capture_stack_trace(),
        };

        let mut allocations = self.allocations.lock().unwrap();
        allocations.insert(ptr, info);
        
        self.total_allocated.fetch_add(size, std::sync::atomic::Ordering::Relaxed);
    }

    pub fn track_deallocation(&self, ptr: usize) {
        if !self.enabled {
            return;
        }

        let mut allocations = self.allocations.lock().unwrap();
        if let Some(info) = allocations.remove(&ptr) {
            self.total_freed.fetch_add(info.size, std::sync::atomic::Ordering::Relaxed);
        }
    }

    pub fn get_memory_stats(&self) -> MemoryStats {
        let allocations = self.allocations.lock().unwrap();
        let total_allocated = self.total_allocated.load(std::sync::atomic::Ordering::Relaxed);
        let total_freed = self.total_freed.load(std::sync::atomic::Ordering::Relaxed);
        
        let active_allocations = allocations.len();
        let active_memory = allocations.values().map(|info| info.size).sum();

        MemoryStats {
            total_allocated,
            total_freed,
            current_allocated: total_allocated - total_freed,
            active_allocations,
            active_memory,
            fragmentation_ratio: self.calculate_fragmentation(&allocations),
        }
    }

    pub fn detect_leaks(&self, threshold_seconds: u64) -> Vec<MemoryLeak> {
        let allocations = self.allocations.lock().unwrap();
        let now = Instant::now();
        let threshold = std::time::Duration::from_secs(threshold_seconds);

        allocations
            .iter()
            .filter(|(_, info)| now.duration_since(info.timestamp) > threshold)
            .map(|(&ptr, info)| MemoryLeak {
                ptr,
                size: info.size,
                age: now.duration_since(info.timestamp),
                thread_id: info.thread_id,
                stack_trace: info.stack_trace.clone(),
            })
            .collect()
    }

    fn capture_stack_trace(&self) -> Vec<String> {
        // 简化实现，实际可以使用backtrace crate
        vec!["frame1".to_string(), "frame2".to_string()]
    }

    fn calculate_fragmentation(&self, allocations: &HashMap<usize, AllocationInfo>) -> f64 {
        if allocations.is_empty() {
            return 0.0;
        }

        let mut sizes: Vec<usize> = allocations.values().map(|info| info.size).collect();
        sizes.sort();

        let total_size: usize = sizes.iter().sum();
        let avg_size = total_size as f64 / sizes.len() as f64;
        
        let variance: f64 = sizes.iter()
            .map(|&size| (size as f64 - avg_size).powi(2))
            .sum::<f64>() / sizes.len() as f64;

        variance.sqrt() / avg_size
    }

    pub fn set_enabled(&mut self, enabled: bool) {
        self.enabled = enabled;
    }
}

#[derive(Debug, Clone)]
pub struct MemoryStats {
    pub total_allocated: usize,
    pub total_freed: usize,
    pub current_allocated: usize,
    pub active_allocations: usize,
    pub active_memory: usize,
    pub fragmentation_ratio: f64,
}

#[derive(Debug, Clone)]
pub struct MemoryLeak {
    pub ptr: usize,
    pub size: usize,
    pub age: std::time::Duration,
    pub thread_id: ThreadId,
    pub stack_trace: Vec<String>,
}

// 全局内存追踪器
lazy_static::lazy_static! {
    static ref GLOBAL_MEMORY_TRACKER: MemoryTracker = MemoryTracker::new();
}

pub fn track_allocation(ptr: usize, size: usize) {
    GLOBAL_MEMORY_TRACKER.track_allocation(ptr, size);
}

pub fn track_deallocation(ptr: usize) {
    GLOBAL_MEMORY_TRACKER.track_deallocation(ptr);
}

pub fn get_memory_stats() -> MemoryStats {
    GLOBAL_MEMORY_TRACKER.get_memory_stats()
}

pub fn detect_memory_leaks(threshold_seconds: u64) -> Vec<MemoryLeak> {
    GLOBAL_MEMORY_TRACKER.detect_leaks(threshold_seconds)
}
```

### 4. 智能指针优化

```rust
use std::sync::{Arc, Weak};
use std::cell::RefCell;
use std::rc::Rc;

// 引用计数池
pub struct RcPool<T> {
    objects: RefCell<Vec<Rc<RefCell<T>>>>,
    factory: Box<dyn Fn() -> T>,
}

impl<T> RcPool<T> {
    pub fn new<F>(factory: F) -> Self 
    where 
        F: Fn() -> T + 'static,
    {
        Self {
            objects: RefCell::new(Vec::new()),
            factory: Box::new(factory),
        }
    }

    pub fn get(&self) -> Rc<RefCell<T>> {
        let mut objects = self.objects.borrow_mut();
        
        // 查找可重用的对象
        for i in (0..objects.len()).rev() {
            if Rc::strong_count(&objects[i]) == 1 {
                return objects.swap_remove(i);
            }
        }

        // 创建新对象
        Rc::new(RefCell::new((self.factory)()))
    }

    pub fn return_object(&self, obj: Rc<RefCell<T>>) {
        if Rc::strong_count(&obj) == 1 {
            let mut objects = self.objects.borrow_mut();
            objects.push(obj);
        }
    }

    pub fn len(&self) -> usize {
        self.objects.borrow().len()
    }

    pub fn clear(&self) {
        self.objects.borrow_mut().clear();
    }
}

// 弱引用缓存
pub struct WeakCache<K, V> {
    cache: RefCell<HashMap<K, Weak<V>>>,
}

impl<K, V> WeakCache<K, V> 
where 
    K: std::hash::Hash + Eq + Clone,
{
    pub fn new() -> Self {
        Self {
            cache: RefCell::new(HashMap::new()),
        }
    }

    pub fn get(&self, key: &K) -> Option<Arc<V>> {
        let mut cache = self.cache.borrow_mut();
        
        if let Some(weak_ref) = cache.get(key) {
            if let Some(strong_ref) = weak_ref.upgrade() {
                return Some(strong_ref);
            } else {
                // 弱引用已失效，移除
                cache.remove(key);
            }
        }
        
        None
    }

    pub fn insert(&self, key: K, value: Arc<V>) {
        let weak_ref = Arc::downgrade(&value);
        let mut cache = self.cache.borrow_mut();
        cache.insert(key, weak_ref);
    }

    pub fn cleanup(&self) {
        let mut cache = self.cache.borrow_mut();
        cache.retain(|_, weak_ref| weak_ref.strong_count() > 0);
    }

    pub fn len(&self) -> usize {
        self.cache.borrow().len()
    }
}

// 自动清理的Arc包装器
pub struct ManagedArc<T> {
    inner: Arc<T>,
    cleanup_callback: Option<Box<dyn Fn() + Send + Sync>>,
}

impl<T> ManagedArc<T> {
    pub fn new(value: T) -> Self {
        Self {
            inner: Arc::new(value),
            cleanup_callback: None,
        }
    }

    pub fn with_cleanup<F>(value: T, cleanup: F) -> Self 
    where 
        F: Fn() + Send + Sync + 'static,
    {
        Self {
            inner: Arc::new(value),
            cleanup_callback: Some(Box::new(cleanup)),
        }
    }

    pub fn clone(&self) -> Self {
        Self {
            inner: Arc::clone(&self.inner),
            cleanup_callback: self.cleanup_callback.as_ref().map(|cb| cb.as_ref().into()),
        }
    }

    pub fn strong_count(&self) -> usize {
        Arc::strong_count(&self.inner)
    }

    pub fn weak_count(&self) -> usize {
        Arc::weak_count(&self.inner)
    }
}

impl<T> std::ops::Deref for ManagedArc<T> {
    type Target = T;

    fn deref(&self) -> &Self::Target {
        &self.inner
    }
}

impl<T> Drop for ManagedArc<T> {
    fn drop(&mut self) {
        if Arc::strong_count(&self.inner) == 1 {
            if let Some(cleanup) = &self.cleanup_callback {
                cleanup();
            }
        }
    }
}
```

### 5. 内存压缩和碎片整理

```rust
use std::collections::BTreeMap;

pub struct MemoryCompactor {
    regions: BTreeMap<usize, MemoryRegion>,
    free_blocks: Vec<FreeBlock>,
    total_size: usize,
    fragmentation_threshold: f64,
}

#[derive(Debug, Clone)]
pub struct MemoryRegion {
    pub start: usize,
    pub size: usize,
    pub used: bool,
    pub data: Option<Vec<u8>>,
}

#[derive(Debug, Clone)]
pub struct FreeBlock {
    pub start: usize,
    pub size: usize,
}

impl MemoryCompactor {
    pub fn new(total_size: usize, fragmentation_threshold: f64) -> Self {
        let mut regions = BTreeMap::new();
        regions.insert(0, MemoryRegion {
            start: 0,
            size: total_size,
            used: false,
            data: None,
        });

        Self {
            regions,
            free_blocks: vec![FreeBlock { start: 0, size: total_size }],
            total_size,
            fragmentation_threshold,
        }
    }

    pub fn allocate(&mut self, size: usize) -> Option<usize> {
        // 查找合适的空闲块
        if let Some(block_index) = self.find_free_block(size) {
            let block = self.free_blocks.remove(block_index);
            
            // 创建新的已使用区域
            let region = MemoryRegion {
                start: block.start,
                size,
                used: true,
                data: Some(vec![0; size]),
            };
            
            self.regions.insert(block.start, region);

            // 如果有剩余空间，创建新的空闲块
            if block.size > size {
                let remaining = FreeBlock {
                    start: block.start + size,
                    size: block.size - size,
                };
                self.free_blocks.push(remaining);
                self.free_blocks.sort_by_key(|b| b.start);
            }

            Some(block.start)
        } else {
            // 尝试压缩内存
            if self.should_compact() {
                self.compact();
                self.allocate(size)
            } else {
                None
            }
        }
    }

    pub fn deallocate(&mut self, addr: usize) -> bool {
        if let Some(region) = self.regions.remove(&addr) {
            if !region.used {
                return false;
            }

            // 添加到空闲块列表
            let free_block = FreeBlock {
                start: region.start,
                size: region.size,
            };

            self.free_blocks.push(free_block);
            self.merge_free_blocks();
            true
        } else {
            false
        }
    }

    fn find_free_block(&self, size: usize) -> Option<usize> {
        self.free_blocks
            .iter()
            .position(|block| block.size >= size)
    }

    fn should_compact(&self) -> bool {
        let fragmentation = self.calculate_fragmentation();
        fragmentation > self.fragmentation_threshold
    }

    fn calculate_fragmentation(&self) -> f64 {
        if self.free_blocks.is_empty() {
            return 0.0;
        }

        let total_free: usize = self.free_blocks.iter().map(|b| b.size).sum();
        let largest_free = self.free_blocks.iter().map(|b| b.size).max().unwrap_or(0);

        if total_free == 0 {
            0.0
        } else {
            1.0 - (largest_free as f64 / total_free as f64)
        }
    }

    fn compact(&mut self) {
        let mut used_regions: Vec<_> = self.regions
            .values()
            .filter(|r| r.used)
            .cloned()
            .collect();

        used_regions.sort_by_key(|r| r.start);

        // 清空当前区域和空闲块
        self.regions.clear();
        self.free_blocks.clear();

        let mut current_pos = 0;

        // 重新放置已使用的区域
        for region in used_regions {
            let new_region = MemoryRegion {
                start: current_pos,
                size: region.size,
                used: true,
                data: region.data,
            };

            self.regions.insert(current_pos, new_region);
            current_pos += region.size;
        }

        // 创建单个大的空闲块
        if current_pos < self.total_size {
            self.free_blocks.push(FreeBlock {
                start: current_pos,
                size: self.total_size - current_pos,
            });
        }
    }

    fn merge_free_blocks(&mut self) {
        self.free_blocks.sort_by_key(|b| b.start);

        let mut merged = Vec::new();
        let mut current: Option<FreeBlock> = None;

        for block in &self.free_blocks {
            match current {
                None => current = Some(block.clone()),
                Some(ref mut curr) => {
                    if curr.start + curr.size == block.start {
                        // 合并相邻的块
                        curr.size += block.size;
                    } else {
                        merged.push(curr.clone());
                        current = Some(block.clone());
                    }
                }
            }
        }

        if let Some(last) = current {
            merged.push(last);
        }

        self.free_blocks = merged;
    }

    pub fn get_memory_info(&self) -> MemoryCompactorInfo {
        let used_memory: usize = self.regions.values()
            .filter(|r| r.used)
            .map(|r| r.size)
            .sum();

        let free_memory: usize = self.free_blocks.iter().map(|b| b.size).sum();

        MemoryCompactorInfo {
            total_size: self.total_size,
            used_memory,
            free_memory,
            fragmentation: self.calculate_fragmentation(),
            used_regions: self.regions.values().filter(|r| r.used).count(),
            free_blocks: self.free_blocks.len(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct MemoryCompactorInfo {
    pub total_size: usize,
    pub used_memory: usize,
    pub free_memory: usize,
    pub fragmentation: f64,
    pub used_regions: usize,
    pub free_blocks: usize,
}
```

## 配置管理

```toml
[memory]
pool_enabled = true
leak_detection_enabled = true
compaction_enabled = true

[memory_pool]
default_block_size = 1024
blocks_per_chunk = 256
max_chunks = 100

[object_pool]
max_objects = 1000
reset_on_return = true
auto_shrink = true

[leak_detection]
tracking_enabled = true
threshold_seconds = 300
max_tracked_allocations = 10000

[compaction]
fragmentation_threshold = 0.3
auto_compact = true
compact_interval_seconds = 60
```

## 性能测试

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_memory_pool_performance() {
        let mut pool = MemoryPool::new(1024, 100);
        
        let start = std::time::Instant::now();
        
        let mut ptrs = Vec::new();
        for _ in 0..1000 {
            if let Some(ptr) = pool.allocate() {
                ptrs.push(ptr);
            }
        }
        
        for ptr in ptrs {
            pool.deallocate(ptr);
        }
        
        let duration = start.elapsed();
        println!("Memory pool operations took: {:?}", duration);
        
        let stats = pool.get_stats();
        assert_eq!(stats.active_blocks, 0);
    }

    #[test]
    fn test_object_pool() {
        let pool = ByteBufferPool::new_with_capacity(10, 1024);
        
        let mut buffer = pool.get();
        buffer.write(b"Hello, World!");
        assert_eq!(buffer.len(), 13);
        
        drop(buffer);
        assert_eq!(pool.size(), 1);
    }

    #[test]
    fn test_memory_compactor() {
        let mut compactor = MemoryCompactor::new(1024, 0.3);
        
        let ptr1 = compactor.allocate(100).unwrap();
        let ptr2 = compactor.allocate(200).unwrap();
        let ptr3 = compactor.allocate(150).unwrap();
        
        compactor.deallocate(ptr2);
        
        let info = compactor.get_memory_info();
        assert!(info.fragmentation > 0.0);
    }
}
```

## 总结

本内存管理优化实现提供了：

- 高效的内存池和对象池
- 全面的内存泄漏检测
- 智能指针优化和弱引用缓存
- 内存压缩和碎片整理
- 完整的性能监控和统计
