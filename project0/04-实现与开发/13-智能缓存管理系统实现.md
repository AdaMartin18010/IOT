# 智能缓存管理系统实现

## 1. 概述

本文档实现智能缓存管理系统，支持多级缓存、智能预取和自适应失效策略。

## 2. 缓存接口定义

```rust
use std::time::Duration;
use serde::{Serialize, Deserialize};

#[async_trait::async_trait]
pub trait Cache<K, V>: Send + Sync
where
    K: Clone + Send + Sync,
    V: Clone + Send + Sync,
{
    type Error: std::error::Error + Send + Sync;
    
    async fn get(&self, key: &K) -> Result<Option<V>, Self::Error>;
    async fn set(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), Self::Error>;
    async fn delete(&self, key: &K) -> Result<bool, Self::Error>;
    async fn exists(&self, key: &K) -> Result<bool, Self::Error>;
    async fn clear(&self) -> Result<(), Self::Error>;
    
    fn get_cache_type(&self) -> CacheType;
    fn get_stats(&self) -> CacheStats;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CacheType {
    Memory,
    Redis,
    Disk,
    Hybrid,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheStats {
    pub hits: u64,
    pub misses: u64,
    pub evictions: u64,
    pub size: usize,
    pub capacity: usize,
    pub hit_rate: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheEntry<V> {
    pub value: V,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub expires_at: Option<chrono::DateTime<chrono::Utc>>,
    pub access_count: u64,
    pub last_accessed: chrono::DateTime<chrono::Utc>,
}
```

## 3. 多级缓存管理器

```rust
use std::sync::Arc;
use dashmap::DashMap;

pub struct MultiLevelCacheManager {
    levels: Vec<CacheLevel>,
    strategy: CacheStrategy,
    metrics: CacheMetrics,
    prefetch_engine: PrefetchEngine,
}

#[derive(Debug, Clone)]
pub struct CacheLevel {
    pub level: u8,
    pub cache: Arc<dyn Cache<String, serde_json::Value>>,
    pub promotion_threshold: u64,
    pub demotion_threshold: u64,
}

#[derive(Debug, Clone)]
pub enum CacheStrategy {
    WriteThrough,
    WriteBack,
    WriteAround,
}

impl MultiLevelCacheManager {
    pub fn new(strategy: CacheStrategy) -> Self {
        Self {
            levels: Vec::new(),
            strategy,
            metrics: CacheMetrics::new(),
            prefetch_engine: PrefetchEngine::new(),
        }
    }
    
    pub fn add_cache_level(&mut self, level: CacheLevel) {
        self.levels.push(level);
        self.levels.sort_by_key(|l| l.level);
    }
    
    pub async fn get(&self, key: &str) -> Result<Option<serde_json::Value>, CacheError> {
        let start_time = std::time::Instant::now();
        
        for (index, level) in self.levels.iter().enumerate() {
            match level.cache.get(&key.to_string()).await {
                Ok(Some(value)) => {
                    // 缓存命中
                    self.metrics.record_hit(level.level).await;
                    
                    // 检查是否需要提升到更高级缓存
                    if index > 0 {
                        self.promote_to_higher_level(key, &value, index - 1).await?;
                    }
                    
                    // 触发预取
                    self.prefetch_engine.trigger_prefetch(key, &value).await;
                    
                    let duration = start_time.elapsed();
                    self.metrics.record_access_time(level.level, duration).await;
                    
                    return Ok(Some(value));
                }
                Ok(None) => {
                    // 缓存未命中，继续查找下一级
                    self.metrics.record_miss(level.level).await;
                }
                Err(e) => {
                    eprintln!("Cache level {} error: {:?}", level.level, e);
                }
            }
        }
        
        // 所有级别都未命中
        Ok(None)
    }
    
    pub async fn set(&self, key: String, value: serde_json::Value, ttl: Option<Duration>) -> Result<(), CacheError> {
        match self.strategy {
            CacheStrategy::WriteThrough => {
                self.write_through(key, value, ttl).await
            }
            CacheStrategy::WriteBack => {
                self.write_back(key, value, ttl).await
            }
            CacheStrategy::WriteAround => {
                self.write_around(key, value, ttl).await
            }
        }
    }
    
    async fn write_through(&self, key: String, value: serde_json::Value, ttl: Option<Duration>) -> Result<(), CacheError> {
        // 写入所有级别
        for level in &self.levels {
            if let Err(e) = level.cache.set(key.clone(), value.clone(), ttl).await {
                eprintln!("Failed to write to cache level {}: {:?}", level.level, e);
            }
        }
        Ok(())
    }
    
    async fn write_back(&self, key: String, value: serde_json::Value, ttl: Option<Duration>) -> Result<(), CacheError> {
        // 只写入最高级缓存，标记为脏数据
        if let Some(level) = self.levels.first() {
            level.cache.set(key, value, ttl).await
                .map_err(|e| CacheError::WriteError(e.to_string()))?;
        }
        Ok(())
    }
    
    async fn write_around(&self, key: String, value: serde_json::Value, ttl: Option<Duration>) -> Result<(), CacheError> {
        // 跳过缓存，直接写入后端存储
        if let Some(level) = self.levels.last() {
            level.cache.set(key, value, ttl).await
                .map_err(|e| CacheError::WriteError(e.to_string()))?;
        }
        Ok(())
    }
    
    async fn promote_to_higher_level(&self, key: &str, value: &serde_json::Value, target_level_index: usize) -> Result<(), CacheError> {
        if let Some(target_level) = self.levels.get(target_level_index) {
            target_level.cache.set(key.to_string(), value.clone(), None).await
                .map_err(|e| CacheError::PromotionError(e.to_string()))?;
        }
        Ok(())
    }
    
    pub async fn delete(&self, key: &str) -> Result<(), CacheError> {
        for level in &self.levels {
            if let Err(e) = level.cache.delete(&key.to_string()).await {
                eprintln!("Failed to delete from cache level {}: {:?}", level.level, e);
            }
        }
        Ok(())
    }
    
    pub async fn invalidate_pattern(&self, pattern: &str) -> Result<u64, CacheError> {
        let mut total_invalidated = 0;
        
        for level in &self.levels {
            // 这里需要具体的缓存实现支持模式匹配
            // total_invalidated += level.cache.delete_pattern(pattern).await?;
        }
        
        Ok(total_invalidated)
    }
}

#[derive(Debug)]
pub enum CacheError {
    NotFound,
    WriteError(String),
    ReadError(String),
    PromotionError(String),
    EvictionError(String),
    ConfigurationError(String),
}
```

## 4. 内存缓存实现

```rust
use std::sync::RwLock;
use std::collections::HashMap;

pub struct MemoryCache<K, V> {
    storage: Arc<RwLock<HashMap<K, CacheEntry<V>>>>,
    config: MemoryCacheConfig,
    stats: Arc<RwLock<CacheStats>>,
    eviction_policy: EvictionPolicy,
}

#[derive(Debug, Clone)]
pub struct MemoryCacheConfig {
    pub max_capacity: usize,
    pub default_ttl: Duration,
    pub cleanup_interval: Duration,
}

#[derive(Debug, Clone)]
pub enum EvictionPolicy {
    LRU,
    LFU,
    FIFO,
    TTL,
    Random,
}

impl<K, V> MemoryCache<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync,
    V: Clone + Send + Sync,
{
    pub fn new(config: MemoryCacheConfig, eviction_policy: EvictionPolicy) -> Self {
        let cache = Self {
            storage: Arc::new(RwLock::new(HashMap::new())),
            config,
            stats: Arc::new(RwLock::new(CacheStats::default())),
            eviction_policy,
        };
        
        // 启动清理任务
        cache.start_cleanup_task();
        
        cache
    }
    
    fn start_cleanup_task(&self) {
        let storage = self.storage.clone();
        let interval = self.config.cleanup_interval;
        
        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);
            
            loop {
                interval_timer.tick().await;
                Self::cleanup_expired_entries(&storage).await;
            }
        });
    }
    
    async fn cleanup_expired_entries(storage: &Arc<RwLock<HashMap<K, CacheEntry<V>>>>) {
        let now = chrono::Utc::now();
        let mut write_guard = storage.write().unwrap();
        
        write_guard.retain(|_, entry| {
            if let Some(expires_at) = entry.expires_at {
                expires_at > now
            } else {
                true
            }
        });
    }
    
    fn should_evict(&self) -> bool {
        let storage = self.storage.read().unwrap();
        storage.len() >= self.config.max_capacity
    }
    
    fn evict_entries(&self) -> Result<(), CacheError> {
        let mut storage = self.storage.write().unwrap();
        
        if storage.is_empty() {
            return Ok(());
        }
        
        match self.eviction_policy {
            EvictionPolicy::LRU => {
                // 找到最近最少使用的条目
                if let Some((key_to_remove, _)) = storage.iter()
                    .min_by_key(|(_, entry)| entry.last_accessed) {
                    let key_to_remove = key_to_remove.clone();
                    storage.remove(&key_to_remove);
                }
            }
            EvictionPolicy::LFU => {
                // 找到最少使用的条目
                if let Some((key_to_remove, _)) = storage.iter()
                    .min_by_key(|(_, entry)| entry.access_count) {
                    let key_to_remove = key_to_remove.clone();
                    storage.remove(&key_to_remove);
                }
            }
            EvictionPolicy::FIFO => {
                // 找到最早创建的条目
                if let Some((key_to_remove, _)) = storage.iter()
                    .min_by_key(|(_, entry)| entry.created_at) {
                    let key_to_remove = key_to_remove.clone();
                    storage.remove(&key_to_remove);
                }
            }
            EvictionPolicy::TTL => {
                // 找到最早过期的条目
                if let Some((key_to_remove, _)) = storage.iter()
                    .filter(|(_, entry)| entry.expires_at.is_some())
                    .min_by_key(|(_, entry)| entry.expires_at.unwrap()) {
                    let key_to_remove = key_to_remove.clone();
                    storage.remove(&key_to_remove);
                }
            }
            EvictionPolicy::Random => {
                // 随机选择一个条目
                use rand::seq::IteratorRandom;
                let mut rng = rand::thread_rng();
                if let Some((key_to_remove, _)) = storage.iter().choose(&mut rng) {
                    let key_to_remove = key_to_remove.clone();
                    storage.remove(&key_to_remove);
                }
            }
        }
        
        Ok(())
    }
    
    fn update_stats_on_hit(&self) {
        let mut stats = self.stats.write().unwrap();
        stats.hits += 1;
        stats.hit_rate = stats.hits as f64 / (stats.hits + stats.misses) as f64;
    }
    
    fn update_stats_on_miss(&self) {
        let mut stats = self.stats.write().unwrap();
        stats.misses += 1;
        stats.hit_rate = stats.hits as f64 / (stats.hits + stats.misses) as f64;
    }
}

#[async_trait::async_trait]
impl<K, V> Cache<K, V> for MemoryCache<K, V>
where
    K: Clone + Eq + std::hash::Hash + Send + Sync,
    V: Clone + Send + Sync,
{
    type Error = CacheError;
    
    async fn get(&self, key: &K) -> Result<Option<V>, Self::Error> {
        let now = chrono::Utc::now();
        let mut storage = self.storage.write().unwrap();
        
        if let Some(entry) = storage.get_mut(key) {
            // 检查是否过期
            if let Some(expires_at) = entry.expires_at {
                if now > expires_at {
                    storage.remove(key);
                    self.update_stats_on_miss();
                    return Ok(None);
                }
            }
            
            // 更新访问信息
            entry.access_count += 1;
            entry.last_accessed = now;
            
            self.update_stats_on_hit();
            Ok(Some(entry.value.clone()))
        } else {
            self.update_stats_on_miss();
            Ok(None)
        }
    }
    
    async fn set(&self, key: K, value: V, ttl: Option<Duration>) -> Result<(), Self::Error> {
        // 检查是否需要驱逐
        if self.should_evict() {
            self.evict_entries()?;
        }
        
        let now = chrono::Utc::now();
        let expires_at = ttl.map(|duration| now + chrono::Duration::from_std(duration).unwrap());
        
        let entry = CacheEntry {
            value,
            created_at: now,
            expires_at,
            access_count: 0,
            last_accessed: now,
        };
        
        let mut storage = self.storage.write().unwrap();
        storage.insert(key, entry);
        
        // 更新统计信息
        let mut stats = self.stats.write().unwrap();
        stats.size = storage.len();
        
        Ok(())
    }
    
    async fn delete(&self, key: &K) -> Result<bool, Self::Error> {
        let mut storage = self.storage.write().unwrap();
        let removed = storage.remove(key).is_some();
        
        if removed {
            let mut stats = self.stats.write().unwrap();
            stats.size = storage.len();
        }
        
        Ok(removed)
    }
    
    async fn exists(&self, key: &K) -> Result<bool, Self::Error> {
        let storage = self.storage.read().unwrap();
        let now = chrono::Utc::now();
        
        if let Some(entry) = storage.get(key) {
            // 检查是否过期
            if let Some(expires_at) = entry.expires_at {
                Ok(now <= expires_at)
            } else {
                Ok(true)
            }
        } else {
            Ok(false)
        }
    }
    
    async fn clear(&self) -> Result<(), Self::Error> {
        let mut storage = self.storage.write().unwrap();
        storage.clear();
        
        let mut stats = self.stats.write().unwrap();
        stats.size = 0;
        
        Ok(())
    }
    
    fn get_cache_type(&self) -> CacheType {
        CacheType::Memory
    }
    
    fn get_stats(&self) -> CacheStats {
        self.stats.read().unwrap().clone()
    }
}

impl Default for CacheStats {
    fn default() -> Self {
        Self {
            hits: 0,
            misses: 0,
            evictions: 0,
            size: 0,
            capacity: 1000,
            hit_rate: 0.0,
        }
    }
}
```

## 5. 预取引擎

```rust
pub struct PrefetchEngine {
    patterns: Arc<RwLock<Vec<PrefetchPattern>>>,
    access_history: AccessHistory,
    ml_predictor: MLPredictor,
}

#[derive(Debug, Clone)]
pub struct PrefetchPattern {
    pub pattern_id: String,
    pub key_pattern: String,
    pub confidence: f64,
    pub success_rate: f64,
    pub last_used: chrono::DateTime<chrono::Utc>,
}

impl PrefetchEngine {
    pub fn new() -> Self {
        Self {
            patterns: Arc::new(RwLock::new(Vec::new())),
            access_history: AccessHistory::new(),
            ml_predictor: MLPredictor::new(),
        }
    }
    
    pub async fn trigger_prefetch(&self, accessed_key: &str, _value: &serde_json::Value) {
        // 记录访问历史
        self.access_history.record_access(accessed_key).await;
        
        // 使用机器学习预测下一个可能访问的键
        let predicted_keys = self.ml_predictor.predict_next_keys(accessed_key).await;
        
        // 触发预取任务
        for predicted_key in predicted_keys {
            self.schedule_prefetch(predicted_key).await;
        }
        
        // 更新预取模式
        self.update_patterns(accessed_key).await;
    }
    
    async fn schedule_prefetch(&self, key: String) {
        tokio::spawn(async move {
            // 这里实现具体的预取逻辑
            println!("Prefetching key: {}", key);
            // 实际实现中会从数据源加载数据并存入缓存
        });
    }
    
    async fn update_patterns(&self, accessed_key: &str) {
        // 分析访问模式并更新预取规则
        let sequential_pattern = self.detect_sequential_pattern(accessed_key).await;
        let temporal_pattern = self.detect_temporal_pattern(accessed_key).await;
        
        let mut patterns = self.patterns.write().unwrap();
        
        if let Some(pattern) = sequential_pattern {
            patterns.push(pattern);
        }
        
        if let Some(pattern) = temporal_pattern {
            patterns.push(pattern);
        }
        
        // 清理过期或低效的模式
        patterns.retain(|p| p.success_rate > 0.3 && 
            chrono::Utc::now().signed_duration_since(p.last_used).num_hours() < 24);
    }
    
    async fn detect_sequential_pattern(&self, _key: &str) -> Option<PrefetchPattern> {
        // 检测顺序访问模式，如 key1, key2, key3...
        // 简化实现
        None
    }
    
    async fn detect_temporal_pattern(&self, _key: &str) -> Option<PrefetchPattern> {
        // 检测时间相关的访问模式
        // 简化实现
        None
    }
}

pub struct AccessHistory {
    history: Arc<RwLock<Vec<AccessRecord>>>,
    max_history_size: usize,
}

#[derive(Debug, Clone)]
pub struct AccessRecord {
    pub key: String,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub access_type: AccessType,
}

#[derive(Debug, Clone)]
pub enum AccessType {
    Hit,
    Miss,
    Prefetch,
}

impl AccessHistory {
    pub fn new() -> Self {
        Self {
            history: Arc::new(RwLock::new(Vec::new())),
            max_history_size: 10000,
        }
    }
    
    pub async fn record_access(&self, key: &str) {
        let record = AccessRecord {
            key: key.to_string(),
            timestamp: chrono::Utc::now(),
            access_type: AccessType::Hit,
        };
        
        let mut history = self.history.write().unwrap();
        history.push(record);
        
        // 保持历史记录大小
        if history.len() > self.max_history_size {
            history.remove(0);
        }
    }
    
    pub fn get_recent_accesses(&self, duration: Duration) -> Vec<AccessRecord> {
        let cutoff_time = chrono::Utc::now() - chrono::Duration::from_std(duration).unwrap();
        let history = self.history.read().unwrap();
        
        history.iter()
            .filter(|record| record.timestamp > cutoff_time)
            .cloned()
            .collect()
    }
}

pub struct MLPredictor {
    // 简化的机器学习预测器
}

impl MLPredictor {
    pub fn new() -> Self {
        Self {}
    }
    
    pub async fn predict_next_keys(&self, _current_key: &str) -> Vec<String> {
        // 简化实现：基于当前键预测下一个可能的键
        vec![]
    }
    
    pub async fn train_on_access_pattern(&self, _pattern: &[AccessRecord]) {
        // 使用访问模式训练预测模型
    }
}
```

## 6. 缓存指标监控

```rust
pub struct CacheMetrics {
    level_metrics: DashMap<u8, LevelMetrics>,
    global_metrics: Arc<RwLock<GlobalMetrics>>,
}

#[derive(Debug, Clone)]
pub struct LevelMetrics {
    pub level: u8,
    pub hits: u64,
    pub misses: u64,
    pub hit_rate: f64,
    pub avg_access_time: Duration,
    pub evictions: u64,
}

#[derive(Debug, Clone)]
pub struct GlobalMetrics {
    pub total_requests: u64,
    pub cache_efficiency: f64,
    pub memory_usage: usize,
    pub prefetch_success_rate: f64,
}

impl CacheMetrics {
    pub fn new() -> Self {
        Self {
            level_metrics: DashMap::new(),
            global_metrics: Arc::new(RwLock::new(GlobalMetrics::default())),
        }
    }
    
    pub async fn record_hit(&self, level: u8) {
        let mut metrics = self.level_metrics.entry(level).or_insert(LevelMetrics::new(level));
        metrics.hits += 1;
        metrics.hit_rate = metrics.hits as f64 / (metrics.hits + metrics.misses) as f64;
        
        let mut global = self.global_metrics.write().unwrap();
        global.total_requests += 1;
    }
    
    pub async fn record_miss(&self, level: u8) {
        let mut metrics = self.level_metrics.entry(level).or_insert(LevelMetrics::new(level));
        metrics.misses += 1;
        metrics.hit_rate = metrics.hits as f64 / (metrics.hits + metrics.misses) as f64;
        
        let mut global = self.global_metrics.write().unwrap();
        global.total_requests += 1;
    }
    
    pub async fn record_access_time(&self, level: u8, duration: Duration) {
        let mut metrics = self.level_metrics.entry(level).or_insert(LevelMetrics::new(level));
        // 简化的平均时间计算
        metrics.avg_access_time = (metrics.avg_access_time + duration) / 2;
    }
    
    pub fn get_metrics_report(&self) -> MetricsReport {
        let level_reports: Vec<_> = self.level_metrics.iter()
            .map(|entry| entry.value().clone())
            .collect();
        
        let global = self.global_metrics.read().unwrap().clone();
        
        MetricsReport {
            levels: level_reports,
            global,
            timestamp: chrono::Utc::now(),
        }
    }
}

impl LevelMetrics {
    fn new(level: u8) -> Self {
        Self {
            level,
            hits: 0,
            misses: 0,
            hit_rate: 0.0,
            avg_access_time: Duration::from_millis(0),
            evictions: 0,
        }
    }
}

impl Default for GlobalMetrics {
    fn default() -> Self {
        Self {
            total_requests: 0,
            cache_efficiency: 0.0,
            memory_usage: 0,
            prefetch_success_rate: 0.0,
        }
    }
}

#[derive(Debug, Clone)]
pub struct MetricsReport {
    pub levels: Vec<LevelMetrics>,
    pub global: GlobalMetrics,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}
```

## 7. 测试框架

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_memory_cache_basic_operations() {
        let config = MemoryCacheConfig {
            max_capacity: 100,
            default_ttl: Duration::from_secs(60),
            cleanup_interval: Duration::from_secs(10),
        };
        
        let cache = MemoryCache::new(config, EvictionPolicy::LRU);
        
        // 测试设置和获取
        cache.set("key1".to_string(), "value1".to_string(), None).await.unwrap();
        let result = cache.get(&"key1".to_string()).await.unwrap();
        assert_eq!(result, Some("value1".to_string()));
        
        // 测试不存在的键
        let result = cache.get(&"nonexistent".to_string()).await.unwrap();
        assert_eq!(result, None);
        
        // 测试删除
        let deleted = cache.delete(&"key1".to_string()).await.unwrap();
        assert!(deleted);
        
        let result = cache.get(&"key1".to_string()).await.unwrap();
        assert_eq!(result, None);
    }
    
    #[tokio::test]
    async fn test_cache_ttl() {
        let config = MemoryCacheConfig {
            max_capacity: 100,
            default_ttl: Duration::from_secs(60),
            cleanup_interval: Duration::from_secs(10),
        };
        
        let cache = MemoryCache::new(config, EvictionPolicy::TTL);
        
        // 设置一个很短的TTL
        cache.set("temp_key".to_string(), "temp_value".to_string(), Some(Duration::from_millis(100))).await.unwrap();
        
        // 立即获取应该成功
        let result = cache.get(&"temp_key".to_string()).await.unwrap();
        assert_eq!(result, Some("temp_value".to_string()));
        
        // 等待过期
        tokio::time::sleep(Duration::from_millis(150)).await;
        
        // 现在应该返回None
        let result = cache.get(&"temp_key".to_string()).await.unwrap();
        assert_eq!(result, None);
    }
    
    #[tokio::test]
    async fn test_multi_level_cache() {
        let mut manager = MultiLevelCacheManager::new(CacheStrategy::WriteThrough);
        
        // 创建L1缓存（内存，快速）
        let l1_config = MemoryCacheConfig {
            max_capacity: 10,
            default_ttl: Duration::from_secs(60),
            cleanup_interval: Duration::from_secs(10),
        };
        let l1_cache = MemoryCache::new(l1_config, EvictionPolicy::LRU);
        
        let l1_level = CacheLevel {
            level: 1,
            cache: Arc::new(l1_cache),
            promotion_threshold: 2,
            demotion_threshold: 1,
        };
        
        manager.add_cache_level(l1_level);
        
        // 测试多级缓存操作
        manager.set("test_key".to_string(), serde_json::json!("test_value"), None).await.unwrap();
        
        let result = manager.get("test_key").await.unwrap();
        assert_eq!(result, Some(serde_json::json!("test_value")));
    }
}
```

这个实现提供了完整的智能缓存管理系统，支持多级缓存、智能预取和自适应失效策略。
