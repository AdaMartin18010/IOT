# 性能优化与负载均衡实现

## 1. 负载均衡器

### 1.1 负载均衡算法

```rust
// src/load_balancer/mod.rs
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, RwLock};
use serde::{Deserialize, Serialize};
use std::time::{Duration, Instant};

#[derive(Debug)]
pub struct LoadBalancer {
    algorithm: Box<dyn LoadBalancingAlgorithm>,
    backend_servers: Arc<RwLock<Vec<BackendServer>>>,
    health_checker: HealthChecker,
    metrics_collector: MetricsCollector,
    session_manager: SessionManager,
}

#[derive(Debug, Clone)]
pub struct BackendServer {
    pub id: String,
    pub address: String,
    pub port: u16,
    pub weight: u32,
    pub max_connections: u32,
    pub current_connections: Arc<RwLock<u32>>,
    pub health_status: HealthStatus,
    pub response_time: Arc<RwLock<f64>>,
    pub last_health_check: Arc<RwLock<Instant>>,
}

#[derive(Debug, Clone)]
pub enum HealthStatus {
    Healthy,
    Unhealthy,
    Unknown,
}

#[async_trait::async_trait]
pub trait LoadBalancingAlgorithm: Send + Sync {
    async fn select_backend(&self, backends: &[BackendServer], request: &Request) -> Result<BackendServer, LoadBalancerError>;
    fn get_algorithm_name(&self) -> &str;
}

#[derive(Debug)]
pub struct RoundRobinAlgorithm {
    current_index: Arc<RwLock<usize>>,
}

#[async_trait::async_trait]
impl LoadBalancingAlgorithm for RoundRobinAlgorithm {
    async fn select_backend(&self, backends: &[BackendServer], _request: &Request) -> Result<BackendServer, LoadBalancerError> {
        if backends.is_empty() {
            return Err(LoadBalancerError::NoBackendServers);
        }
        
        let mut index = self.current_index.write().await;
        let selected_backend = backends[*index].clone();
        *index = (*index + 1) % backends.len();
        
        Ok(selected_backend)
    }
    
    fn get_algorithm_name(&self) -> &str {
        "RoundRobin"
    }
}

#[derive(Debug)]
pub struct WeightedRoundRobinAlgorithm {
    current_index: Arc<RwLock<usize>>,
    current_weight: Arc<RwLock<u32>>,
}

#[async_trait::async_trait]
impl LoadBalancingAlgorithm for WeightedRoundRobinAlgorithm {
    async fn select_backend(&self, backends: &[BackendServer], _request: &Request) -> Result<BackendServer, LoadBalancerError> {
        if backends.is_empty() {
            return Err(LoadBalancerError::NoBackendServers);
        }
        
        let mut index = self.current_index.write().await;
        let mut weight = self.current_weight.write().await;
        
        loop {
            if *index >= backends.len() {
                *index = 0;
                *weight = 0;
            }
            
            if *weight < backends[*index].weight {
                let selected_backend = backends[*index].clone();
                *weight += 1;
                return Ok(selected_backend);
            }
            
            *index += 1;
            *weight = 0;
        }
    }
    
    fn get_algorithm_name(&self) -> &str {
        "WeightedRoundRobin"
    }
}

#[derive(Debug)]
pub struct LeastConnectionsAlgorithm;

#[async_trait::async_trait]
impl LoadBalancingAlgorithm for LeastConnectionsAlgorithm {
    async fn select_backend(&self, backends: &[BackendServer], _request: &Request) -> Result<BackendServer, LoadBalancerError> {
        if backends.is_empty() {
            return Err(LoadBalancerError::NoBackendServers);
        }
        
        let mut min_connections = u32::MAX;
        let mut selected_backend = None;
        
        for backend in backends {
            let connections = *backend.current_connections.read().await;
            if connections < min_connections && backend.health_status == HealthStatus::Healthy {
                min_connections = connections;
                selected_backend = Some(backend.clone());
            }
        }
        
        selected_backend.ok_or(LoadBalancerError::NoHealthyBackendServers)
    }
    
    fn get_algorithm_name(&self) -> &str {
        "LeastConnections"
    }
}

#[derive(Debug)]
pub struct ResponseTimeAlgorithm {
    response_time_threshold: f64,
}

#[async_trait::async_trait]
impl LoadBalancingAlgorithm for ResponseTimeAlgorithm {
    async fn select_backend(&self, backends: &[BackendServer], _request: &Request) -> Result<BackendServer, LoadBalancerError> {
        if backends.is_empty() {
            return Err(LoadBalancerError::NoBackendServers);
        }
        
        let mut best_backend = None;
        let mut best_response_time = f64::MAX;
        
        for backend in backends {
            if backend.health_status == HealthStatus::Healthy {
                let response_time = *backend.response_time.read().await;
                if response_time < best_response_time && response_time < self.response_time_threshold {
                    best_response_time = response_time;
                    best_backend = Some(backend.clone());
                }
            }
        }
        
        best_backend.ok_or(LoadBalancerError::NoHealthyBackendServers)
    }
    
    fn get_algorithm_name(&self) -> &str {
        "ResponseTime"
    }
}

impl LoadBalancer {
    pub async fn new(algorithm: Box<dyn LoadBalancingAlgorithm>) -> Result<Self, LoadBalancerError> {
        Ok(LoadBalancer {
            algorithm,
            backend_servers: Arc::new(RwLock::new(Vec::new())),
            health_checker: HealthChecker::new(),
            metrics_collector: MetricsCollector::new(),
            session_manager: SessionManager::new(),
        })
    }
    
    pub async fn add_backend(&mut self, backend: BackendServer) -> Result<(), LoadBalancerError> {
        let mut backends = self.backend_servers.write().await;
        backends.push(backend);
        Ok(())
    }
    
    pub async fn remove_backend(&mut self, backend_id: &str) -> Result<(), LoadBalancerError> {
        let mut backends = self.backend_servers.write().await;
        backends.retain(|b| b.id != backend_id);
        Ok(())
    }
    
    pub async fn route_request(&mut self, request: Request) -> Result<Response, LoadBalancerError> {
        // 获取健康的后端服务器
        let backends = self.get_healthy_backends().await?;
        
        if backends.is_empty() {
            return Err(LoadBalancerError::NoHealthyBackendServers);
        }
        
        // 选择后端服务器
        let selected_backend = self.algorithm.select_backend(&backends, &request).await?;
        
        // 增加连接计数
        self.increment_connection_count(&selected_backend.id).await?;
        
        // 记录请求开始时间
        let start_time = Instant::now();
        
        // 转发请求
        let response = self.forward_request(&selected_backend, request).await?;
        
        // 更新响应时间
        let response_time = start_time.elapsed().as_millis() as f64;
        self.update_response_time(&selected_backend.id, response_time).await?;
        
        // 减少连接计数
        self.decrement_connection_count(&selected_backend.id).await?;
        
        // 收集指标
        self.metrics_collector.record_request(&selected_backend.id, response_time).await?;
        
        Ok(response)
    }
    
    async fn get_healthy_backends(&self) -> Result<Vec<BackendServer>, LoadBalancerError> {
        let backends = self.backend_servers.read().await;
        let healthy_backends: Vec<_> = backends.iter()
            .filter(|b| b.health_status == HealthStatus::Healthy)
            .cloned()
            .collect();
        
        Ok(healthy_backends)
    }
    
    async fn increment_connection_count(&self, backend_id: &str) -> Result<(), LoadBalancerError> {
        let backends = self.backend_servers.read().await;
        if let Some(backend) = backends.iter().find(|b| b.id == backend_id) {
            let mut connections = backend.current_connections.write().await;
            *connections += 1;
        }
        Ok(())
    }
    
    async fn decrement_connection_count(&self, backend_id: &str) -> Result<(), LoadBalancerError> {
        let backends = self.backend_servers.read().await;
        if let Some(backend) = backends.iter().find(|b| b.id == backend_id) {
            let mut connections = backend.current_connections.write().await;
            *connections = connections.saturating_sub(1);
        }
        Ok(())
    }
    
    async fn update_response_time(&self, backend_id: &str, response_time: f64) -> Result<(), LoadBalancerError> {
        let backends = self.backend_servers.read().await;
        if let Some(backend) = backends.iter().find(|b| b.id == backend_id) {
            let mut avg_response_time = backend.response_time.write().await;
            // 使用指数移动平均
            *avg_response_time = *avg_response_time * 0.9 + response_time * 0.1;
        }
        Ok(())
    }
}
```

### 1.2 会话保持

```rust
#[derive(Debug)]
pub struct SessionManager {
    sessions: Arc<RwLock<HashMap<String, SessionInfo>>>,
    session_timeout: Duration,
    sticky_cookie_name: String,
}

#[derive(Debug, Clone)]
pub struct SessionInfo {
    pub session_id: String,
    pub backend_id: String,
    pub created_at: Instant,
    pub last_accessed: Instant,
    pub request_count: u32,
}

impl SessionManager {
    pub async fn get_backend_for_session(&self, session_id: &str) -> Option<String> {
        let sessions = self.sessions.read().await;
        if let Some(session) = sessions.get(session_id) {
            // 检查会话是否过期
            if session.last_accessed.elapsed() < self.session_timeout {
                return Some(session.backend_id.clone());
            }
        }
        None
    }
    
    pub async fn create_session(&mut self, session_id: String, backend_id: String) -> Result<(), LoadBalancerError> {
        let mut sessions = self.sessions.write().await;
        let session_info = SessionInfo {
            session_id: session_id.clone(),
            backend_id,
            created_at: Instant::now(),
            last_accessed: Instant::now(),
            request_count: 1,
        };
        sessions.insert(session_id, session_info);
        Ok(())
    }
    
    pub async fn update_session(&mut self, session_id: &str) -> Result<(), LoadBalancerError> {
        let mut sessions = self.sessions.write().await;
        if let Some(session) = sessions.get_mut(session_id) {
            session.last_accessed = Instant::now();
            session.request_count += 1;
        }
        Ok(())
    }
    
    pub async fn cleanup_expired_sessions(&mut self) -> Result<(), LoadBalancerError> {
        let mut sessions = self.sessions.write().await;
        let now = Instant::now();
        sessions.retain(|_, session| {
            now.duration_since(session.last_accessed) < self.session_timeout
        });
        Ok(())
    }
}
```

## 2. 性能优化

### 2.1 缓存系统

```rust
#[derive(Debug)]
pub struct CacheManager {
    memory_cache: Arc<RwLock<HashMap<String, CacheEntry>>>,
    redis_cache: RedisCache,
    cache_policy: CachePolicy,
    metrics_collector: CacheMetricsCollector,
}

#[derive(Debug, Clone)]
pub struct CacheEntry {
    pub key: String,
    pub value: serde_json::Value,
    pub created_at: Instant,
    pub last_accessed: Instant,
    pub access_count: u32,
    pub ttl: Duration,
}

#[derive(Debug, Clone)]
pub struct CachePolicy {
    pub max_memory_mb: u64,
    pub max_entries: u32,
    pub eviction_policy: EvictionPolicy,
    pub default_ttl: Duration,
}

#[derive(Debug, Clone)]
pub enum EvictionPolicy {
    LRU, // Least Recently Used
    LFU, // Least Frequently Used
    FIFO, // First In First Out
    TTL, // Time To Live
}

impl CacheManager {
    pub async fn get(&mut self, key: &str) -> Result<Option<serde_json::Value>, CacheError> {
        // 首先检查内存缓存
        if let Some(value) = self.get_from_memory_cache(key).await? {
            return Ok(Some(value));
        }
        
        // 检查Redis缓存
        if let Some(value) = self.get_from_redis_cache(key).await? {
            // 回填到内存缓存
            self.set_in_memory_cache(key, &value).await?;
            return Ok(Some(value));
        }
        
        Ok(None)
    }
    
    pub async fn set(&mut self, key: &str, value: serde_json::Value, ttl: Option<Duration>) -> Result<(), CacheError> {
        let ttl = ttl.unwrap_or(self.cache_policy.default_ttl);
        
        // 设置到内存缓存
        self.set_in_memory_cache(key, &value).await?;
        
        // 设置到Redis缓存
        self.set_in_redis_cache(key, &value, ttl).await?;
        
        // 记录指标
        self.metrics_collector.record_set(key).await?;
        
        Ok(())
    }
    
    async fn get_from_memory_cache(&mut self, key: &str) -> Result<Option<serde_json::Value>, CacheError> {
        let mut cache = self.memory_cache.write().await;
        
        if let Some(entry) = cache.get_mut(key) {
            // 检查TTL
            if entry.created_at.elapsed() < entry.ttl {
                entry.last_accessed = Instant::now();
                entry.access_count += 1;
                return Ok(Some(entry.value.clone()));
            } else {
                // 移除过期条目
                cache.remove(key);
            }
        }
        
        Ok(None)
    }
    
    async fn set_in_memory_cache(&mut self, key: &str, value: &serde_json::Value) -> Result<(), CacheError> {
        let mut cache = self.memory_cache.write().await;
        
        // 检查缓存大小限制
        if cache.len() >= self.cache_policy.max_entries as usize {
            self.evict_entries(&mut cache).await?;
        }
        
        let entry = CacheEntry {
            key: key.to_string(),
            value: value.clone(),
            created_at: Instant::now(),
            last_accessed: Instant::now(),
            access_count: 1,
            ttl: self.cache_policy.default_ttl,
        };
        
        cache.insert(key.to_string(), entry);
        Ok(())
    }
    
    async fn evict_entries(&self, cache: &mut HashMap<String, CacheEntry>) -> Result<(), CacheError> {
        match self.cache_policy.eviction_policy {
            EvictionPolicy::LRU => {
                // 移除最久未访问的条目
                let oldest_key = cache.iter()
                    .min_by_key(|(_, entry)| entry.last_accessed)
                    .map(|(key, _)| key.clone());
                
                if let Some(key) = oldest_key {
                    cache.remove(&key);
                }
            }
            EvictionPolicy::LFU => {
                // 移除访问次数最少的条目
                let least_frequent_key = cache.iter()
                    .min_by_key(|(_, entry)| entry.access_count)
                    .map(|(key, _)| key.clone());
                
                if let Some(key) = least_frequent_key {
                    cache.remove(&key);
                }
            }
            EvictionPolicy::FIFO => {
                // 移除最早创建的条目
                let oldest_key = cache.iter()
                    .min_by_key(|(_, entry)| entry.created_at)
                    .map(|(key, _)| key.clone());
                
                if let Some(key) = oldest_key {
                    cache.remove(&key);
                }
            }
            EvictionPolicy::TTL => {
                // 移除TTL最短的条目
                let shortest_ttl_key = cache.iter()
                    .min_by_key(|(_, entry)| entry.ttl)
                    .map(|(key, _)| key.clone());
                
                if let Some(key) = shortest_ttl_key {
                    cache.remove(&key);
                }
            }
        }
        
        Ok(())
    }
}
```

### 2.2 连接池管理

```rust
#[derive(Debug)]
pub struct ConnectionPool {
    pool_config: PoolConfig,
    connections: Arc<RwLock<Vec<PooledConnection>>>,
    connection_factory: Box<dyn ConnectionFactory>,
    health_checker: ConnectionHealthChecker,
}

#[derive(Debug, Clone)]
pub struct PoolConfig {
    pub min_connections: u32,
    pub max_connections: u32,
    pub connection_timeout: Duration,
    pub idle_timeout: Duration,
    pub health_check_interval: Duration,
}

#[derive(Debug)]
pub struct PooledConnection {
    pub id: String,
    pub connection: Box<dyn Connection>,
    pub created_at: Instant,
    pub last_used: Instant,
    pub is_healthy: bool,
    pub is_in_use: bool,
}

#[async_trait::async_trait]
pub trait Connection: Send + Sync {
    async fn execute(&mut self, query: &str) -> Result<QueryResult, ConnectionError>;
    async fn is_healthy(&self) -> bool;
    async fn close(&mut self) -> Result<(), ConnectionError>;
}

#[async_trait::async_trait]
pub trait ConnectionFactory: Send + Sync {
    async fn create_connection(&self) -> Result<Box<dyn Connection>, ConnectionError>;
}

impl ConnectionPool {
    pub async fn new(config: PoolConfig, factory: Box<dyn ConnectionFactory>) -> Result<Self, ConnectionError> {
        let pool = ConnectionPool {
            pool_config: config,
            connections: Arc::new(RwLock::new(Vec::new())),
            connection_factory: factory,
            health_checker: ConnectionHealthChecker::new(),
        };
        
        // 初始化最小连接数
        pool.initialize_min_connections().await?;
        
        Ok(pool)
    }
    
    pub async fn get_connection(&mut self) -> Result<PooledConnection, ConnectionError> {
        let mut connections = self.connections.write().await;
        
        // 查找可用的连接
        for connection in connections.iter_mut() {
            if !connection.is_in_use && connection.is_healthy {
                connection.is_in_use = true;
                connection.last_used = Instant::now();
                return Ok(connection.clone());
            }
        }
        
        // 如果没有可用连接，尝试创建新连接
        if connections.len() < self.pool_config.max_connections as usize {
            let new_connection = self.create_new_connection().await?;
            connections.push(new_connection.clone());
            return Ok(new_connection);
        }
        
        // 等待可用连接
        self.wait_for_available_connection().await
    }
    
    pub async fn release_connection(&mut self, connection_id: &str) -> Result<(), ConnectionError> {
        let mut connections = self.connections.write().await;
        
        if let Some(connection) = connections.iter_mut().find(|c| c.id == connection_id) {
            connection.is_in_use = false;
        }
        
        Ok(())
    }
    
    async fn create_new_connection(&self) -> Result<PooledConnection, ConnectionError> {
        let connection = self.connection_factory.create_connection().await?;
        
        Ok(PooledConnection {
            id: uuid::Uuid::new_v4().to_string(),
            connection,
            created_at: Instant::now(),
            last_used: Instant::now(),
            is_healthy: true,
            is_in_use: false,
        })
    }
    
    async fn initialize_min_connections(&self) -> Result<(), ConnectionError> {
        let mut connections = self.connections.write().await;
        
        for _ in 0..self.pool_config.min_connections {
            let connection = self.create_new_connection().await?;
            connections.push(connection);
        }
        
        Ok(())
    }
    
    async fn wait_for_available_connection(&self) -> Result<PooledConnection, ConnectionError> {
        let timeout = self.pool_config.connection_timeout;
        let start_time = Instant::now();
        
        while start_time.elapsed() < timeout {
            let mut connections = self.connections.write().await;
            
            for connection in connections.iter_mut() {
                if !connection.is_in_use && connection.is_healthy {
                    connection.is_in_use = true;
                    connection.last_used = Instant::now();
                    return Ok(connection.clone());
                }
            }
            
            drop(connections);
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
        
        Err(ConnectionError::ConnectionTimeout)
    }
    
    pub async fn health_check(&mut self) -> Result<(), ConnectionError> {
        let mut connections = self.connections.write().await;
        
        for connection in connections.iter_mut() {
            if !connection.is_in_use {
                connection.is_healthy = connection.connection.is_healthy().await;
            }
        }
        
        // 移除不健康的连接
        connections.retain(|c| c.is_healthy);
        
        // 补充到最小连接数
        while connections.len() < self.pool_config.min_connections as usize {
            let new_connection = self.create_new_connection().await?;
            connections.push(new_connection);
        }
        
        Ok(())
    }
}
```

## 3. 配置和使用示例

### 3.1 负载均衡配置

```yaml
# config/load_balancer.yaml
load_balancer:
  algorithm: "WeightedRoundRobin"
  health_check:
    enabled: true
    interval: 30
    timeout: 5
    retries: 3
    
  session_sticky:
    enabled: true
    cookie_name: "lb_session"
    timeout: 3600
    
  backends:
    - id: "backend-1"
      address: "192.168.1.10"
      port: 8080
      weight: 3
      max_connections: 100
      
    - id: "backend-2"
      address: "192.168.1.11"
      port: 8080
      weight: 2
      max_connections: 100
      
    - id: "backend-3"
      address: "192.168.1.12"
      port: 8080
      weight: 1
      max_connections: 100
      
  metrics:
    enabled: true
    prometheus_endpoint: "/metrics"
```

### 3.2 缓存配置

```yaml
# config/cache.yaml
cache:
  memory_cache:
    max_entries: 10000
    max_memory_mb: 512
    eviction_policy: "LRU"
    default_ttl: 3600
    
  redis_cache:
    enabled: true
    host: "localhost"
    port: 6379
    password: ""
    database: 0
    max_connections: 50
    
  cache_policy:
    write_through: true
    write_behind: false
    cache_aside: true
```

### 3.3 使用示例

```rust
use crate::load_balancer::{LoadBalancer, WeightedRoundRobinAlgorithm, BackendServer};
use crate::cache::{CacheManager, CachePolicy, EvictionPolicy};
use crate::connection_pool::{ConnectionPool, PoolConfig};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 创建负载均衡器
    let algorithm = Box::new(WeightedRoundRobinAlgorithm::new());
    let mut load_balancer = LoadBalancer::new(algorithm).await?;
    
    // 添加后端服务器
    let backends = vec![
        BackendServer {
            id: "backend-1".to_string(),
            address: "192.168.1.10".to_string(),
            port: 8080,
            weight: 3,
            max_connections: 100,
            current_connections: Arc::new(RwLock::new(0)),
            health_status: HealthStatus::Healthy,
            response_time: Arc::new(RwLock::new(0.0)),
            last_health_check: Arc::new(RwLock::new(Instant::now())),
        },
        BackendServer {
            id: "backend-2".to_string(),
            address: "192.168.1.11".to_string(),
            port: 8080,
            weight: 2,
            max_connections: 100,
            current_connections: Arc::new(RwLock::new(0)),
            health_status: HealthStatus::Healthy,
            response_time: Arc::new(RwLock::new(0.0)),
            last_health_check: Arc::new(RwLock::new(Instant::now())),
        },
    ];
    
    for backend in backends {
        load_balancer.add_backend(backend).await?;
    }
    
    // 创建缓存管理器
    let cache_policy = CachePolicy {
        max_memory_mb: 512,
        max_entries: 10000,
        eviction_policy: EvictionPolicy::LRU,
        default_ttl: Duration::from_secs(3600),
    };
    
    let mut cache_manager = CacheManager::new(cache_policy).await?;
    
    // 创建连接池
    let pool_config = PoolConfig {
        min_connections: 5,
        max_connections: 50,
        connection_timeout: Duration::from_secs(30),
        idle_timeout: Duration::from_secs(300),
        health_check_interval: Duration::from_secs(60),
    };
    
    let connection_factory = Box::new(DatabaseConnectionFactory::new());
    let mut connection_pool = ConnectionPool::new(pool_config, connection_factory).await?;
    
    // 模拟请求处理
    for i in 0..100 {
        let request = Request {
            id: format!("req-{}", i),
            method: "GET".to_string(),
            path: "/api/data".to_string(),
            headers: HashMap::new(),
            body: None,
        };
        
        // 检查缓存
        let cache_key = format!("data:{}", i);
        if let Some(cached_data) = cache_manager.get(&cache_key).await? {
            println!("从缓存获取数据: {}", cached_data);
            continue;
        }
        
        // 通过负载均衡器路由请求
        let response = load_balancer.route_request(request).await?;
        
        // 缓存结果
        let data = json!({"id": i, "data": "some data"});
        cache_manager.set(&cache_key, data, Some(Duration::from_secs(300))).await?;
        
        println!("处理请求 {}: {:?}", i, response);
    }
    
    // 启动健康检查
    tokio::spawn(async move {
        loop {
            load_balancer.health_checker.run_health_checks().await.unwrap_or_else(|e| {
                eprintln!("健康检查失败: {:?}", e);
            });
            
            connection_pool.health_check().await.unwrap_or_else(|e| {
                eprintln!("连接池健康检查失败: {:?}", e);
            });
            
            tokio::time::sleep(Duration::from_secs(30)).await;
        }
    });
    
    // 保持运行
    tokio::signal::ctrl_c().await?;
    println!("正在关闭负载均衡器...");
    
    Ok(())
}
```

这个性能优化与负载均衡实现提供了完整的负载均衡和性能优化功能，包括：

- 多种负载均衡算法（轮询、加权轮询、最少连接、响应时间）
- 会话保持和健康检查
- 多级缓存系统（内存+Redis）
- 连接池管理
- 完整的配置和使用示例

支持高并发场景下的性能优化和负载均衡管理。
