# 物联网工作流引擎实现

## 概述

物联网工作流引擎提供复杂业务流程的自动化执行能力，支持状态机、任务编排、条件分支和并行处理。

## 核心架构

### 1. 工作流引擎核心

```rust
// 工作流引擎核心结构
pub struct WorkflowEngine {
    workflows: Arc<RwLock<HashMap<String, Workflow>>>,
    executions: Arc<RwLock<HashMap<String, WorkflowExecution>>>,
    task_executor: Box<dyn TaskExecutor>,
    state_manager: Box<dyn StateManager>,
}

// 工作流定义
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Workflow {
    pub id: String,
    pub name: String,
    pub description: String,
    pub nodes: Vec<WorkflowNode>,
    pub edges: Vec<WorkflowEdge>,
    pub variables: HashMap<String, VariableDefinition>,
}

// 工作流节点
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowNode {
    pub id: String,
    pub name: String,
    pub node_type: NodeType,
    pub config: NodeConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum NodeType {
    Start,
    End,
    Task,
    Decision,
    Parallel,
    Wait,
    Timer,
}

// 任务配置
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskConfig {
    pub task_type: TaskType,
    pub parameters: HashMap<String, serde_json::Value>,
    pub retry_config: RetryConfig,
    pub timeout: Duration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TaskType {
    DeviceControl,
    DataProcessing,
    Notification,
    API,
    Script,
}

// 工作流边
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowEdge {
    pub id: String,
    pub source_node: String,
    pub target_node: String,
    pub condition: Option<String>,
}

// 工作流执行
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowExecution {
    pub id: String,
    pub workflow_id: String,
    pub status: ExecutionStatus,
    pub current_node: Option<String>,
    pub variables: HashMap<String, serde_json::Value>,
    pub execution_path: Vec<ExecutionStep>,
    pub start_time: DateTime<Utc>,
    pub end_time: Option<DateTime<Utc>>,
    pub error: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ExecutionStatus {
    Running,
    Completed,
    Failed,
    Suspended,
    Cancelled,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionStep {
    pub node_id: String,
    pub node_name: String,
    pub status: StepStatus,
    pub start_time: DateTime<Utc>,
    pub end_time: Option<DateTime<Utc>>,
    pub input: HashMap<String, serde_json::Value>,
    pub output: HashMap<String, serde_json::Value>,
    pub error: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StepStatus {
    Pending,
    Running,
    Completed,
    Failed,
    Skipped,
}
```

### 2. 任务执行器

```rust
// 任务执行器接口
pub trait TaskExecutor: Send + Sync {
    fn execute(&self, task: &TaskConfig, context: &TaskContext) -> Result<TaskResult, WorkflowError>;
}

// 默认任务执行器
pub struct DefaultTaskExecutor {
    device_controller: Arc<DeviceController>,
    notification_service: Arc<NotificationService>,
    api_client: Arc<ApiClient>,
}

impl TaskExecutor for DefaultTaskExecutor {
    fn execute(&self, task: &TaskConfig, context: &TaskContext) -> Result<TaskResult, WorkflowError> {
        let start_time = Instant::now();
        
        let result = match &task.task_type {
            TaskType::DeviceControl => self.execute_device_control(task, context),
            TaskType::Notification => self.execute_notification(task, context),
            TaskType::API => self.execute_api_call(task, context),
            _ => Err(WorkflowError::UnsupportedTaskType),
        };
        
        let execution_time = start_time.elapsed();
        
        Ok(TaskResult {
            success: result.is_ok(),
            output: result.ok(),
            error: result.err().map(|e| e.to_string()),
            execution_time,
        })
    }
}

impl DefaultTaskExecutor {
    async fn execute_device_control(&self, task: &TaskConfig, context: &TaskContext) -> Result<HashMap<String, serde_json::Value>, WorkflowError> {
        let device_id = task.parameters.get("device_id")
            .and_then(|v| v.as_str())
            .ok_or(WorkflowError::MissingParameter("device_id".to_string()))?;
        
        let command = task.parameters.get("command")
            .and_then(|v| v.as_str())
            .ok_or(WorkflowError::MissingParameter("command".to_string()))?;
        
        let result = self.device_controller.send_command(device_id, command, HashMap::new()).await?;
        
        Ok(HashMap::from([
            ("result".to_string(), json!(result)),
            ("device_id".to_string(), json!(device_id)),
        ]))
    }
    
    async fn execute_notification(&self, task: &TaskConfig, context: &TaskContext) -> Result<HashMap<String, serde_json::Value>, WorkflowError> {
        let message = task.parameters.get("message")
            .and_then(|v| v.as_str())
            .ok_or(WorkflowError::MissingParameter("message".to_string()))?;
        
        let recipients = task.parameters.get("recipients")
            .and_then(|v| v.as_array())
            .ok_or(WorkflowError::MissingParameter("recipients".to_string()))?;
        
        let result = self.notification_service.send_notification(message, recipients, "email").await?;
        
        Ok(HashMap::from([
            ("result".to_string(), json!(result)),
            ("message".to_string(), json!(message)),
        ]))
    }
}

#[derive(Debug, Clone)]
pub struct TaskContext {
    pub execution_id: String,
    pub node_id: String,
    pub variables: HashMap<String, serde_json::Value>,
}

#[derive(Debug, Clone)]
pub struct TaskResult {
    pub success: bool,
    pub output: Option<HashMap<String, serde_json::Value>>,
    pub error: Option<String>,
    pub execution_time: Duration,
}
```

### 3. 工作流引擎实现

```rust
impl WorkflowEngine {
    pub fn new() -> Self {
        Self {
            workflows: Arc::new(RwLock::new(HashMap::new())),
            executions: Arc::new(RwLock::new(HashMap::new())),
            task_executor: Box::new(DefaultTaskExecutor::new()),
            state_manager: Box::new(DefaultStateManager::new()),
        }
    }

    // 注册工作流
    pub async fn register_workflow(&self, workflow: Workflow) -> Result<(), WorkflowError> {
        let mut workflows = self.workflows.write().await;
        workflows.insert(workflow.id.clone(), workflow);
        Ok(())
    }

    // 启动工作流执行
    pub async fn start_execution(&self, workflow_id: &str, input_variables: HashMap<String, serde_json::Value>) -> Result<String, WorkflowError> {
        let workflows = self.workflows.read().await;
        let workflow = workflows.get(workflow_id)
            .ok_or(WorkflowError::WorkflowNotFound(workflow_id.to_string()))?;
        
        let execution_id = Uuid::new_v4().to_string();
        let start_node = workflow.nodes.iter()
            .find(|node| matches!(node.node_type, NodeType::Start))
            .ok_or(WorkflowError::NoStartNode)?;
        
        let execution = WorkflowExecution {
            id: execution_id.clone(),
            workflow_id: workflow_id.to_string(),
            status: ExecutionStatus::Running,
            current_node: Some(start_node.id.clone()),
            variables: input_variables,
            execution_path: Vec::new(),
            start_time: Utc::now(),
            end_time: None,
            error: None,
        };
        
        let mut executions = self.executions.write().await;
        executions.insert(execution_id.clone(), execution);
        
        self.execute_node(&execution_id, &start_node.id).await?;
        
        Ok(execution_id)
    }

    // 执行节点
    async fn execute_node(&self, execution_id: &str, node_id: &str) -> Result<(), WorkflowError> {
        let mut executions = self.executions.write().await;
        let execution = executions.get_mut(execution_id)
            .ok_or(WorkflowError::ExecutionNotFound(execution_id.to_string()))?;
        
        let workflows = self.workflows.read().await;
        let workflow = workflows.get(&execution.workflow_id)
            .ok_or(WorkflowError::WorkflowNotFound(execution.workflow_id.clone()))?;
        
        let node = workflow.nodes.iter()
            .find(|n| n.id == node_id)
            .ok_or(WorkflowError::NodeNotFound(node_id.to_string()))?;
        
        let mut step = ExecutionStep {
            node_id: node.id.clone(),
            node_name: node.name.clone(),
            status: StepStatus::Running,
            start_time: Utc::now(),
            end_time: None,
            input: HashMap::new(),
            output: HashMap::new(),
            error: None,
        };
        
        let result = match &node.node_type {
            NodeType::Start => Ok(HashMap::new()),
            NodeType::Task => self.execute_task_node(node, execution).await,
            NodeType::End => {
                execution.status = ExecutionStatus::Completed;
                execution.end_time = Some(Utc::now());
                Ok(HashMap::new())
            }
            _ => Err(WorkflowError::UnsupportedNodeType),
        };
        
        match result {
            Ok(output) => {
                step.status = StepStatus::Completed;
                step.output = output;
            }
            Err(e) => {
                step.status = StepStatus::Failed;
                step.error = Some(e.to_string());
                execution.status = ExecutionStatus::Failed;
                execution.error = Some(e.to_string());
                execution.end_time = Some(Utc::now());
            }
        }
        step.end_time = Some(Utc::now());
        
        execution.execution_path.push(step);
        
        if execution.status == ExecutionStatus::Running {
            self.execute_next_node(execution, node_id, workflow).await?;
        }
        
        Ok(())
    }
    
    async fn execute_task_node(&self, node: &WorkflowNode, execution: &WorkflowExecution) -> Result<HashMap<String, serde_json::Value>, WorkflowError> {
        let task_config = node.config.task_config.as_ref()
            .ok_or(WorkflowError::MissingTaskConfig)?;
        
        let context = TaskContext {
            execution_id: execution.id.clone(),
            node_id: node.id.clone(),
            variables: execution.variables.clone(),
        };
        
        let result = self.task_executor.execute(task_config, &context).await?;
        
        if result.success {
            Ok(result.output.unwrap_or_default())
        } else {
            Err(WorkflowError::TaskExecutionFailed(result.error.unwrap_or_default()))
        }
    }
    
    async fn execute_next_node(&self, execution: &mut WorkflowExecution, current_node_id: &str, workflow: &Workflow) -> Result<(), WorkflowError> {
        let next_node = workflow.edges.iter()
            .find(|edge| edge.source_node == current_node_id)
            .map(|edge| edge.target_node.clone())
            .ok_or(WorkflowError::NoNextNode)?;
        
        execution.current_node = Some(next_node.clone());
        self.execute_node(&execution.id, &next_node).await
    }
}
```

### 4. 工作流引擎API

```rust
#[derive(Deserialize)]
pub struct StartWorkflowRequest {
    pub workflow_id: String,
    pub variables: HashMap<String, serde_json::Value>,
}

#[derive(Serialize)]
pub struct WorkflowExecutionResponse {
    pub execution_id: String,
    pub status: ExecutionStatus,
    pub current_node: Option<String>,
    pub start_time: DateTime<Utc>,
}

// 工作流引擎API路由
pub fn workflow_engine_routes() -> Router {
    Router::new()
        .route("/workflows", post(register_workflow))
        .route("/executions", post(start_execution))
        .route("/executions/:id", get(get_execution))
}

async fn start_execution(
    Json(request): Json<StartWorkflowRequest>,
    State(workflow_engine): State<Arc<WorkflowEngine>>,
) -> Result<Json<WorkflowExecutionResponse>, StatusCode> {
    let execution_id = workflow_engine.start_execution(&request.workflow_id, request.variables).await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    
    let executions = workflow_engine.executions.read().await;
    let execution = executions.get(&execution_id)
        .ok_or(StatusCodes::NOT_FOUND)?;
    
    Ok(Json(WorkflowExecutionResponse {
        execution_id,
        status: execution.status.clone(),
        current_node: execution.current_node.clone(),
        start_time: execution.start_time,
    }))
}
```

## 使用示例

### 1. 创建设备监控工作流

```rust
#[tokio::main]
async fn main() {
    let workflow_engine = Arc::new(WorkflowEngine::new());
    
    // 创建设备监控工作流
    let device_monitoring_workflow = Workflow {
        id: "device-monitoring".to_string(),
        name: "设备监控工作流".to_string(),
        description: "监控设备状态并执行相应动作".to_string(),
        nodes: vec![
            WorkflowNode {
                id: "start".to_string(),
                name: "开始".to_string(),
                node_type: NodeType::Start,
                config: NodeConfig {
                    task_config: None,
                },
            },
            WorkflowNode {
                id: "check-status".to_string(),
                name: "检查设备状态".to_string(),
                node_type: NodeType::Task,
                config: NodeConfig {
                    task_config: Some(TaskConfig {
                        task_type: TaskType::DeviceControl,
                        parameters: HashMap::from([
                            ("device_id".to_string(), json!("device-001")),
                            ("command".to_string(), json!("get_status")),
                        ]),
                        retry_config: RetryConfig {
                            max_retries: 3,
                            retry_delay: Duration::from_secs(5),
                            backoff_multiplier: 2.0,
                        },
                        timeout: Duration::from_secs(30),
                    }),
                },
            },
            WorkflowNode {
                id: "send-alert".to_string(),
                name: "发送告警".to_string(),
                node_type: NodeType::Task,
                config: NodeConfig {
                    task_config: Some(TaskConfig {
                        task_type: TaskType::Notification,
                        parameters: HashMap::from([
                            ("message".to_string(), json!("设备状态异常")),
                            ("recipients".to_string(), json!(["admin@example.com"])),
                        ]),
                        retry_config: RetryConfig {
                            max_retries: 3,
                            retry_delay: Duration::from_secs(10),
                            backoff_multiplier: 2.0,
                        },
                        timeout: Duration::from_secs(60),
                    }),
                },
            },
            WorkflowNode {
                id: "end".to_string(),
                name: "结束".to_string(),
                node_type: NodeType::End,
                config: NodeConfig {
                    task_config: None,
                },
            },
        ],
        edges: vec![
            WorkflowEdge {
                id: "start-to-check".to_string(),
                source_node: "start".to_string(),
                target_node: "check-status".to_string(),
                condition: None,
            },
            WorkflowEdge {
                id: "check-to-alert".to_string(),
                source_node: "check-status".to_string(),
                target_node: "send-alert".to_string(),
                condition: None,
            },
            WorkflowEdge {
                id: "alert-to-end".to_string(),
                source_node: "send-alert".to_string(),
                target_node: "end".to_string(),
                condition: None,
            },
        ],
        variables: HashMap::new(),
    };
    
    workflow_engine.register_workflow(device_monitoring_workflow).await.unwrap();
    println!("设备监控工作流注册成功");
}
```

### 2. 启动工作流执行

```rust
// 启动工作流执行
async fn start_device_monitoring(workflow_engine: Arc<WorkflowEngine>) {
    let variables = HashMap::from([
        ("device_id".to_string(), json!("device-001")),
        ("monitoring_interval".to_string(), json!(300)),
    ]);
    
    let execution_id = workflow_engine.start_execution("device-monitoring", variables).await.unwrap();
    
    println!("工作流执行已启动: {}", execution_id);
    
    // 监控执行状态
    loop {
        let executions = workflow_engine.executions.read().await;
        let execution = executions.get(&execution_id).unwrap();
        
        println!("执行状态: {:?}", execution.status);
        println!("当前节点: {:?}", execution.current_node);
        println!("执行步骤数: {}", execution.execution_path.len());
        
        match execution.status {
            ExecutionStatus::Completed => {
                println!("工作流执行完成");
                break;
            }
            ExecutionStatus::Failed => {
                println!("工作流执行失败: {:?}", execution.error);
                break;
            }
            _ => {
                tokio::time::sleep(Duration::from_secs(5)).await;
            }
        }
    }
}
```

## 核心特性

1. **工作流定义**: 支持节点和边的可视化定义
2. **多种节点类型**: 任务、决策、并行、等待、定时器等
3. **状态管理**: 持久化执行状态和恢复能力
4. **任务执行**: 支持多种任务类型和重试机制
5. **条件分支**: 基于条件的流程控制
6. **错误处理**: 完善的错误处理和恢复机制
7. **监控和日志**: 详细的执行路径和状态监控
8. **API接口**: RESTful API支持
9. **可扩展性**: 插件式任务执行器

这个物联网工作流引擎实现提供了强大的业务流程自动化能力，支持复杂的设备管理和数据处理流程。
