# 边缘计算实现

## 1. 边缘节点

### 1.1 边缘节点定义

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use chrono::{DateTime, Utc};

/// 边缘节点状态
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum EdgeNodeStatus {
    Online,
    Offline,
    Maintenance,
}

/// 边缘节点类型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum EdgeNodeType {
    Gateway,
    Compute,
    Storage,
}

/// 边缘节点
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EdgeNode {
    pub id: String,
    pub name: String,
    pub node_type: EdgeNodeType,
    pub status: EdgeNodeStatus,
    pub location: String,
    pub ip_address: String,
    pub port: u16,
    pub capabilities: Vec<String>,
    pub resources: NodeResources,
    pub connected_devices: Vec<String>,
    pub created_at: DateTime<Utc>,
    pub last_heartbeat: DateTime<Utc>,
}

/// 节点资源
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeResources {
    pub cpu_cores: u32,
    pub memory_mb: u64,
    pub storage_gb: u64,
    pub network_mbps: u64,
    pub cpu_usage_percent: f64,
    pub memory_usage_percent: f64,
    pub storage_usage_percent: f64,
    pub network_usage_percent: f64,
}

impl NodeResources {
    pub fn new(cpu_cores: u32, memory_mb: u64, storage_gb: u64, network_mbps: u64) -> Self {
        Self {
            cpu_cores,
            memory_mb,
            storage_gb,
            network_mbps,
            cpu_usage_percent: 0.0,
            memory_usage_percent: 0.0,
            storage_usage_percent: 0.0,
            network_usage_percent: 0.0,
        }
    }
    
    /// 检查是否有足够资源
    pub fn has_sufficient_resources(&self, required: &NodeResources) -> bool {
        self.cpu_usage_percent + required.cpu_usage_percent <= 100.0 &&
        self.memory_usage_percent + required.memory_usage_percent <= 100.0 &&
        self.storage_usage_percent + required.storage_usage_percent <= 100.0 &&
        self.network_usage_percent + required.network_usage_percent <= 100.0
    }
}
```

### 1.2 边缘节点管理器

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;

/// 边缘节点管理器
pub struct EdgeNodeManager {
    nodes: Arc<RwLock<HashMap<String, EdgeNode>>>,
}

impl EdgeNodeManager {
    pub fn new() -> Self {
        Self {
            nodes: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// 注册边缘节点
    pub async fn register_node(&self, node: EdgeNode) -> Result<(), Box<dyn std::error::Error>> {
        let mut nodes = self.nodes.write().await;
        nodes.insert(node.id.clone(), node);
        println!("Edge node registered: {}", node.id);
        Ok(())
    }
    
    /// 更新节点心跳
    pub async fn update_heartbeat(&self, node_id: &str, resources: NodeResources) -> Result<(), Box<dyn std::error::Error>> {
        let mut nodes = self.nodes.write().await;
        if let Some(node) = nodes.get_mut(node_id) {
            node.last_heartbeat = Utc::now();
            node.resources = resources;
        }
        Ok(())
    }
    
    /// 获取所有节点
    pub async fn get_all_nodes(&self) -> Vec<EdgeNode> {
        let nodes = self.nodes.read().await;
        nodes.values().cloned().collect()
    }
    
    /// 获取在线节点
    pub async fn get_online_nodes(&self) -> Vec<EdgeNode> {
        let nodes = self.nodes.read().await;
        nodes.values()
            .filter(|node| matches!(node.status, EdgeNodeStatus::Online))
            .cloned()
            .collect()
    }
    
    /// 根据类型获取节点
    pub async fn get_nodes_by_type(&self, node_type: EdgeNodeType) -> Vec<EdgeNode> {
        let nodes = self.nodes.read().await;
        nodes.values()
            .filter(|node| node.node_type == node_type)
            .cloned()
            .collect()
    }
    
    /// 查找最适合的节点
    pub async fn find_best_node(&self, required_resources: &NodeResources, node_type: Option<EdgeNodeType>) -> Option<EdgeNode> {
        let nodes = self.nodes.read().await;
        
        let mut best_node: Option<EdgeNode> = None;
        let mut best_score = f64::NEG_INFINITY;
        
        for node in nodes.values() {
            if !matches!(node.status, EdgeNodeStatus::Online) {
                continue;
            }
            
            if let Some(ref required_type) = node_type {
                if node.node_type != *required_type {
                    continue;
                }
            }
            
            if !node.resources.has_sufficient_resources(required_resources) {
                continue;
            }
            
            let score = self.calculate_node_score(&node.resources);
            if score > best_score {
                best_score = score;
                best_node = Some(node.clone());
            }
        }
        
        best_node
    }
    
    /// 计算节点评分
    fn calculate_node_score(&self, resources: &NodeResources) -> f64 {
        let cpu_score = 100.0 - resources.cpu_usage_percent;
        let memory_score = 100.0 - resources.memory_usage_percent;
        let storage_score = 100.0 - resources.storage_usage_percent;
        let network_score = 100.0 - resources.network_usage_percent;
        
        (cpu_score + memory_score + storage_score + network_score) / 4.0
    }
}
```

## 2. 本地数据处理

### 2.1 数据处理管道

```rust
use std::sync::Arc;
use tokio::sync::mpsc;
use serde::{Deserialize, Serialize};

/// 数据处理任务
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataProcessingTask {
    pub id: String,
    pub task_type: String,
    pub input_data: serde_json::Value,
    pub parameters: HashMap<String, serde_json::Value>,
    pub priority: u32,
    pub created_at: DateTime<Utc>,
}

/// 处理结果
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessingResult {
    pub task_id: String,
    pub success: bool,
    pub result_data: Option<serde_json::Value>,
    pub error_message: Option<String>,
    pub processing_time_ms: u64,
    pub completed_at: DateTime<Utc>,
}

/// 数据处理管道
pub struct DataProcessingPipeline {
    task_sender: mpsc::Sender<DataProcessingTask>,
    result_receiver: mpsc::Receiver<ProcessingResult>,
    processors: HashMap<String, Arc<dyn DataProcessor>>,
}

/// 数据处理器接口
#[async_trait::async_trait]
pub trait DataProcessor: Send + Sync {
    async fn process(&self, task: &DataProcessingTask) -> Result<serde_json::Value, Box<dyn std::error::Error>>;
    fn get_name(&self) -> &str;
}

impl DataProcessingPipeline {
    pub fn new() -> Self {
        let (task_sender, task_receiver) = mpsc::channel(1000);
        let (result_sender, result_receiver) = mpsc::channel(1000);
        
        let pipeline = Self {
            task_sender,
            result_receiver,
            processors: HashMap::new(),
        };
        
        // 启动任务处理循环
        let processors = pipeline.processors.clone();
        tokio::spawn(async move {
            Self::task_processing_loop(task_receiver, result_sender, processors).await;
        });
        
        pipeline
    }
    
    /// 注册数据处理器
    pub fn register_processor(&mut self, processor: Arc<dyn DataProcessor>) {
        let processor_name = processor.get_name().to_string();
        self.processors.insert(processor_name, processor);
    }
    
    /// 提交处理任务
    pub async fn submit_task(&self, task: DataProcessingTask) -> Result<(), Box<dyn std::error::Error>> {
        self.task_sender.send(task).await
            .map_err(|e| format!("Failed to submit task: {}", e))?;
        Ok(())
    }
    
    /// 获取处理结果
    pub async fn get_result(&mut self) -> Option<ProcessingResult> {
        self.result_receiver.recv().await
    }
    
    /// 任务处理循环
    async fn task_processing_loop(
        mut task_receiver: mpsc::Receiver<DataProcessingTask>,
        result_sender: mpsc::Sender<ProcessingResult>,
        processors: HashMap<String, Arc<dyn DataProcessor>>,
    ) {
        while let Some(task) = task_receiver.recv().await {
            let start_time = std::time::Instant::now();
            
            let result = if let Some(processor) = processors.get(&task.task_type) {
                match processor.process(&task).await {
                    Ok(result_data) => ProcessingResult {
                        task_id: task.id,
                        success: true,
                        result_data: Some(result_data),
                        error_message: None,
                        processing_time_ms: start_time.elapsed().as_millis() as u64,
                        completed_at: Utc::now(),
                    },
                    Err(e) => ProcessingResult {
                        task_id: task.id,
                        success: false,
                        result_data: None,
                        error_message: Some(e.to_string()),
                        processing_time_ms: start_time.elapsed().as_millis() as u64,
                        completed_at: Utc::now(),
                    },
                }
            } else {
                ProcessingResult {
                    task_id: task.id,
                    success: false,
                    result_data: None,
                    error_message: Some("No processor found".to_string()),
                    processing_time_ms: start_time.elapsed().as_millis() as u64,
                    completed_at: Utc::now(),
                }
            };
            
            let _ = result_sender.send(result).await;
        }
    }
}
```

### 2.2 传感器数据处理器

```rust
/// 传感器数据处理器
pub struct SensorDataProcessor {
    name: String,
}

impl SensorDataProcessor {
    pub fn new() -> Self {
        Self {
            name: "SensorDataProcessor".to_string(),
        }
    }
    
    /// 处理传感器数据
    async fn process_sensor_data(&self, data: &serde_json::Value) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
        let mut processed_data = data.clone();
        
        if let Some(obj) = processed_data.as_object_mut() {
            obj.insert("processed_at".to_string(), serde_json::Value::String(Utc::now().to_rfc3339()));
            
            // 数据验证
            if let Some(value) = obj.get("value") {
                if let Some(value_num) = value.as_f64() {
                    if value_num < -100.0 || value_num > 100.0 {
                        obj.insert("valid".to_string(), serde_json::Value::Bool(false));
                    } else {
                        obj.insert("valid".to_string(), serde_json::Value::Bool(true));
                    }
                }
            }
        }
        
        Ok(processed_data)
    }
    
    /// 异常检测
    async fn detect_anomalies(&self, data: &serde_json::Value) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
        let mut result = data.clone();
        
        if let Some(obj) = result.as_object_mut() {
            if let Some(value) = obj.get("value") {
                if let Some(value_num) = value.as_f64() {
                    let threshold = 50.0;
                    let is_anomaly = value_num.abs() > threshold;
                    
                    obj.insert("is_anomaly".to_string(), serde_json::Value::Bool(is_anomaly));
                }
            }
        }
        
        Ok(result)
    }
}

#[async_trait::async_trait]
impl DataProcessor for SensorDataProcessor {
    async fn process(&self, task: &DataProcessingTask) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
        match task.task_type.as_str() {
            "process_sensor_data" => {
                self.process_sensor_data(&task.input_data).await
            }
            "detect_anomalies" => {
                self.detect_anomalies(&task.input_data).await
            }
            _ => {
                Err("Unsupported task type".into())
            }
        }
    }
    
    fn get_name(&self) -> &str {
        &self.name
    }
}
```

## 3. 资源管理

### 3.1 资源管理器

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;

/// 资源类型
#[derive(Debug, Clone)]
pub enum ResourceType {
    CPU,
    Memory,
    Storage,
    Network,
}

/// 资源分配
#[derive(Debug, Clone)]
pub struct ResourceAllocation {
    pub id: String,
    pub resource_type: ResourceType,
    pub allocated_amount: f64,
    pub task_id: String,
    pub created_at: DateTime<Utc>,
}

/// 资源管理器
pub struct ResourceManager {
    allocations: Arc<RwLock<HashMap<String, ResourceAllocation>>>,
    node_resources: Arc<RwLock<NodeResources>>,
}

impl ResourceManager {
    pub fn new(initial_resources: NodeResources) -> Self {
        Self {
            allocations: Arc::new(RwLock::new(HashMap::new())),
            node_resources: Arc::new(RwLock::new(initial_resources)),
        }
    }
    
    /// 分配资源
    pub async fn allocate_resources(&self, task_id: &str, requirements: &NodeResources) -> Result<bool, Box<dyn std::error::Error>> {
        let mut node_resources = self.node_resources.write().await;
        
        if !node_resources.has_sufficient_resources(requirements) {
            return Ok(false);
        }
        
        // 分配资源
        node_resources.cpu_usage_percent += requirements.cpu_usage_percent;
        node_resources.memory_usage_percent += requirements.memory_usage_percent;
        node_resources.storage_usage_percent += requirements.storage_usage_percent;
        node_resources.network_usage_percent += requirements.network_usage_percent;
        
        // 保存分配记录
        let allocations = vec![
            ResourceAllocation {
                id: format!("cpu_{}", task_id),
                resource_type: ResourceType::CPU,
                allocated_amount: requirements.cpu_usage_percent,
                task_id: task_id.to_string(),
                created_at: Utc::now(),
            },
            ResourceAllocation {
                id: format!("memory_{}", task_id),
                resource_type: ResourceType::Memory,
                allocated_amount: requirements.memory_usage_percent,
                task_id: task_id.to_string(),
                created_at: Utc::now(),
            },
        ];
        
        {
            let mut allocation_map = self.allocations.write().await;
            for allocation in allocations {
                allocation_map.insert(allocation.id.clone(), allocation);
            }
        }
        
        Ok(true)
    }
    
    /// 释放资源
    pub async fn release_resources(&self, task_id: &str) -> Result<(), Box<dyn std::error::Error>> {
        let mut allocations = self.allocations.write().await;
        let mut node_resources = self.node_resources.write().await;
        
        let allocation_ids: Vec<String> = allocations.keys()
            .filter(|id| id.contains(task_id))
            .cloned()
            .collect();
        
        for allocation_id in allocation_ids {
            if let Some(allocation) = allocations.remove(&allocation_id) {
                match allocation.resource_type {
                    ResourceType::CPU => {
                        node_resources.cpu_usage_percent -= allocation.allocated_amount;
                    }
                    ResourceType::Memory => {
                        node_resources.memory_usage_percent -= allocation.allocated_amount;
                    }
                    _ => {}
                }
            }
        }
        
        Ok(())
    }
    
    /// 获取当前资源使用情况
    pub async fn get_resource_usage(&self) -> NodeResources {
        let node_resources = self.node_resources.read().await;
        node_resources.clone()
    }
    
    /// 检查资源是否足够
    pub async fn has_sufficient_resources(&self, requirements: &NodeResources) -> bool {
        let node_resources = self.node_resources.read().await;
        node_resources.has_sufficient_resources(requirements)
    }
}
```

## 4. 应用示例

### 4.1 边缘计算示例

```rust
use std::sync::Arc;

async fn edge_computing_example() -> Result<(), Box<dyn std::error::Error>> {
    // 创建边缘节点管理器
    let node_manager = Arc::new(EdgeNodeManager::new());
    
    // 创建边缘节点
    let edge_node = EdgeNode {
        id: "edge_node_001".to_string(),
        name: "Edge Gateway 1".to_string(),
        node_type: EdgeNodeType::Gateway,
        status: EdgeNodeStatus::Online,
        location: "Building A, Floor 1".to_string(),
        ip_address: "192.168.1.100".to_string(),
        port: 8080,
        capabilities: vec![
            "sensor_data_processing".to_string(),
            "anomaly_detection".to_string(),
        ],
        resources: NodeResources::new(4, 8192, 100, 1000),
        connected_devices: vec![
            "sensor_001".to_string(),
            "sensor_002".to_string(),
        ],
        created_at: Utc::now(),
        last_heartbeat: Utc::now(),
    };
    
    // 注册边缘节点
    node_manager.register_node(edge_node).await?;
    
    // 创建数据处理管道
    let mut pipeline = DataProcessingPipeline::new();
    
    // 注册数据处理器
    let sensor_processor = Arc::new(SensorDataProcessor::new());
    pipeline.register_processor(sensor_processor);
    
    // 创建资源管理器
    let resource_manager = Arc::new(ResourceManager::new(
        NodeResources::new(4, 8192, 100, 1000)
    ));
    
    // 模拟传感器数据处理
    let sensor_data = serde_json::json!({
        "device_id": "sensor_001",
        "timestamp": Utc::now().to_rfc3339(),
        "value": 25.5,
        "unit": "celsius"
    });
    
    // 创建处理任务
    let processing_task = DataProcessingTask {
        id: uuid::Uuid::new_v4().to_string(),
        task_type: "process_sensor_data".to_string(),
        input_data: sensor_data,
        parameters: HashMap::new(),
        priority: 1,
        created_at: Utc::now(),
    };
    
    // 分配资源
    let required_resources = NodeResources::new(1, 512, 1, 10);
    let allocation_success = resource_manager.allocate_resources(&processing_task.id, &required_resources).await?;
    
    if allocation_success {
        println!("Resources allocated for task: {}", processing_task.id);
        
        // 提交处理任务
        pipeline.submit_task(processing_task).await?;
        
        // 获取处理结果
        if let Some(result) = pipeline.get_result().await {
            println!("Processing result:");
            println!("  Task ID: {}", result.task_id);
            println!("  Success: {}", result.success);
            println!("  Processing time: {}ms", result.processing_time_ms);
            
            if let Some(result_data) = result.result_data {
                println!("  Result: {}", result_data);
            }
        }
        
        // 释放资源
        resource_manager.release_resources(&processing_task.id).await?;
        println!("Resources released for task: {}", processing_task.id);
    }
    
    // 获取节点信息
    let all_nodes = node_manager.get_all_nodes().await;
    println!("Total edge nodes: {}", all_nodes.len());
    
    let online_nodes = node_manager.get_online_nodes().await;
    println!("Online edge nodes: {}", online_nodes.len());
    
    // 获取资源使用情况
    let resource_usage = resource_manager.get_resource_usage().await;
    println!("Current resource usage:");
    println!("  CPU: {:.1}%", resource_usage.cpu_usage_percent);
    println!("  Memory: {:.1}%", resource_usage.memory_usage_percent);
    
    println!("Edge computing example completed");
    Ok(())
}

/// 边缘节点管理示例
async fn edge_node_management_example() -> Result<(), Box<dyn std::error::Error>> {
    // 创建边缘节点管理器
    let node_manager = Arc::new(EdgeNodeManager::new());
    
    // 创建多个边缘节点
    let nodes = vec![
        EdgeNode {
            id: "gateway_001".to_string(),
            name: "IoT Gateway 1".to_string(),
            node_type: EdgeNodeType::Gateway,
            status: EdgeNodeStatus::Online,
            location: "Building A".to_string(),
            ip_address: "192.168.1.100".to_string(),
            port: 8080,
            capabilities: vec!["sensor_processing".to_string()],
            resources: NodeResources::new(4, 8192, 100, 1000),
            connected_devices: vec!["sensor_001".to_string()],
            created_at: Utc::now(),
            last_heartbeat: Utc::now(),
        },
        EdgeNode {
            id: "compute_001".to_string(),
            name: "Edge Compute 1".to_string(),
            node_type: EdgeNodeType::Compute,
            status: EdgeNodeStatus::Online,
            location: "Building B".to_string(),
            ip_address: "192.168.1.101".to_string(),
            port: 8081,
            capabilities: vec!["ml_inference".to_string()],
            resources: NodeResources::new(8, 16384, 200, 2000),
            connected_devices: vec![],
            created_at: Utc::now(),
            last_heartbeat: Utc::now(),
        },
    ];
    
    // 注册所有节点
    for node in nodes {
        node_manager.register_node(node).await?;
    }
    
    println!("Registered {} edge nodes", node_manager.get_all_nodes().await.len());
    
    // 查找最适合的计算节点
    let required_resources = NodeResources::new(2, 2048, 10, 100);
    if let Some(best_node) = node_manager.find_best_node(&required_resources, Some(EdgeNodeType::Compute)).await {
        println!("Best compute node found: {} ({})", best_node.name, best_node.id);
    }
    
    // 获取网关节点
    let gateway_nodes = node_manager.get_nodes_by_type(EdgeNodeType::Gateway).await;
    println!("Gateway nodes: {}", gateway_nodes.len());
    
    Ok(())
}

/// 数据处理示例
async fn data_processing_example() -> Result<(), Box<dyn std::error::Error>> {
    // 创建数据处理管道
    let mut pipeline = DataProcessingPipeline::new();
    
    // 注册数据处理器
    let sensor_processor = Arc::new(SensorDataProcessor::new());
    pipeline.register_processor(sensor_processor);
    
    // 创建处理任务
    let task = DataProcessingTask {
        id: uuid::Uuid::new_v4().to_string(),
        task_type: "process_sensor_data".to_string(),
        input_data: serde_json::json!({
            "device_id": "temp_sensor_001",
            "value": 25.5,
            "unit": "celsius",
            "timestamp": Utc::now().to_rfc3339()
        }),
        parameters: HashMap::new(),
        priority: 1,
        created_at: Utc::now(),
    };
    
    // 提交处理任务
    pipeline.submit_task(task).await?;
    
    // 获取处理结果
    if let Some(result) = pipeline.get_result().await {
        println!("Processing result:");
        println!("  Task ID: {}", result.task_id);
        println!("  Success: {}", result.success);
        println!("  Processing time: {}ms", result.processing_time_ms);
        
        if let Some(result_data) = result.result_data {
            println!("  Result: {}", result_data);
        }
    }
    
    Ok(())
}

/// 资源管理示例
async fn resource_management_example() -> Result<(), Box<dyn std::error::Error>> {
    // 创建资源管理器
    let resource_manager = Arc::new(ResourceManager::new(
        NodeResources::new(4, 8192, 100, 1000)
    ));
    
    println!("Initial resource usage:");
    let initial_usage = resource_manager.get_resource_usage().await;
    println!("  CPU: {:.1}%", initial_usage.cpu_usage_percent);
    println!("  Memory: {:.1}%", initial_usage.memory_usage_percent);
    
    // 分配资源
    let required_resources = NodeResources::new(1, 1024, 10, 50);
    let success = resource_manager.allocate_resources("task_001", &required_resources).await?;
    println!("Task resource allocation: {}", if success { "SUCCESS" } else { "FAILED" });
    
    if success {
        let usage = resource_manager.get_resource_usage().await;
        println!("  Current CPU usage: {:.1}%", usage.cpu_usage_percent);
        println!("  Current Memory usage: {:.1}%", usage.memory_usage_percent);
        
        // 释放资源
        resource_manager.release_resources("task_001").await?;
        println!("Resources released for task_001");
        
        let final_usage = resource_manager.get_resource_usage().await;
        println!("Final resource usage:");
        println!("  CPU: {:.1}%", final_usage.cpu_usage_percent);
        println!("  Memory: {:.1}%", final_usage.memory_usage_percent);
    }
    
    Ok(())
}
```

## 5. 总结

本实现提供了完整的边缘计算组件：

1. **边缘节点管理** - 节点注册、状态监控、资源分配
2. **本地数据处理** - 数据处理管道、传感器数据处理
3. **资源管理** - 资源分配、释放、监控
4. **实际应用示例** - 完整的边缘计算演示

这个边缘计算实现为IoT平台提供了本地化、低延迟的数据处理能力。
