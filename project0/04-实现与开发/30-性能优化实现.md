# 性能优化实现

## 概述

性能优化模块负责IoT系统的性能监控、分析和优化，包括内存管理、并发控制、缓存策略和资源调度。

## 核心组件

### 1. 性能监控器

#### Rust实现

```rust
use std::collections::HashMap;
use std::sync::{Arc, RwLock};
use tokio::sync::mpsc;
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};
use std::time::{Duration, Instant};

/// 性能指标
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetric {
    pub name: String,
    pub value: f64,
    pub timestamp: DateTime<Utc>,
    pub labels: HashMap<String, String>,
}

/// 性能统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceStats {
    pub total_requests: u64,
    pub average_response_time: f64,
    pub p95_response_time: f64,
    pub memory_usage: f64,
    pub cpu_usage: f64,
    pub timestamp: DateTime<Utc>,
}

/// 性能监控器
pub struct PerformanceMonitor {
    metrics: Arc<RwLock<HashMap<String, PerformanceMetric>>>,
    response_times: Arc<RwLock<Vec<Duration>>>,
    event_sender: mpsc::Sender<PerformanceEvent>,
}

impl PerformanceMonitor {
    pub fn new() -> Self {
        let (event_sender, _) = mpsc::channel(1000);
        
        Self {
            metrics: Arc::new(RwLock::new(HashMap::new())),
            response_times: Arc::new(RwLock::new(Vec::new())),
            event_sender,
        }
    }

    /// 记录请求
    pub async fn record_request(&self, start_time: Instant) -> Result<(), Box<dyn std::error::Error>> {
        let response_time = start_time.elapsed();
        
        {
            let mut response_times = self.response_times.write().unwrap();
            response_times.push(response_time);
            
            if response_times.len() > 1000 {
                response_times.remove(0);
            }
        }

        let metric = PerformanceMetric {
            name: "request_duration".to_string(),
            value: response_time.as_millis() as f64,
            timestamp: Utc::now(),
            labels: HashMap::new(),
        };

        {
            let mut metrics = self.metrics.write().unwrap();
            metrics.insert(format!("request_{}", Utc::now().timestamp()), metric);
        }

        // 检查性能阈值
        if response_time.as_millis() > 1000 {
            let _ = self.event_sender.send(PerformanceEvent::PerformanceAlert {
                metric_name: "request_duration".to_string(),
                value: response_time.as_millis() as f64,
                threshold: 1000.0,
            }).await;
        }

        Ok(())
    }

    /// 记录内存使用
    pub async fn record_memory_usage(&self, usage_mb: f64) -> Result<(), Box<dyn std::error::Error>> {
        let metric = PerformanceMetric {
            name: "memory_usage".to_string(),
            value: usage_mb,
            timestamp: Utc::now(),
            labels: HashMap::new(),
        };

        {
            let mut metrics = self.metrics.write().unwrap();
            metrics.insert(format!("memory_{}", Utc::now().timestamp()), metric);
        }

        if usage_mb > 1024.0 {
            let _ = self.event_sender.send(PerformanceEvent::PerformanceAlert {
                metric_name: "memory_usage".to_string(),
                value: usage_mb,
                threshold: 1024.0,
            }).await;
        }

        Ok(())
    }

    /// 计算性能统计
    pub async fn calculate_stats(&self) -> PerformanceStats {
        let response_times = {
            let response_times = self.response_times.read().unwrap();
            response_times.clone()
        };

        let mut sorted_times: Vec<Duration> = response_times.clone();
        sorted_times.sort();

        let average_response_time = if !sorted_times.is_empty() {
            let total_ms: u128 = sorted_times.iter().map(|d| d.as_millis()).sum();
            total_ms as f64 / sorted_times.len() as f64
        } else {
            0.0
        };

        let p95_response_time = if sorted_times.len() > 0 {
            let index = (sorted_times.len() as f64 * 0.95) as usize;
            sorted_times.get(index).map(|d| d.as_millis() as f64).unwrap_or(0.0)
        } else {
            0.0
        };

        PerformanceStats {
            total_requests: response_times.len() as u64,
            average_response_time,
            p95_response_time,
            memory_usage: 0.0,
            cpu_usage: 0.0,
            timestamp: Utc::now(),
        }
    }
}

/// 性能事件
#[derive(Debug, Clone)]
pub enum PerformanceEvent {
    PerformanceAlert {
        metric_name: String,
        value: f64,
        threshold: f64,
    },
}

/// 缓存管理器
pub struct CacheManager {
    cache: Arc<RwLock<HashMap<String, (Vec<u8>, Instant)>>>,
    max_size: usize,
    ttl: Duration,
}

impl CacheManager {
    pub fn new(max_size: usize, ttl: Duration) -> Self {
        Self {
            cache: Arc::new(RwLock::new(HashMap::new())),
            max_size,
            ttl,
        }
    }

    /// 获取缓存
    pub async fn get(&self, key: &str) -> Option<Vec<u8>> {
        let cache = self.cache.read().unwrap();
        if let Some((value, timestamp)) = cache.get(key) {
            if timestamp.elapsed() < self.ttl {
                return Some(value.clone());
            }
        }
        None
    }

    /// 设置缓存
    pub async fn set(&self, key: String, value: Vec<u8>) -> Result<(), Box<dyn std::error::Error>> {
        let mut cache = self.cache.write().unwrap();
        
        if cache.len() >= self.max_size {
            let oldest_key = cache.keys().next().cloned();
            if let Some(key_to_remove) = oldest_key {
                cache.remove(&key_to_remove);
            }
        }

        cache.insert(key, (value, Instant::now()));
        Ok(())
    }
}
```

#### Go实现

```go
package performance

import (
    "fmt"
    "sync"
    "time"
)

// PerformanceMetric 性能指标
type PerformanceMetric struct {
    Name      string            `json:"name"`
    Value     float64           `json:"value"`
    Timestamp time.Time         `json:"timestamp"`
    Labels    map[string]string `json:"labels"`
}

// PerformanceStats 性能统计
type PerformanceStats struct {
    TotalRequests       uint64    `json:"total_requests"`
    AverageResponseTime float64   `json:"average_response_time"`
    P95ResponseTime     float64   `json:"p95_response_time"`
    MemoryUsage         float64   `json:"memory_usage"`
    CPUUsage            float64   `json:"cpu_usage"`
    Timestamp           time.Time `json:"timestamp"`
}

// PerformanceMonitor 性能监控器
type PerformanceMonitor struct {
    metrics       map[string]PerformanceMetric
    responseTimes []time.Duration
    eventChan     chan PerformanceEvent
    mu            sync.RWMutex
}

// NewPerformanceMonitor 创建性能监控器
func NewPerformanceMonitor() *PerformanceMonitor {
    return &PerformanceMonitor{
        metrics:       make(map[string]PerformanceMetric),
        responseTimes: make([]time.Duration, 0),
        eventChan:     make(chan PerformanceEvent, 1000),
    }
}

// RecordRequest 记录请求
func (pm *PerformanceMonitor) RecordRequest(startTime time.Time) error {
    responseTime := time.Since(startTime)

    pm.mu.Lock()
    pm.responseTimes = append(pm.responseTimes, responseTime)
    
    if len(pm.responseTimes) > 1000 {
        pm.responseTimes = pm.responseTimes[1:]
    }
    pm.mu.Unlock()

    metric := PerformanceMetric{
        Name:      "request_duration",
        Value:     float64(responseTime.Milliseconds()),
        Timestamp: time.Now(),
        Labels:    make(map[string]string),
    }

    pm.mu.Lock()
    pm.metrics[fmt.Sprintf("request_%d", time.Now().Unix())] = metric
    pm.mu.Unlock()

    if responseTime.Milliseconds() > 1000 {
        select {
        case pm.eventChan <- PerformanceEvent{
            Type:       EventTypePerformanceAlert,
            MetricName: "request_duration",
            Value:      float64(responseTime.Milliseconds()),
            Threshold:  1000.0,
        }:
        default:
        }
    }

    return nil
}

// RecordMemoryUsage 记录内存使用
func (pm *PerformanceMonitor) RecordMemoryUsage(usageMB float64) error {
    metric := PerformanceMetric{
        Name:      "memory_usage",
        Value:     usageMB,
        Timestamp: time.Now(),
        Labels:    make(map[string]string),
    }

    pm.mu.Lock()
    pm.metrics[fmt.Sprintf("memory_%d", time.Now().Unix())] = metric
    pm.mu.Unlock()

    if usageMB > 1024.0 {
        select {
        case pm.eventChan <- PerformanceEvent{
            Type:       EventTypePerformanceAlert,
            MetricName: "memory_usage",
            Value:      usageMB,
            Threshold:  1024.0,
        }:
        default:
        }
    }

    return nil
}

// CalculateStats 计算性能统计
func (pm *PerformanceMonitor) CalculateStats() PerformanceStats {
    pm.mu.RLock()
    responseTimes := make([]time.Duration, len(pm.responseTimes))
    copy(responseTimes, pm.responseTimes)
    pm.mu.RUnlock()

    var averageResponseTime float64
    var p95ResponseTime float64

    if len(responseTimes) > 0 {
        totalMs := int64(0)
        for _, rt := range responseTimes {
            totalMs += rt.Milliseconds()
        }
        averageResponseTime = float64(totalMs) / float64(len(responseTimes))

        sortedTimes := make([]time.Duration, len(responseTimes))
        copy(sortedTimes, responseTimes)
        sort.Slice(sortedTimes, func(i, j int) bool {
            return sortedTimes[i] < sortedTimes[j]
        })

        p95Index := int(float64(len(sortedTimes)) * 0.95)
        if p95Index < len(sortedTimes) {
            p95ResponseTime = float64(sortedTimes[p95Index].Milliseconds())
        }
    }

    return PerformanceStats{
        TotalRequests:       uint64(len(responseTimes)),
        AverageResponseTime: averageResponseTime,
        P95ResponseTime:     p95ResponseTime,
        MemoryUsage:         0.0,
        CPUUsage:            0.0,
        Timestamp:           time.Now(),
    }
}

// GetEventChannel 获取事件通道
func (pm *PerformanceMonitor) GetEventChannel() <-chan PerformanceEvent {
    return pm.eventChan
}

// PerformanceEvent 性能事件
type PerformanceEvent struct {
    Type       EventType `json:"type"`
    MetricName string    `json:"metric_name,omitempty"`
    Value      float64   `json:"value,omitempty"`
    Threshold  float64   `json:"threshold,omitempty"`
}

// EventType 事件类型
type EventType string

const (
    EventTypePerformanceAlert EventType = "performance_alert"
)

// CacheManager 缓存管理器
type CacheManager struct {
    cache   map[string]cacheEntry
    maxSize int
    ttl     time.Duration
    mu      sync.RWMutex
}

type cacheEntry struct {
    value     []byte
    timestamp time.Time
}

// NewCacheManager 创建缓存管理器
func NewCacheManager(maxSize int, ttl time.Duration) *CacheManager {
    return &CacheManager{
        cache:   make(map[string]cacheEntry),
        maxSize: maxSize,
        ttl:     ttl,
    }
}

// Get 获取缓存
func (cm *CacheManager) Get(key string) ([]byte, bool) {
    cm.mu.RLock()
    defer cm.mu.RUnlock()

    if entry, exists := cm.cache[key]; exists {
        if time.Since(entry.timestamp) < cm.ttl {
            return entry.value, true
        }
    }
    return nil, false
}

// Set 设置缓存
func (cm *CacheManager) Set(key string, value []byte) error {
    cm.mu.Lock()
    defer cm.mu.Unlock()

    if len(cm.cache) >= cm.maxSize {
        var oldestKey string
        var oldestTime time.Time
        for k, entry := range cm.cache {
            if oldestKey == "" || entry.timestamp.Before(oldestTime) {
                oldestKey = k
                oldestTime = entry.timestamp
            }
        }
        if oldestKey != "" {
            delete(cm.cache, oldestKey)
        }
    }

    cm.cache[key] = cacheEntry{
        value:     value,
        timestamp: time.Now(),
    }

    return nil
}
```

### 2. 使用示例

```rust
// Rust示例
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let monitor = Arc::new(PerformanceMonitor::new());

    // 模拟请求处理
    for i in 0..100 {
        let start_time = Instant::now();
        
        // 模拟处理时间
        tokio::time::sleep(Duration::from_millis(100 + (i % 900))).await;
        
        monitor.record_request(start_time).await?;
    }

    // 记录系统指标
    monitor.record_memory_usage(512.0).await?;

    // 计算性能统计
    let stats = monitor.calculate_stats().await;
    println!("Performance stats: {:?}", stats);

    // 创建缓存管理器
    let cache_manager = Arc::new(CacheManager::new(1000, Duration::from_secs(300)));

    // 使用缓存
    cache_manager.set("key1".to_string(), b"value1".to_vec()).await?;
    
    if let Some(value) = cache_manager.get("key1").await {
        println!("Cache hit: {:?}", value);
    }

    Ok(())
}
```

```go
// Go示例
func main() {
    monitor := NewPerformanceMonitor()

    // 模拟请求处理
    for i := 0; i < 100; i++ {
        startTime := time.Now()
        
        // 模拟处理时间
        time.Sleep(time.Duration(100+(i%900)) * time.Millisecond)
        
        monitor.RecordRequest(startTime)
    }

    // 记录系统指标
    monitor.RecordMemoryUsage(512.0)

    // 计算性能统计
    stats := monitor.CalculateStats()
    fmt.Printf("Performance stats: %+v\n", stats)

    // 创建缓存管理器
    cacheManager := NewCacheManager(1000, 5*time.Minute)

    // 使用缓存
    cacheManager.Set("key1", []byte("value1"))
    
    if value, exists := cacheManager.Get("key1"); exists {
        fmt.Printf("Cache hit: %s\n", string(value))
    }

    // 监听事件
    go func() {
        for event := range monitor.GetEventChannel() {
            fmt.Printf("Performance event: %+v\n", event)
        }
    }()

    time.Sleep(5 * time.Second)
}
```

## 总结

性能优化实现提供了以下核心功能：

1. **性能监控**：实时监控请求响应时间和系统资源使用
2. **性能统计**：计算平均响应时间、P95百分位数等关键指标
3. **性能告警**：基于阈值的性能告警机制
4. **缓存管理**：LRU缓存策略，支持TTL过期
5. **事件系统**：性能相关事件的通知机制

这个实现为IoT平台提供了基础的性能监控和优化能力。
