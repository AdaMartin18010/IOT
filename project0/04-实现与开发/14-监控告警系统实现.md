# 监控告警系统实现

## 1. 概述

本文档实现IoT系统的监控告警系统，支持实时指标收集、智能告警和可视化监控。

## 2. 监控指标接口

```rust
use serde::{Serialize, Deserialize};
use std::collections::HashMap;

pub trait MetricsCollector: Send + Sync {
    fn collect_metrics(&self) -> Vec<Metric>;
    fn get_collector_name(&self) -> String;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Metric {
    pub name: String,
    pub value: MetricValue,
    pub labels: HashMap<String, String>,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub metric_type: MetricType,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetricValue {
    Counter(u64),
    Gauge(f64),
    Histogram(Vec<f64>),
    Summary { sum: f64, count: u64 },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetricType {
    Counter,
    Gauge,
    Histogram,
    Summary,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Alert {
    pub alert_id: String,
    pub rule_name: String,
    pub severity: AlertSeverity,
    pub message: String,
    pub labels: HashMap<String, String>,
    pub started_at: chrono::DateTime<chrono::Utc>,
    pub resolved_at: Option<chrono::DateTime<chrono::Utc>>,
    pub status: AlertStatus,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertSeverity {
    Info,
    Warning,
    Critical,
    Emergency,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertStatus {
    Firing,
    Resolved,
    Suppressed,
}
```

## 3. 监控引擎

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use dashmap::DashMap;

pub struct MonitoringEngine {
    collectors: Vec<Box<dyn MetricsCollector>>,
    alert_rules: Arc<RwLock<Vec<AlertRule>>>,
    active_alerts: DashMap<String, Alert>,
    metrics_storage: MetricsStorage,
    notification_manager: NotificationManager,
    config: MonitoringConfig,
}

#[derive(Debug, Clone)]
pub struct MonitoringConfig {
    pub collection_interval: std::time::Duration,
    pub retention_period: std::time::Duration,
    pub alert_evaluation_interval: std::time::Duration,
    pub max_metrics_per_collection: usize,
}

impl MonitoringEngine {
    pub fn new(config: MonitoringConfig) -> Self {
        Self {
            collectors: Vec::new(),
            alert_rules: Arc::new(RwLock::new(Vec::new())),
            active_alerts: DashMap::new(),
            metrics_storage: MetricsStorage::new(),
            notification_manager: NotificationManager::new(),
            config,
        }
    }
    
    pub fn register_collector(&mut self, collector: Box<dyn MetricsCollector>) {
        self.collectors.push(collector);
    }
    
    pub async fn add_alert_rule(&self, rule: AlertRule) {
        let mut rules = self.alert_rules.write().await;
        rules.push(rule);
    }
    
    pub async fn start_monitoring(&self) {
        // 启动指标收集任务
        self.start_metrics_collection().await;
        
        // 启动告警评估任务
        self.start_alert_evaluation().await;
        
        // 启动数据清理任务
        self.start_cleanup_task().await;
    }
    
    async fn start_metrics_collection(&self) {
        let collectors = self.collectors.iter()
            .map(|c| c.as_ref() as &dyn MetricsCollector)
            .collect::<Vec<_>>();
        
        let storage = self.metrics_storage.clone();
        let interval = self.config.collection_interval;
        
        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);
            
            loop {
                interval_timer.tick().await;
                
                for collector in &collectors {
                    let metrics = collector.collect_metrics();
                    for metric in metrics {
                        if let Err(e) = storage.store_metric(metric).await {
                            eprintln!("Failed to store metric: {:?}", e);
                        }
                    }
                }
            }
        });
    }
    
    async fn start_alert_evaluation(&self) {
        let rules = self.alert_rules.clone();
        let storage = self.metrics_storage.clone();
        let alerts = self.active_alerts.clone();
        let notification_manager = self.notification_manager.clone();
        let interval = self.config.alert_evaluation_interval;
        
        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(interval);
            
            loop {
                interval_timer.tick().await;
                
                let rules_guard = rules.read().await;
                for rule in rules_guard.iter() {
                    match Self::evaluate_alert_rule(rule, &storage).await {
                        Ok(Some(alert)) => {
                            let alert_id = alert.alert_id.clone();
                            
                            // 检查是否是新告警
                            if !alerts.contains_key(&alert_id) {
                                alerts.insert(alert_id.clone(), alert.clone());
                                notification_manager.send_alert_notification(&alert).await;
                            }
                        }
                        Ok(None) => {
                            // 检查是否有需要解决的告警
                            if let Some(mut existing_alert) = alerts.get_mut(&rule.rule_id) {
                                if existing_alert.status == AlertStatus::Firing {
                                    existing_alert.status = AlertStatus::Resolved;
                                    existing_alert.resolved_at = Some(chrono::Utc::now());
                                    notification_manager.send_resolution_notification(&existing_alert).await;
                                }
                            }
                        }
                        Err(e) => {
                            eprintln!("Failed to evaluate alert rule {}: {:?}", rule.rule_id, e);
                        }
                    }
                }
            }
        });
    }
    
    async fn evaluate_alert_rule(rule: &AlertRule, storage: &MetricsStorage) -> Result<Option<Alert>, MonitoringError> {
        // 从存储中获取相关指标
        let query_result = storage.query_metrics(&rule.query, rule.evaluation_window).await?;
        
        // 评估条件
        let condition_met = rule.condition.evaluate(&query_result)?;
        
        if condition_met {
            let alert = Alert {
                alert_id: format!("{}_{}", rule.rule_id, chrono::Utc::now().timestamp()),
                rule_name: rule.rule_id.clone(),
                severity: rule.severity.clone(),
                message: rule.format_message(&query_result),
                labels: rule.labels.clone(),
                started_at: chrono::Utc::now(),
                resolved_at: None,
                status: AlertStatus::Firing,
            };
            
            Ok(Some(alert))
        } else {
            Ok(None)
        }
    }
    
    async fn start_cleanup_task(&self) {
        let storage = self.metrics_storage.clone();
        let retention_period = self.config.retention_period;
        
        tokio::spawn(async move {
            let mut interval_timer = tokio::time::interval(std::time::Duration::from_hours(1));
            
            loop {
                interval_timer.tick().await;
                
                let cutoff_time = chrono::Utc::now() - chrono::Duration::from_std(retention_period).unwrap();
                if let Err(e) = storage.cleanup_old_metrics(cutoff_time).await {
                    eprintln!("Failed to cleanup old metrics: {:?}", e);
                }
            }
        });
    }
    
    pub async fn get_metrics(&self, query: &str, time_range: TimeRange) -> Result<Vec<Metric>, MonitoringError> {
        self.metrics_storage.query_metrics(query, time_range).await
    }
    
    pub fn get_active_alerts(&self) -> Vec<Alert> {
        self.active_alerts.iter().map(|entry| entry.value().clone()).collect()
    }
}

#[derive(Debug)]
pub enum MonitoringError {
    CollectionError(String),
    StorageError(String),
    QueryError(String),
    EvaluationError(String),
}
```

## 4. 告警规则引擎

```rust
#[derive(Debug, Clone)]
pub struct AlertRule {
    pub rule_id: String,
    pub name: String,
    pub query: String,
    pub condition: AlertCondition,
    pub severity: AlertSeverity,
    pub labels: HashMap<String, String>,
    pub evaluation_window: TimeRange,
    pub for_duration: std::time::Duration,
    pub enabled: bool,
}

#[derive(Debug, Clone)]
pub enum AlertCondition {
    Threshold { operator: ThresholdOperator, value: f64 },
    Range { min: Option<f64>, max: Option<f64> },
    Rate { threshold: f64, window: std::time::Duration },
    Anomaly { sensitivity: f64 },
    Custom(String),
}

#[derive(Debug, Clone)]
pub enum ThresholdOperator {
    GreaterThan,
    LessThan,
    Equal,
    NotEqual,
    GreaterThanOrEqual,
    LessThanOrEqual,
}

impl AlertCondition {
    pub fn evaluate(&self, metrics: &[Metric]) -> Result<bool, MonitoringError> {
        match self {
            AlertCondition::Threshold { operator, value } => {
                self.evaluate_threshold(metrics, operator, *value)
            }
            AlertCondition::Range { min, max } => {
                self.evaluate_range(metrics, *min, *max)
            }
            AlertCondition::Rate { threshold, window } => {
                self.evaluate_rate(metrics, *threshold, *window)
            }
            AlertCondition::Anomaly { sensitivity } => {
                self.evaluate_anomaly(metrics, *sensitivity)
            }
            AlertCondition::Custom(_expr) => {
                // 自定义表达式评估
                Ok(false)
            }
        }
    }
    
    fn evaluate_threshold(&self, metrics: &[Metric], operator: &ThresholdOperator, threshold: f64) -> Result<bool, MonitoringError> {
        if metrics.is_empty() {
            return Ok(false);
        }
        
        // 使用最新的指标值
        let latest_metric = &metrics[metrics.len() - 1];
        let current_value = match &latest_metric.value {
            MetricValue::Gauge(v) => *v,
            MetricValue::Counter(v) => *v as f64,
            MetricValue::Summary { sum, count } => {
                if *count > 0 {
                    sum / (*count as f64)
                } else {
                    0.0
                }
            }
            MetricValue::Histogram(values) => {
                if values.is_empty() {
                    0.0
                } else {
                    values.iter().sum::<f64>() / values.len() as f64
                }
            }
        };
        
        let result = match operator {
            ThresholdOperator::GreaterThan => current_value > threshold,
            ThresholdOperator::LessThan => current_value < threshold,
            ThresholdOperator::Equal => (current_value - threshold).abs() < f64::EPSILON,
            ThresholdOperator::NotEqual => (current_value - threshold).abs() >= f64::EPSILON,
            ThresholdOperator::GreaterThanOrEqual => current_value >= threshold,
            ThresholdOperator::LessThanOrEqual => current_value <= threshold,
        };
        
        Ok(result)
    }
    
    fn evaluate_range(&self, metrics: &[Metric], min: Option<f64>, max: Option<f64>) -> Result<bool, MonitoringError> {
        if metrics.is_empty() {
            return Ok(false);
        }
        
        let latest_metric = &metrics[metrics.len() - 1];
        let current_value = match &latest_metric.value {
            MetricValue::Gauge(v) => *v,
            MetricValue::Counter(v) => *v as f64,
            _ => return Ok(false),
        };
        
        let below_min = min.map_or(false, |min_val| current_value < min_val);
        let above_max = max.map_or(false, |max_val| current_value > max_val);
        
        Ok(below_min || above_max)
    }
    
    fn evaluate_rate(&self, metrics: &[Metric], threshold: f64, window: std::time::Duration) -> Result<bool, MonitoringError> {
        if metrics.len() < 2 {
            return Ok(false);
        }
        
        let window_start = chrono::Utc::now() - chrono::Duration::from_std(window).unwrap();
        let recent_metrics: Vec<_> = metrics.iter()
            .filter(|m| m.timestamp > window_start)
            .collect();
        
        if recent_metrics.len() < 2 {
            return Ok(false);
        }
        
        // 计算变化率
        let first = &recent_metrics[0];
        let last = &recent_metrics[recent_metrics.len() - 1];
        
        let first_value = match &first.value {
            MetricValue::Counter(v) => *v as f64,
            MetricValue::Gauge(v) => *v,
            _ => return Ok(false),
        };
        
        let last_value = match &last.value {
            MetricValue::Counter(v) => *v as f64,
            MetricValue::Gauge(v) => *v,
            _ => return Ok(false),
        };
        
        let time_diff = last.timestamp.signed_duration_since(first.timestamp).num_seconds() as f64;
        if time_diff <= 0.0 {
            return Ok(false);
        }
        
        let rate = (last_value - first_value) / time_diff;
        Ok(rate > threshold)
    }
    
    fn evaluate_anomaly(&self, metrics: &[Metric], sensitivity: f64) -> Result<bool, MonitoringError> {
        if metrics.len() < 10 {
            return Ok(false);
        }
        
        // 简单的异常检测：基于标准差
        let values: Vec<f64> = metrics.iter()
            .filter_map(|m| match &m.value {
                MetricValue::Gauge(v) => Some(*v),
                MetricValue::Counter(v) => Some(*v as f64),
                _ => None,
            })
            .collect();
        
        if values.len() < 10 {
            return Ok(false);
        }
        
        let mean = values.iter().sum::<f64>() / values.len() as f64;
        let variance = values.iter()
            .map(|v| (v - mean).powi(2))
            .sum::<f64>() / values.len() as f64;
        let std_dev = variance.sqrt();
        
        let latest_value = values[values.len() - 1];
        let z_score = (latest_value - mean).abs() / std_dev;
        
        Ok(z_score > sensitivity)
    }
}

impl AlertRule {
    pub fn format_message(&self, metrics: &[Metric]) -> String {
        if metrics.is_empty() {
            return format!("Alert {} triggered with no metrics", self.name);
        }
        
        let latest_metric = &metrics[metrics.len() - 1];
        format!("Alert {} triggered: {} = {:?}", 
            self.name, 
            latest_metric.name, 
            latest_metric.value)
    }
}

#[derive(Debug, Clone)]
pub struct TimeRange {
    pub start: chrono::DateTime<chrono::Utc>,
    pub end: chrono::DateTime<chrono::Utc>,
}

impl TimeRange {
    pub fn last_minutes(minutes: i64) -> Self {
        let now = chrono::Utc::now();
        Self {
            start: now - chrono::Duration::minutes(minutes),
            end: now,
        }
    }
    
    pub fn last_hours(hours: i64) -> Self {
        let now = chrono::Utc::now();
        Self {
            start: now - chrono::Duration::hours(hours),
            end: now,
        }
    }
}
```

## 5. 指标存储

```rust
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Clone)]
pub struct MetricsStorage {
    memory_store: Arc<RwLock<Vec<Metric>>>,
    max_memory_size: usize,
}

impl MetricsStorage {
    pub fn new() -> Self {
        Self {
            memory_store: Arc::new(RwLock::new(Vec::new())),
            max_memory_size: 100000,
        }
    }
    
    pub async fn store_metric(&self, metric: Metric) -> Result<(), MonitoringError> {
        let mut store = self.memory_store.write().await;
        store.push(metric);
        
        // 保持存储大小在限制内
        if store.len() > self.max_memory_size {
            let remove_count = store.len() - self.max_memory_size;
            store.drain(0..remove_count);
        }
        
        Ok(())
    }
    
    pub async fn query_metrics(&self, query: &str, time_range: TimeRange) -> Result<Vec<Metric>, MonitoringError> {
        let store = self.memory_store.read().await;
        
        let filtered_metrics: Vec<Metric> = store.iter()
            .filter(|m| {
                m.timestamp >= time_range.start && 
                m.timestamp <= time_range.end &&
                self.matches_query(m, query)
            })
            .cloned()
            .collect();
        
        Ok(filtered_metrics)
    }
    
    pub async fn cleanup_old_metrics(&self, cutoff_time: chrono::DateTime<chrono::Utc>) -> Result<(), MonitoringError> {
        let mut store = self.memory_store.write().await;
        store.retain(|m| m.timestamp > cutoff_time);
        Ok(())
    }
    
    fn matches_query(&self, metric: &Metric, query: &str) -> bool {
        // 简化的查询匹配
        if query.is_empty() {
            return true;
        }
        
        // 支持简单的名称匹配
        metric.name.contains(query) || 
        metric.labels.values().any(|v| v.contains(query))
    }
    
    pub async fn get_metric_names(&self) -> Vec<String> {
        let store = self.memory_store.read().await;
        let mut names: Vec<String> = store.iter()
            .map(|m| m.name.clone())
            .collect();
        names.sort();
        names.dedup();
        names
    }
}
```

## 6. 通知管理器

```rust
#[derive(Clone)]
pub struct NotificationManager {
    channels: Vec<Box<dyn NotificationChannel>>,
    config: NotificationConfig,
}

#[derive(Debug, Clone)]
pub struct NotificationConfig {
    pub enabled: bool,
    pub rate_limit: std::time::Duration,
    pub escalation_rules: Vec<EscalationRule>,
}

#[derive(Debug, Clone)]
pub struct EscalationRule {
    pub severity: AlertSeverity,
    pub delay: std::time::Duration,
    pub channels: Vec<String>,
}

pub trait NotificationChannel: Send + Sync {
    fn send_notification(&self, alert: &Alert) -> Result<(), NotificationError>;
    fn get_channel_name(&self) -> String;
}

impl NotificationManager {
    pub fn new() -> Self {
        Self {
            channels: Vec::new(),
            config: NotificationConfig {
                enabled: true,
                rate_limit: std::time::Duration::from_minutes(5),
                escalation_rules: Vec::new(),
            },
        }
    }
    
    pub fn add_channel(&mut self, channel: Box<dyn NotificationChannel>) {
        self.channels.push(channel);
    }
    
    pub async fn send_alert_notification(&self, alert: &Alert) {
        if !self.config.enabled {
            return;
        }
        
        for channel in &self.channels {
            if let Err(e) = channel.send_notification(alert) {
                eprintln!("Failed to send notification via {}: {:?}", 
                    channel.get_channel_name(), e);
            }
        }
    }
    
    pub async fn send_resolution_notification(&self, alert: &Alert) {
        let mut resolution_alert = alert.clone();
        resolution_alert.message = format!("RESOLVED: {}", alert.message);
        
        self.send_alert_notification(&resolution_alert).await;
    }
}

pub struct EmailNotificationChannel {
    smtp_config: EmailConfig,
}

#[derive(Debug, Clone)]
pub struct EmailConfig {
    pub smtp_server: String,
    pub smtp_port: u16,
    pub username: String,
    pub password: String,
    pub from_email: String,
    pub to_emails: Vec<String>,
}

impl NotificationChannel for EmailNotificationChannel {
    fn send_notification(&self, alert: &Alert) -> Result<(), NotificationError> {
        println!("Sending email notification for alert: {}", alert.alert_id);
        // 实际实现会使用SMTP客户端发送邮件
        Ok(())
    }
    
    fn get_channel_name(&self) -> String {
        "email".to_string()
    }
}

pub struct SlackNotificationChannel {
    webhook_url: String,
}

impl SlackNotificationChannel {
    pub fn new(webhook_url: String) -> Self {
        Self { webhook_url }
    }
}

impl NotificationChannel for SlackNotificationChannel {
    fn send_notification(&self, alert: &Alert) -> Result<(), NotificationError> {
        println!("Sending Slack notification for alert: {}", alert.alert_id);
        // 实际实现会调用Slack Webhook
        Ok(())
    }
    
    fn get_channel_name(&self) -> String {
        "slack".to_string()
    }
}

#[derive(Debug)]
pub enum NotificationError {
    SendError(String),
    ConfigError(String),
    RateLimitExceeded,
}
```

## 7. 系统指标收集器

```rust
pub struct SystemMetricsCollector {
    hostname: String,
}

impl SystemMetricsCollector {
    pub fn new() -> Self {
        Self {
            hostname: hostname::get()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string(),
        }
    }
}

impl MetricsCollector for SystemMetricsCollector {
    fn collect_metrics(&self) -> Vec<Metric> {
        let mut metrics = Vec::new();
        let now = chrono::Utc::now();
        let mut labels = HashMap::new();
        labels.insert("hostname".to_string(), self.hostname.clone());
        
        // CPU使用率
        if let Ok(cpu_usage) = self.get_cpu_usage() {
            metrics.push(Metric {
                name: "system_cpu_usage_percent".to_string(),
                value: MetricValue::Gauge(cpu_usage),
                labels: labels.clone(),
                timestamp: now,
                metric_type: MetricType::Gauge,
            });
        }
        
        // 内存使用率
        if let Ok(memory_usage) = self.get_memory_usage() {
            metrics.push(Metric {
                name: "system_memory_usage_percent".to_string(),
                value: MetricValue::Gauge(memory_usage),
                labels: labels.clone(),
                timestamp: now,
                metric_type: MetricType::Gauge,
            });
        }
        
        // 磁盘使用率
        if let Ok(disk_usage) = self.get_disk_usage() {
            metrics.push(Metric {
                name: "system_disk_usage_percent".to_string(),
                value: MetricValue::Gauge(disk_usage),
                labels: labels.clone(),
                timestamp: now,
                metric_type: MetricType::Gauge,
            });
        }
        
        metrics
    }
    
    fn get_collector_name(&self) -> String {
        "system_metrics".to_string()
    }
}

impl SystemMetricsCollector {
    fn get_cpu_usage(&self) -> Result<f64, std::io::Error> {
        // 简化实现，实际应该读取 /proc/stat 或使用系统API
        Ok(rand::random::<f64>() * 100.0)
    }
    
    fn get_memory_usage(&self) -> Result<f64, std::io::Error> {
        // 简化实现，实际应该读取 /proc/meminfo
        Ok(rand::random::<f64>() * 100.0)
    }
    
    fn get_disk_usage(&self) -> Result<f64, std::io::Error> {
        // 简化实现，实际应该使用 statvfs 或类似API
        Ok(rand::random::<f64>() * 100.0)
    }
}
```

## 8. 测试框架

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_metrics_storage() {
        let storage = MetricsStorage::new();
        
        let metric = Metric {
            name: "test_metric".to_string(),
            value: MetricValue::Gauge(42.0),
            labels: HashMap::new(),
            timestamp: chrono::Utc::now(),
            metric_type: MetricType::Gauge,
        };
        
        storage.store_metric(metric).await.unwrap();
        
        let time_range = TimeRange::last_minutes(5);
        let results = storage.query_metrics("test_metric", time_range).await.unwrap();
        
        assert_eq!(results.len(), 1);
        assert_eq!(results[0].name, "test_metric");
    }
    
    #[test]
    fn test_alert_condition_threshold() {
        let condition = AlertCondition::Threshold {
            operator: ThresholdOperator::GreaterThan,
            value: 50.0,
        };
        
        let metric = Metric {
            name: "test".to_string(),
            value: MetricValue::Gauge(75.0),
            labels: HashMap::new(),
            timestamp: chrono::Utc::now(),
            metric_type: MetricType::Gauge,
        };
        
        let result = condition.evaluate(&[metric]).unwrap();
        assert!(result);
    }
    
    #[test]
    fn test_system_metrics_collector() {
        let collector = SystemMetricsCollector::new();
        let metrics = collector.collect_metrics();
        
        assert!(!metrics.is_empty());
        assert!(metrics.iter().any(|m| m.name.contains("cpu")));
        assert!(metrics.iter().any(|m| m.name.contains("memory")));
    }
}
```

这个实现提供了完整的监控告警系统，支持实时指标收集、智能告警和多渠道通知。 