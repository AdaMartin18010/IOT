# 数据备份恢复实现

## 目录

- [数据备份恢复实现](#数据备份恢复实现)
  - [目录](#目录)
  - [概述](#概述)
  - [核心架构](#核心架构)
  - [核心实现](#核心实现)
    - [1. 备份管理器](#1-备份管理器)
    - [2. 存储后端接口](#2-存储后端接口)
    - [3. 备份调度器](#3-备份调度器)
    - [4. 错误处理](#4-错误处理)
  - [配置管理](#配置管理)
  - [测试框架](#测试框架)
  - [部署配置](#部署配置)
    - [Docker](#docker)
  - [总结](#总结)

## 概述

IoT系统数据备份恢复机制确保关键数据的安全性和可恢复性，支持增量备份、全量备份和点对点恢复。

## 核心架构

```text
数据备份恢复系统
├── 备份策略模块
│   ├── 全量备份
│   ├── 增量备份
│   └── 差异备份
├── 存储管理模块
│   ├── 本地存储
│   ├── 云存储
│   └── 分布式存储
├── 压缩加密模块
│   ├── 数据压缩
│   ├── 数据加密
│   └── 完整性校验
└── 恢复管理模块
    ├── 数据恢复
    ├── 一致性检查
    └── 回滚机制
```

## 核心实现

### 1. 备份管理器

```rust
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::{Arc, RwLock};
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use serde::{Serialize, Deserialize};
use tokio::fs;
use tokio::io::{AsyncReadExt, AsyncWriteExt};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackupMetadata {
    pub id: String,
    pub backup_type: BackupType,
    pub timestamp: u64,
    pub size: u64,
    pub checksum: String,
    pub source_path: String,
    pub backup_path: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackupType {
    Full,
    Incremental,
    Differential,
}

pub struct BackupManager {
    config: BackupConfig,
    metadata_store: Arc<RwLock<HashMap<String, BackupMetadata>>>,
    storage_backends: HashMap<String, Box<dyn StorageBackend>>,
}

#[derive(Debug, Clone)]
pub struct BackupConfig {
    pub backup_directory: PathBuf,
    pub max_backups: usize,
    pub encryption_enabled: bool,
    pub encryption_key: Vec<u8>,
}

impl BackupManager {
    pub fn new(config: BackupConfig) -> Self {
        Self {
            config,
            metadata_store: Arc::new(RwLock::new(HashMap::new())),
            storage_backends: HashMap::new(),
        }
    }

    pub fn register_storage_backend(&mut self, name: String, backend: Box<dyn StorageBackend>) {
        self.storage_backends.insert(name, backend);
    }

    pub async fn create_backup(
        &self,
        source_path: &Path,
        backup_type: BackupType,
        storage_backend: &str,
    ) -> Result<String, BackupError> {
        let backup_id = self.generate_backup_id();
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();

        // 读取源数据
        let source_data = self.read_source_data(source_path).await?;
        
        // 压缩数据
        let compressed_data = self.compress_data(&source_data)?;
        
        // 加密数据
        let final_data = if self.config.encryption_enabled {
            self.encrypt_data(&compressed_data)?
        } else {
            compressed_data
        };

        // 计算校验和
        let checksum = self.calculate_checksum(&final_data);

        // 存储数据
        let backend = self.storage_backends.get(storage_backend)
            .ok_or(BackupError::StorageBackendNotFound)?;
        
        let backup_path = format!("backup_{}_{}.dat", backup_id, timestamp);
        backend.store(&backup_path, &final_data).await?;

        // 保存元数据
        let metadata = BackupMetadata {
            id: backup_id.clone(),
            backup_type,
            timestamp,
            size: final_data.len() as u64,
            checksum,
            source_path: source_path.to_string_lossy().to_string(),
            backup_path,
        };

        {
            let mut store = self.metadata_store.write().unwrap();
            store.insert(backup_id.clone(), metadata);
        }

        self.cleanup_old_backups().await?;

        Ok(backup_id)
    }

    pub async fn restore_backup(&self, backup_id: &str, target_path: &Path) -> Result<(), BackupError> {
        let metadata = {
            let store = self.metadata_store.read().unwrap();
            store.get(backup_id).cloned()
                .ok_or(BackupError::BackupNotFound)?
        };

        let backend = self.storage_backends.values().next()
            .ok_or(BackupError::StorageBackendNotFound)?;
        
        let encrypted_data = backend.retrieve(&metadata.backup_path).await?;

        // 验证校验和
        let calculated_checksum = self.calculate_checksum(&encrypted_data);
        if calculated_checksum != metadata.checksum {
            return Err(BackupError::ChecksumMismatch);
        }

        // 解密数据
        let compressed_data = if self.config.encryption_enabled {
            self.decrypt_data(&encrypted_data)?
        } else {
            encrypted_data
        };

        // 解压数据
        let restored_data = self.decompress_data(&compressed_data)?;

        // 写入目标路径
        self.write_restored_data(target_path, &restored_data).await?;

        Ok(())
    }

    async fn read_source_data(&self, source_path: &Path) -> Result<Vec<u8>, BackupError> {
        let mut file = fs::File::open(source_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        let mut data = Vec::new();
        file.read_to_end(&mut data).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        Ok(data)
    }

    fn compress_data(&self, data: &[u8]) -> Result<Vec<u8>, BackupError> {
        use flate2::write::GzEncoder;
        use flate2::Compression;
        use std::io::Write;

        let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
        encoder.write_all(data)
            .map_err(|e| BackupError::CompressionError(e.to_string()))?;
        encoder.finish()
            .map_err(|e| BackupError::CompressionError(e.to_string()))
    }

    fn decompress_data(&self, data: &[u8]) -> Result<Vec<u8>, BackupError> {
        use flate2::read::GzDecoder;
        use std::io::Read;

        let mut decoder = GzDecoder::new(data);
        let mut decompressed = Vec::new();
        decoder.read_to_end(&mut decompressed)
            .map_err(|e| BackupError::DecompressionError(e.to_string()))?;
        Ok(decompressed)
    }

    fn encrypt_data(&self, data: &[u8]) -> Result<Vec<u8>, BackupError> {
        use aes_gcm::{Aes256Gcm, Key, Nonce, Aead, KeyInit};
        use rand::{rngs::OsRng, RngCore};

        let key = Key::<Aes256Gcm>::from_slice(&self.config.encryption_key);
        let cipher = Aes256Gcm::new(key);

        let mut nonce_bytes = [0u8; 12];
        OsRng.fill_bytes(&mut nonce_bytes);
        let nonce = Nonce::from_slice(&nonce_bytes);

        let ciphertext = cipher.encrypt(nonce, data)
            .map_err(|_| BackupError::EncryptionError("Encryption failed".to_string()))?;

        let mut result = nonce_bytes.to_vec();
        result.extend_from_slice(&ciphertext);
        Ok(result)
    }

    fn decrypt_data(&self, data: &[u8]) -> Result<Vec<u8>, BackupError> {
        use aes_gcm::{Aes256Gcm, Key, Nonce, Aead, KeyInit};

        if data.len() < 12 {
            return Err(BackupError::DecryptionError("Invalid encrypted data".to_string()));
        }

        let key = Key::<Aes256Gcm>::from_slice(&self.config.encryption_key);
        let cipher = Aes256Gcm::new(key);

        let nonce = Nonce::from_slice(&data[0..12]);
        let ciphertext = &data[12..];

        cipher.decrypt(nonce, ciphertext)
            .map_err(|_| BackupError::DecryptionError("Decryption failed".to_string()))
    }

    fn calculate_checksum(&self, data: &[u8]) -> String {
        use sha2::{Sha256, Digest};
        let mut hasher = Sha256::new();
        hasher.update(data);
        format!("{:x}", hasher.finalize())
    }

    async fn write_restored_data(&self, target_path: &Path, data: &[u8]) -> Result<(), BackupError> {
        let mut file = fs::File::create(target_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        file.write_all(data).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        Ok(())
    }

    fn generate_backup_id(&self) -> String {
        use uuid::Uuid;
        Uuid::new_v4().to_string()
    }

    async fn cleanup_old_backups(&self) -> Result<(), BackupError> {
        let mut store = self.metadata_store.write().unwrap();
        
        if store.len() <= self.config.max_backups {
            return Ok();
        }

        let mut backups: Vec<_> = store.values().cloned().collect();
        backups.sort_by_key(|b| b.timestamp);

        let to_remove = backups.len() - self.config.max_backups;
        for backup in backups.iter().take(to_remove) {
            for backend in self.storage_backends.values() {
                let _ = backend.delete(&backup.backup_path).await;
            }
            
            store.remove(&backup.id);
        }

        Ok(())
    }

    pub fn list_backups(&self) -> Vec<BackupMetadata> {
        let store = self.metadata_store.read().unwrap();
        store.values().cloned().collect()
    }
}
```

### 2. 存储后端接口

```rust
use async_trait::async_trait;

#[async_trait]
pub trait StorageBackend: Send + Sync {
    async fn store(&self, path: &str, data: &[u8]) -> Result<(), BackupError>;
    async fn retrieve(&self, path: &str) -> Result<Vec<u8>, BackupError>;
    async fn delete(&self, path: &str) -> Result<(), BackupError>;
    async fn list(&self) -> Result<Vec<String>, BackupError>;
}

pub struct LocalStorageBackend {
    base_path: PathBuf,
}

impl LocalStorageBackend {
    pub fn new(base_path: PathBuf) -> Self {
        Self { base_path }
    }
}

#[async_trait]
impl StorageBackend for LocalStorageBackend {
    async fn store(&self, path: &str, data: &[u8]) -> Result<(), BackupError> {
        let full_path = self.base_path.join(path);
        
        if let Some(parent) = full_path.parent() {
            fs::create_dir_all(parent).await
                .map_err(|e| BackupError::IoError(e.to_string()))?;
        }

        let mut file = fs::File::create(full_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        file.write_all(data).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        Ok(())
    }

    async fn retrieve(&self, path: &str) -> Result<Vec<u8>, BackupError> {
        let full_path = self.base_path.join(path);
        
        let mut file = fs::File::open(full_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        let mut data = Vec::new();
        file.read_to_end(&mut data).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        Ok(data)
    }

    async fn delete(&self, path: &str) -> Result<(), BackupError> {
        let full_path = self.base_path.join(path);
        
        fs::remove_file(full_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        Ok(())
    }

    async fn list(&self) -> Result<Vec<String>, BackupError> {
        let mut entries = fs::read_dir(&self.base_path).await
            .map_err(|e| BackupError::IoError(e.to_string()))?;
        
        let mut files = Vec::new();
        
        while let Some(entry) = entries.next_entry().await
            .map_err(|e| BackupError::IoError(e.to_string()))? {
            
            if entry.file_type().await
                .map_err(|e| BackupError::IoError(e.to_string()))?
                .is_file() {
                files.push(entry.file_name().to_string_lossy().to_string());
            }
        }
        
        Ok(files)
    }
}
```

### 3. 备份调度器

```rust
use tokio::time::{interval, Duration};

pub struct BackupScheduler {
    backup_manager: Arc<BackupManager>,
    schedule_config: ScheduleConfig,
}

#[derive(Debug, Clone)]
pub struct ScheduleConfig {
    pub full_backup_interval: Duration,
    pub incremental_backup_interval: Duration,
    pub backup_sources: Vec<PathBuf>,
    pub storage_backend: String,
}

impl BackupScheduler {
    pub fn new(backup_manager: Arc<BackupManager>, schedule_config: ScheduleConfig) -> Self {
        Self {
            backup_manager,
            schedule_config,
        }
    }

    pub async fn start(&self) {
        let backup_manager = self.backup_manager.clone();
        let config = self.schedule_config.clone();

        tokio::spawn(async move {
            let mut interval = interval(config.full_backup_interval);
            
            loop {
                interval.tick().await;
                
                for source in &config.backup_sources {
                    match backup_manager.create_backup(
                        source,
                        BackupType::Full,
                        &config.storage_backend,
                    ).await {
                        Ok(backup_id) => {
                            println!("Full backup created: {} for {:?}", backup_id, source);
                        }
                        Err(e) => {
                            eprintln!("Full backup failed for {:?}: {:?}", source, e);
                        }
                    }
                }
            }
        });
    }
}
```

### 4. 错误处理

```rust
#[derive(Debug, thiserror::Error)]
pub enum BackupError {
    #[error("IO error: {0}")]
    IoError(String),
    #[error("Compression error: {0}")]
    CompressionError(String),
    #[error("Decompression error: {0}")]
    DecompressionError(String),
    #[error("Encryption error: {0}")]
    EncryptionError(String),
    #[error("Decryption error: {0}")]
    DecryptionError(String),
    #[error("Backup not found")]
    BackupNotFound,
    #[error("Storage backend not found")]
    StorageBackendNotFound,
    #[error("Checksum mismatch")]
    ChecksumMismatch,
}
```

## 配置管理

```toml
[backup]
backup_directory = "/var/backups/iot"
max_backups = 30
encryption_enabled = true
encryption_key_file = "/etc/iot/backup.key"

[schedule]
full_backup_interval_hours = 24
incremental_backup_interval_hours = 4
backup_sources = [
    "/var/lib/iot/data",
    "/etc/iot/config"
]

[storage.local]
enabled = true
base_path = "/var/backups/iot/local"
```

## 测试框架

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_backup_and_restore() {
        let temp_dir = TempDir::new().unwrap();
        let backup_dir = temp_dir.path().join("backups");
        
        let config = BackupConfig {
            backup_directory: backup_dir.clone(),
            max_backups: 10,
            encryption_enabled: false,
            encryption_key: vec![0u8; 32],
        };

        let mut backup_manager = BackupManager::new(config);
        backup_manager.register_storage_backend(
            "local".to_string(),
            Box::new(LocalStorageBackend::new(backup_dir)),
        );

        let test_file = temp_dir.path().join("test.txt");
        tokio::fs::write(&test_file, b"Hello, World!").await.unwrap();

        let backup_id = backup_manager
            .create_backup(&test_file, BackupType::Full, "local")
            .await
            .unwrap();

        let restore_file = temp_dir.path().join("restored.txt");
        backup_manager
            .restore_backup(&backup_id, &restore_file)
            .await
            .unwrap();

        let restored_data = tokio::fs::read(&restore_file).await.unwrap();
        assert_eq!(restored_data, b"Hello, World!");
    }
}
```

## 部署配置

### Docker

```dockerfile
FROM rust:1.70-alpine AS builder
WORKDIR /app
COPY . .
RUN apk add --no-cache openssl-dev
RUN cargo build --release

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /app/target/release/backup_system ./
COPY config/backup.toml ./config/
VOLUME ["/var/backups", "/var/lib/iot"]
CMD ["./backup_system"]
```

## 总结

本数据备份恢复实现提供了完整的备份策略管理、多种存储后端支持、数据压缩加密和自动化调度功能，确保IoT系统数据的安全性和可恢复性。
