# IoT语义互操作备份恢复系统实现

## 1. 系统架构概述

### 1.1 核心组件架构

```mermaid
graph TB
    subgraph "备份源"
        DB[(PostgreSQL)]
        CONFIG[配置文件]
        SEMANTIC[语义模型]
        RULES[推理规则]
    end
    
    subgraph "备份系统"
        SCHEDULER[备份调度器]
        EXECUTOR[执行引擎]
        COMPRESS[压缩模块]
        ENCRYPT[加密模块]
    end
    
    subgraph "存储系统"
        LOCAL[本地存储]
        S3[S3兼容存储]
        NFS[网络存储]
    end
    
    subgraph "恢复系统"
        RESTORE[恢复服务]
        VERIFY[验证模块]
        MONITOR[监控模块]
    end
    
    DB --> SCHEDULER
    CONFIG --> SCHEDULER
    SEMANTIC --> SCHEDULER
    RULES --> SCHEDULER
    
    SCHEDULER --> EXECUTOR
    EXECUTOR --> COMPRESS
    COMPRESS --> ENCRYPT
    ENCRYPT --> LOCAL
    ENCRYPT --> S3
    ENCRYPT --> NFS
    
    LOCAL --> RESTORE
    S3 --> RESTORE
    NFS --> RESTORE
    RESTORE --> VERIFY
    RESTORE --> MONITOR
```

## 2. 核心数据结构

### 2.1 备份任务定义

```rust
// src/backup/types.rs
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use chrono::{DateTime, Utc};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackupJob {
    pub id: Uuid,
    pub name: String,
    pub backup_type: BackupType,
    pub source: DataSource,
    pub schedule: String, // Cron表达式
    pub retention_days: u32,
    pub compression_enabled: bool,
    pub encryption_enabled: bool,
    pub storage_targets: Vec<StorageTarget>,
    pub enabled: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackupType {
    Full,
    Incremental,
    Differential,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataSource {
    pub source_type: SourceType,
    pub connection_string: String,
    pub include_patterns: Vec<String>,
    pub exclude_patterns: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SourceType {
    PostgreSQL,
    FileSystem,
    ConfigStore,
    SemanticModel,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageTarget {
    pub id: Uuid,
    pub name: String,
    pub storage_type: StorageType,
    pub endpoint: String,
    pub bucket: Option<String>,
    pub path: String,
    pub credentials: HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StorageType {
    LocalFS,
    S3,
    NFS,
    SFTP,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackupRecord {
    pub id: Uuid,
    pub job_id: Uuid,
    pub backup_type: BackupType,
    pub started_at: DateTime<Utc>,
    pub completed_at: Option<DateTime<Utc>>,
    pub status: BackupStatus,
    pub size_bytes: u64,
    pub compressed_size_bytes: u64,
    pub checksum: String,
    pub storage_locations: Vec<String>,
    pub error_message: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackupStatus {
    Running,
    Completed,
    Failed,
    Cancelled,
}
```

## 3. 备份调度器实现

### 3.1 主调度器

```rust
// src/backup/scheduler.rs
use tokio_cron_scheduler::{JobScheduler, Job};
use std::sync::Arc;
use tokio::sync::RwLock;
use std::collections::HashMap;

pub struct BackupScheduler {
    scheduler: JobScheduler,
    jobs: Arc<RwLock<HashMap<Uuid, BackupJob>>>,
    storage: Arc<dyn BackupStorage>,
}

impl BackupScheduler {
    pub async fn new(storage: Arc<dyn BackupStorage>) -> Result<Self, Box<dyn std::error::Error>> {
        let scheduler = JobScheduler::new().await?;
        
        Ok(Self {
            scheduler,
            jobs: Arc::new(RwLock::new(HashMap::new())),
            storage,
        })
    }
    
    pub async fn start(&self) -> Result<(), Box<dyn std::error::Error>> {
        self.scheduler.start().await?;
        println!("备份调度器已启动");
        Ok(())
    }
    
    pub async fn add_backup_job(&self, job: BackupJob) -> Result<(), Box<dyn std::error::Error>> {
        let job_id = job.id;
        let schedule = job.schedule.clone();
        
        // 创建调度任务
        let storage_clone = Arc::clone(&self.storage);
        let job_clone = job.clone();
        
        let cron_job = Job::new_async(schedule.as_str(), move |_uuid, _l| {
            let storage = Arc::clone(&storage_clone);
            let job = job_clone.clone();
            
            Box::pin(async move {
                if let Err(e) = Self::execute_backup(job, storage).await {
                    eprintln!("备份执行失败: {}", e);
                }
            })
        })?;
        
        self.scheduler.add(cron_job).await?;
        self.jobs.write().await.insert(job_id, job);
        
        println!("备份任务已添加: {}", job_id);
        Ok(())
    }
    
    async fn execute_backup(
        job: BackupJob,
        storage: Arc<dyn BackupStorage>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        println!("开始执行备份任务: {}", job.name);
        
        let mut record = BackupRecord {
            id: Uuid::new_v4(),
            job_id: job.id,
            backup_type: job.backup_type.clone(),
            started_at: Utc::now(),
            completed_at: None,
            status: BackupStatus::Running,
            size_bytes: 0,
            compressed_size_bytes: 0,
            checksum: String::new(),
            storage_locations: Vec::new(),
            error_message: None,
        };
        
        // 根据源类型选择执行器
        let result = match job.source.source_type {
            SourceType::PostgreSQL => {
                PostgreSQLBackupExecutor::new().execute(&job, &mut record).await
            }
            SourceType::FileSystem => {
                FileSystemBackupExecutor::new().execute(&job, &mut record).await
            }
            SourceType::ConfigStore => {
                ConfigBackupExecutor::new().execute(&job, &mut record).await
            }
            SourceType::SemanticModel => {
                SemanticModelBackupExecutor::new().execute(&job, &mut record).await
            }
        };
        
        match result {
            Ok(_) => {
                record.status = BackupStatus::Completed;
                record.completed_at = Some(Utc::now());
                println!("备份完成: {}", job.name);
            }
            Err(e) => {
                record.status = BackupStatus::Failed;
                record.error_message = Some(e.to_string());
                record.completed_at = Some(Utc::now());
                eprintln!("备份失败: {}", e);
            }
        }
        
        // 保存备份记录
        storage.save_backup_record(&record).await?;
        
        Ok(())
    }
}
```

## 4. PostgreSQL备份执行器

### 4.1 数据库备份实现

```rust
// src/backup/executors/postgresql.rs
use std::process::Command;
use tokio::fs;
use sha2::{Sha256, Digest};

pub struct PostgreSQLBackupExecutor;

impl PostgreSQLBackupExecutor {
    pub fn new() -> Self {
        Self
    }
    
    pub async fn execute(&self, job: &BackupJob, record: &mut BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        match job.backup_type {
            BackupType::Full => self.full_backup(job, record).await,
            BackupType::Incremental => self.incremental_backup(job, record).await,
            BackupType::Differential => self.differential_backup(job, record).await,
        }
    }
    
    async fn full_backup(&self, job: &BackupJob, record: &mut BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        let backup_filename = format!(
            "postgresql_full_{}_{}.sql",
            job.name,
            record.started_at.format("%Y%m%d_%H%M%S")
        );
        let backup_path = format!("/tmp/backups/{}", backup_filename);
        
        // 确保备份目录存在
        fs::create_dir_all("/tmp/backups").await?;
        
        // 解析数据库连接信息
        let db_info = self.parse_connection_string(&job.source.connection_string)?;
        
        // 执行pg_dump
        let output = Command::new("pg_dump")
            .args(&[
                "--host", &db_info.host,
                "--port", &db_info.port,
                "--username", &db_info.username,
                "--dbname", &db_info.database,
                "--format", "custom",
                "--compress", "9",
                "--file", &backup_path,
                "--verbose",
            ])
            .env("PGPASSWORD", &db_info.password)
            .output()?;
        
        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(format!("pg_dump失败: {}", stderr).into());
        }
        
        // 获取文件信息
        let metadata = fs::metadata(&backup_path).await?;
        record.size_bytes = metadata.len();
        
        // 计算校验和
        let content = fs::read(&backup_path).await?;
        let mut hasher = Sha256::new();
        hasher.update(&content);
        record.checksum = format!("{:x}", hasher.finalize());
        
        // 压缩（如果启用）
        let final_path = if job.compression_enabled {
            self.compress_file(&backup_path).await?
        } else {
            backup_path
        };
        
        // 加密（如果启用）
        let encrypted_path = if job.encryption_enabled {
            self.encrypt_file(&final_path).await?
        } else {
            final_path
        };
        
        // 上传到存储目标
        for target in &job.storage_targets {
            let location = self.upload_to_storage(&encrypted_path, target).await?;
            record.storage_locations.push(location);
        }
        
        // 清理临时文件
        fs::remove_file(&encrypted_path).await?;
        
        println!("PostgreSQL全量备份完成");
        Ok(())
    }
    
    async fn incremental_backup(&self, job: &BackupJob, record: &mut BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 增量备份实现（基于WAL文件）
        println!("执行PostgreSQL增量备份");
        
        // 获取WAL文件路径
        let wal_path = self.get_wal_files_since_last_backup(job.id).await?;
        
        let backup_filename = format!(
            "postgresql_incremental_{}_{}.tar.gz",
            job.name,
            record.started_at.format("%Y%m%d_%H%M%S")
        );
        let backup_path = format!("/tmp/backups/{}", backup_filename);
        
        // 创建WAL文件归档
        self.create_wal_archive(&wal_path, &backup_path).await?;
        
        // 更新记录信息
        let metadata = fs::metadata(&backup_path).await?;
        record.size_bytes = metadata.len();
        
        println!("PostgreSQL增量备份完成");
        Ok(())
    }
    
    async fn differential_backup(&self, job: &BackupJob, record: &mut BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 差异备份实现
        println!("执行PostgreSQL差异备份");
        
        // 简化实现，实际上差异备份需要更复杂的逻辑
        self.full_backup(job, record).await
    }
    
    fn parse_connection_string(&self, conn_str: &str) -> Result<DatabaseInfo, Box<dyn std::error::Error>> {
        // 解析 postgresql://username:password@host:port/database
        let url = url::Url::parse(conn_str)?;
        
        Ok(DatabaseInfo {
            host: url.host_str().unwrap_or("localhost").to_string(),
            port: url.port().unwrap_or(5432).to_string(),
            username: url.username().to_string(),
            password: url.password().unwrap_or("").to_string(),
            database: url.path().trim_start_matches('/').to_string(),
        })
    }
    
    async fn compress_file(&self, file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let compressed_path = format!("{}.gz", file_path);
        
        let output = Command::new("gzip")
            .args(&["-9", file_path])
            .output()?;
        
        if !output.status.success() {
            return Err("压缩失败".into());
        }
        
        Ok(compressed_path)
    }
    
    async fn encrypt_file(&self, file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let encrypted_path = format!("{}.enc", file_path);
        
        let output = Command::new("openssl")
            .args(&[
                "enc",
                "-aes-256-cbc",
                "-in", file_path,
                "-out", &encrypted_path,
                "-k", "backup_encryption_key", // 应该从配置获取
            ])
            .output()?;
        
        if !output.status.success() {
            return Err("加密失败".into());
        }
        
        // 删除原文件
        fs::remove_file(file_path).await?;
        
        Ok(encrypted_path)
    }
    
    async fn upload_to_storage(&self, file_path: &str, target: &StorageTarget) -> Result<String, Box<dyn std::error::Error>> {
        match target.storage_type {
            StorageType::LocalFS => {
                self.upload_to_local_fs(file_path, target).await
            }
            StorageType::S3 => {
                self.upload_to_s3(file_path, target).await
            }
            _ => {
                Err("不支持的存储类型".into())
            }
        }
    }
    
    async fn upload_to_local_fs(&self, file_path: &str, target: &StorageTarget) -> Result<String, Box<dyn std::error::Error>> {
        let filename = std::path::Path::new(file_path)
            .file_name()
            .and_then(|n| n.to_str())
            .ok_or("无效的文件名")?;
        
        let dest_path = format!("{}/{}", target.path, filename);
        
        // 确保目标目录存在
        if let Some(parent) = std::path::Path::new(&dest_path).parent() {
            fs::create_dir_all(parent).await?;
        }
        
        // 复制文件
        fs::copy(file_path, &dest_path).await?;
        
        println!("文件已上传到本地存储: {}", dest_path);
        Ok(dest_path)
    }
    
    async fn upload_to_s3(&self, file_path: &str, target: &StorageTarget) -> Result<String, Box<dyn std::error::Error>> {
        // S3上传实现（简化版）
        let filename = std::path::Path::new(file_path)
            .file_name()
            .and_then(|n| n.to_str())
            .ok_or("无效的文件名")?;
        
        let s3_key = format!("{}/{}", target.path, filename);
        
        // 这里应该使用AWS SDK进行真实的S3上传
        // 目前只是模拟
        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
        
        println!("文件已上传到S3: {}", s3_key);
        Ok(s3_key)
    }
    
    async fn get_wal_files_since_last_backup(&self, _job_id: Uuid) -> Result<Vec<String>, Box<dyn std::error::Error>> {
        // 获取自上次备份以来的WAL文件列表
        // 这里返回模拟数据
        Ok(vec![
            "/var/lib/postgresql/wal_archive/000000010000000000000001".to_string(),
            "/var/lib/postgresql/wal_archive/000000010000000000000002".to_string(),
        ])
    }
    
    async fn create_wal_archive(&self, wal_files: &[String], output_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 创建WAL文件归档
        let mut tar_args = vec!["czf".to_string(), output_path.to_string()];
        tar_args.extend(wal_files.iter().cloned());
        
        let output = Command::new("tar")
            .args(&tar_args)
            .output()?;
        
        if !output.status.success() {
            return Err("WAL归档创建失败".into());
        }
        
        Ok(())
    }
}

struct DatabaseInfo {
    host: String,
    port: String,
    username: String,
    password: String,
    database: String,
}
```

## 5. 恢复服务实现

### 5.1 数据恢复服务

```rust
// src/backup/restore.rs
use std::process::Command;
use tokio::fs;

pub struct RestoreService {
    storage: Arc<dyn BackupStorage>,
}

impl RestoreService {
    pub fn new(storage: Arc<dyn BackupStorage>) -> Self {
        Self { storage }
    }
    
    pub async fn restore_database(
        &self,
        backup_id: Uuid,
        target_db: &str,
        point_in_time: Option<DateTime<Utc>>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        println!("开始数据库恢复...");
        
        // 获取备份记录
        let backup_record = self.storage.get_backup_record(backup_id).await?;
        
        // 下载备份文件
        let local_path = self.download_backup(&backup_record).await?;
        
        // 解密（如果需要）
        let decrypted_path = if local_path.ends_with(".enc") {
            self.decrypt_file(&local_path).await?
        } else {
            local_path
        };
        
        // 解压缩（如果需要）
        let final_path = if decrypted_path.ends_with(".gz") {
            self.decompress_file(&decrypted_path).await?
        } else {
            decrypted_path
        };
        
        // 执行恢复
        match backup_record.backup_type {
            BackupType::Full => {
                self.restore_full_backup(&final_path, target_db).await?;
            }
            BackupType::Incremental | BackupType::Differential => {
                if let Some(pit) = point_in_time {
                    self.restore_point_in_time(&final_path, target_db, pit).await?;
                } else {
                    return Err("增量/差异备份需要指定时间点".into());
                }
            }
        }
        
        // 清理临时文件
        fs::remove_file(&final_path).await?;
        
        println!("数据库恢复完成");
        Ok(())
    }
    
    async fn download_backup(&self, record: &BackupRecord) -> Result<String, Box<dyn std::error::Error>> {
        // 从第一个存储位置下载
        if let Some(location) = record.storage_locations.first() {
            let local_path = format!("/tmp/restore/{}", record.id);
            fs::create_dir_all("/tmp/restore").await?;
            
            // 这里应该根据存储类型实现实际的下载逻辑
            // 目前简化处理
            fs::copy(location, &local_path).await?;
            
            Ok(local_path)
        } else {
            Err("没有可用的备份存储位置".into())
        }
    }
    
    async fn decrypt_file(&self, encrypted_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let decrypted_path = encrypted_path.trim_end_matches(".enc");
        
        let output = Command::new("openssl")
            .args(&[
                "enc",
                "-aes-256-cbc",
                "-d",
                "-in", encrypted_path,
                "-out", decrypted_path,
                "-k", "backup_encryption_key",
            ])
            .output()?;
        
        if !output.status.success() {
            return Err("解密失败".into());
        }
        
        Ok(decrypted_path.to_string())
    }
    
    async fn decompress_file(&self, compressed_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let output = Command::new("gunzip")
            .args(&[compressed_path])
            .output()?;
        
        if !output.status.success() {
            return Err("解压缩失败".into());
        }
        
        Ok(compressed_path.trim_end_matches(".gz").to_string())
    }
    
    async fn restore_full_backup(&self, backup_path: &str, target_db: &str) -> Result<(), Box<dyn std::error::Error>> {
        let output = Command::new("pg_restore")
            .args(&[
                "--host", "localhost",
                "--port", "5432",
                "--username", "postgres",
                "--dbname", target_db,
                "--clean",
                "--create",
                "--verbose",
                backup_path,
            ])
            .env("PGPASSWORD", "postgres")
            .output()?;
        
        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(format!("pg_restore失败: {}", stderr).into());
        }
        
        Ok(())
    }
    
    async fn restore_point_in_time(
        &self,
        _backup_path: &str,
        _target_db: &str,
        _point_in_time: DateTime<Utc>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // 时间点恢复实现
        // 这需要WAL重放等复杂逻辑
        println!("执行时间点恢复");
        Ok(())
    }
}
```

## 6. 存储接口实现

### 6.1 备份存储接口

```rust
// src/backup/storage.rs
#[async_trait::async_trait]
pub trait BackupStorage: Send + Sync {
    async fn save_backup_record(&self, record: &BackupRecord) -> Result<(), Box<dyn std::error::Error>>;
    async fn get_backup_record(&self, id: Uuid) -> Result<BackupRecord, Box<dyn std::error::Error>>;
    async fn list_backup_records(&self, job_id: Option<Uuid>) -> Result<Vec<BackupRecord>, Box<dyn std::error::Error>>;
    async fn delete_backup_record(&self, id: Uuid) -> Result<(), Box<dyn std::error::Error>>;
}

pub struct PostgreSQLBackupStorage {
    pool: sqlx::PgPool,
}

impl PostgreSQLBackupStorage {
    pub fn new(pool: sqlx::PgPool) -> Self {
        Self { pool }
    }
}

#[async_trait::async_trait]
impl BackupStorage for PostgreSQLBackupStorage {
    async fn save_backup_record(&self, record: &BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        sqlx::query!(
            r#"
            INSERT INTO backup_records (
                id, job_id, backup_type, started_at, completed_at, status,
                size_bytes, compressed_size_bytes, checksum, storage_locations, error_message
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
            ON CONFLICT (id) DO UPDATE SET
                completed_at = $5,
                status = $6,
                size_bytes = $7,
                compressed_size_bytes = $8,
                checksum = $9,
                storage_locations = $10,
                error_message = $11
            "#,
            record.id,
            record.job_id,
            serde_json::to_string(&record.backup_type)?,
            record.started_at,
            record.completed_at,
            serde_json::to_string(&record.status)?,
            record.size_bytes as i64,
            record.compressed_size_bytes as i64,
            record.checksum,
            serde_json::to_string(&record.storage_locations)?,
            record.error_message
        )
        .execute(&self.pool)
        .await?;
        
        Ok(())
    }
    
    async fn get_backup_record(&self, id: Uuid) -> Result<BackupRecord, Box<dyn std::error::Error>> {
        let row = sqlx::query!(
            "SELECT * FROM backup_records WHERE id = $1",
            id
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(BackupRecord {
            id: row.id,
            job_id: row.job_id,
            backup_type: serde_json::from_str(&row.backup_type)?,
            started_at: row.started_at,
            completed_at: row.completed_at,
            status: serde_json::from_str(&row.status)?,
            size_bytes: row.size_bytes as u64,
            compressed_size_bytes: row.compressed_size_bytes as u64,
            checksum: row.checksum,
            storage_locations: serde_json::from_str(&row.storage_locations)?,
            error_message: row.error_message,
        })
    }
    
    async fn list_backup_records(&self, job_id: Option<Uuid>) -> Result<Vec<BackupRecord>, Box<dyn std::error::Error>> {
        let rows = if let Some(job_id) = job_id {
            sqlx::query!(
                "SELECT * FROM backup_records WHERE job_id = $1 ORDER BY started_at DESC",
                job_id
            )
            .fetch_all(&self.pool)
            .await?
        } else {
            sqlx::query!(
                "SELECT * FROM backup_records ORDER BY started_at DESC"
            )
            .fetch_all(&self.pool)
            .await?
        };
        
        let mut records = Vec::new();
        for row in rows {
            records.push(BackupRecord {
                id: row.id,
                job_id: row.job_id,
                backup_type: serde_json::from_str(&row.backup_type)?,
                started_at: row.started_at,
                completed_at: row.completed_at,
                status: serde_json::from_str(&row.status)?,
                size_bytes: row.size_bytes as u64,
                compressed_size_bytes: row.compressed_size_bytes as u64,
                checksum: row.checksum,
                storage_locations: serde_json::from_str(&row.storage_locations)?,
                error_message: row.error_message,
            });
        }
        
        Ok(records)
    }
    
    async fn delete_backup_record(&self, id: Uuid) -> Result<(), Box<dyn std::error::Error>> {
        sqlx::query!(
            "DELETE FROM backup_records WHERE id = $1",
            id
        )
        .execute(&self.pool)
        .await?;
        
        Ok(())
    }
}
```

这个备份恢复系统提供了完整的数据保护解决方案，支持多种备份策略、存储目标和恢复选项。
