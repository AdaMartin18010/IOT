# AI驱动的设备语义解释

## 1. 理论框架

### 1.1 AI语义解释理论

```python
from typing import Dict, List, Optional, Any, Tuple
import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer
import numpy as np

class AISemanticInterpreter:
    """AI语义解释器"""
    
    def __init__(self, model_name: str = "bert-base-uncased"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.embedding_dim = self.model.config.hidden_size
        
        # 语义分类器
        self.semantic_classifier = nn.Sequential(
            nn.Linear(self.embedding_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 10)  # 10个语义类别
        )
        
        # 设备类型识别器
        self.device_type_classifier = nn.Sequential(
            nn.Linear(self.embedding_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 20)  # 20种设备类型
        )
    
    def extract_semantic_features(self, device_description: str) -> torch.Tensor:
        """提取语义特征"""
        inputs = self.tokenizer(
            device_description,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            # 使用[CLS]标记的输出作为语句级特征
            features = outputs.last_hidden_state[:, 0, :]
        
        return features
    
    def classify_device_semantics(self, device_description: str) -> Dict[str, Any]:
        """分类设备语义"""
        features = self.extract_semantic_features(device_description)
        
        # 语义分类
        semantic_logits = self.semantic_classifier(features)
        semantic_probs = torch.softmax(semantic_logits, dim=-1)
        
        # 设备类型分类
        device_type_logits = self.device_type_classifier(features)
        device_type_probs = torch.softmax(device_type_logits, dim=-1)
        
        return {
            "semantic_class": torch.argmax(semantic_probs, dim=-1).item(),
            "semantic_confidence": torch.max(semantic_probs).item(),
            "device_type": torch.argmax(device_type_probs, dim=-1).item(),
            "device_confidence": torch.max(device_type_probs).item(),
            "features": features.numpy()
        }
```

### 1.2 知识图谱集成

```python
class SemanticKnowledgeGraph:
    """语义知识图谱"""
    
    def __init__(self):
        self.entities = {}
        self.relations = []
        self.entity_embeddings = {}
    
    def add_entity(self, entity_id: str, entity_type: str, properties: Dict[str, Any]):
        """添加实体"""
        self.entities[entity_id] = {
            "type": entity_type,
            "properties": properties
        }
    
    def add_relation(self, subject: str, predicate: str, object: str, confidence: float = 1.0):
        """添加关系"""
        self.relations.append({
            "subject": subject,
            "predicate": predicate,
            "object": object,
            "confidence": confidence
        })
    
    def find_similar_entities(self, query_embedding: np.ndarray, top_k: int = 5) -> List[Tuple[str, float]]:
        """查找相似实体"""
        similarities = []
        
        for entity_id, embedding in self.entity_embeddings.items():
            similarity = np.dot(query_embedding, embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(embedding)
            )
            similarities.append((entity_id, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def infer_device_capabilities(self, device_type: str) -> List[str]:
        """推理设备能力"""
        capabilities = []
        
        for relation in self.relations:
            if (relation["subject"] == device_type and 
                relation["predicate"] == "has_capability"):
                capabilities.append(relation["object"])
        
        return capabilities
```

## 2. 算法实现

### 2.1 自然语言处理管道

```python
class DeviceSemanticNLPPipeline:
    """设备语义NLP管道"""
    
    def __init__(self):
        self.ai_interpreter = AISemanticInterpreter()
        self.knowledge_graph = SemanticKnowledgeGraph()
        self.named_entity_recognizer = self._initialize_ner()
    
    def _initialize_ner(self):
        """初始化命名实体识别器"""
        # 简化实现，实际应该使用预训练的NER模型
        return {
            "device_types": ["sensor", "actuator", "controller", "gateway"],
            "measurement_types": ["temperature", "humidity", "pressure", "flow"],
            "protocols": ["mqtt", "coap", "http", "modbus", "bacnet"]
        }
    
    def process_device_description(self, description: str) -> Dict[str, Any]:
        """处理设备描述"""
        # 1. 命名实体识别
        entities = self._extract_entities(description)
        
        # 2. AI语义分类
        semantic_result = self.ai_interpreter.classify_device_semantics(description)
        
        # 3. 知识图谱匹配
        similar_devices = self.knowledge_graph.find_similar_entities(
            semantic_result["features"].flatten()
        )
        
        # 4. 能力推理
        inferred_capabilities = []
        if entities.get("device_type"):
            inferred_capabilities = self.knowledge_graph.infer_device_capabilities(
                entities["device_type"][0]
            )
        
        return {
            "entities": entities,
            "semantic_classification": semantic_result,
            "similar_devices": similar_devices,
            "inferred_capabilities": inferred_capabilities,
            "interpretation_confidence": semantic_result["semantic_confidence"]
        }
    
    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        """提取命名实体"""
        entities = {
            "device_types": [],
            "measurement_types": [],
            "protocols": []
        }
        
        text_lower = text.lower()
        
        for entity_type, keywords in self.named_entity_recognizer.items():
            for keyword in keywords:
                if keyword in text_lower:
                    entities[entity_type].append(keyword)
        
        return entities
```

### 2.2 语义相似度计算

```python
class SemanticSimilarityCalculator:
    """语义相似度计算器"""
    
    def __init__(self):
        self.embedding_cache = {}
    
    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """计算语义相似度"""
        # 获取或计算嵌入向量
        embedding1 = self._get_embedding(text1)
        embedding2 = self._get_embedding(text2)
        
        # 计算余弦相似度
        similarity = np.dot(embedding1, embedding2) / (
            np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
        )
        
        return float(similarity)
    
    def _get_embedding(self, text: str) -> np.ndarray:
        """获取文本嵌入向量"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        # 使用BERT模型计算嵌入
        tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
        model = AutoModel.from_pretrained("bert-base-uncased")
        
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        with torch.no_grad():
            outputs = model(**inputs)
            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
        
        self.embedding_cache[text] = embedding
        return embedding
    
    def find_most_similar_devices(self, query: str, 
                                 device_descriptions: List[str], 
                                 top_k: int = 5) -> List[Tuple[int, float]]:
        """查找最相似的设备"""
        similarities = []
        
        for i, description in enumerate(device_descriptions):
            similarity = self.calculate_semantic_similarity(query, description)
            similarities.append((i, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
```

### 2.3 设备能力推理

```python
class DeviceCapabilityInferenceEngine:
    """设备能力推理引擎"""
    
    def __init__(self):
        self.capability_rules = self._load_capability_rules()
        self.device_ontology = self._load_device_ontology()
    
    def _load_capability_rules(self) -> List[Dict[str, Any]]:
        """加载能力推理规则"""
        return [
            {
                "condition": {"device_type": "temperature_sensor"},
                "capabilities": ["measure_temperature", "temperature_alert"]
            },
            {
                "condition": {"device_type": "humidity_sensor"},
                "capabilities": ["measure_humidity", "humidity_alert"]
            },
            {
                "condition": {"device_type": "smart_thermostat"},
                "capabilities": ["measure_temperature", "control_heating", "schedule_temperature"]
            },
            {
                "condition": {"protocol": "mqtt"},
                "capabilities": ["publish_data", "subscribe_commands"]
            }
        ]
    
    def _load_device_ontology(self) -> Dict[str, Any]:
        """加载设备本体"""
        return {
            "sensors": {
                "temperature_sensor": {"measures": "temperature", "unit": "celsius"},
                "humidity_sensor": {"measures": "humidity", "unit": "percent"},
                "pressure_sensor": {"measures": "pressure", "unit": "pascal"}
            },
            "actuators": {
                "heater": {"controls": "temperature", "action": "heating"},
                "valve": {"controls": "flow", "action": "open_close"}
            }
        }
    
    def infer_capabilities(self, device_info: Dict[str, Any]) -> List[str]:
        """推理设备能力"""
        inferred_capabilities = set()
        
        # 基于规则的推理
        for rule in self.capability_rules:
            if self._matches_condition(device_info, rule["condition"]):
                inferred_capabilities.update(rule["capabilities"])
        
        # 基于本体的推理
        device_type = device_info.get("device_type")
        if device_type:
            ontology_capabilities = self._get_ontology_capabilities(device_type)
            inferred_capabilities.update(ontology_capabilities)
        
        return list(inferred_capabilities)
    
    def _matches_condition(self, device_info: Dict[str, Any], 
                          condition: Dict[str, Any]) -> bool:
        """检查是否匹配条件"""
        for key, value in condition.items():
            if device_info.get(key) != value:
                return False
        return True
    
    def _get_ontology_capabilities(self, device_type: str) -> List[str]:
        """从本体获取能力"""
        capabilities = []
        
        # 检查传感器类型
        if device_type in self.device_ontology.get("sensors", {}):
            sensor_info = self.device_ontology["sensors"][device_type]
            measure_type = sensor_info.get("measures")
            if measure_type:
                capabilities.append(f"measure_{measure_type}")
        
        # 检查执行器类型
        if device_type in self.device_ontology.get("actuators", {}):
            actuator_info = self.device_ontology["actuators"][device_type]
            control_type = actuator_info.get("controls")
            action_type = actuator_info.get("action")
            if control_type and action_type:
                capabilities.append(f"{action_type}_{control_type}")
        
        return capabilities
```

## 3. 训练和优化

### 3.1 模型训练

```python
class SemanticInterpreterTrainer:
    """语义解释器训练器"""
    
    def __init__(self, model: AISemanticInterpreter):
        self.model = model
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        self.criterion = nn.CrossEntropyLoss()
    
    def train(self, train_data: List[Dict[str, Any]], epochs: int = 10):
        """训练模型"""
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0.0
            
            for batch in self._create_batches(train_data, batch_size=32):
                # 准备输入
                descriptions = [item["description"] for item in batch]
                semantic_labels = torch.tensor([item["semantic_label"] for item in batch])
                device_type_labels = torch.tensor([item["device_type_label"] for item in batch])
                
                # 前向传播
                features = []
                for desc in descriptions:
                    feature = self.model.extract_semantic_features(desc)
                    features.append(feature)
                
                features = torch.cat(features, dim=0)
                
                # 预测
                semantic_logits = self.model.semantic_classifier(features)
                device_type_logits = self.model.device_type_classifier(features)
                
                # 计算损失
                semantic_loss = self.criterion(semantic_logits, semantic_labels)
                device_type_loss = self.criterion(device_type_logits, device_type_labels)
                total_loss_batch = semantic_loss + device_type_loss
                
                # 反向传播
                self.optimizer.zero_grad()
                total_loss_batch.backward()
                self.optimizer.step()
                
                total_loss += total_loss_batch.item()
            
            print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_data):.4f}")
    
    def _create_batches(self, data: List[Dict[str, Any]], batch_size: int):
        """创建批次"""
        for i in range(0, len(data), batch_size):
            yield data[i:i + batch_size]
```

## 4. Rust实现

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticInterpretationResult {
    pub device_type: String,
    pub confidence: f64,
    pub capabilities: Vec<String>,
    pub semantic_features: Vec<f64>,
}

pub struct AISemanticInterpreter {
    capability_rules: Vec<CapabilityRule>,
    device_ontology: HashMap<String, DeviceInfo>,
}

#[derive(Debug, Clone)]
struct CapabilityRule {
    condition: HashMap<String, String>,
    capabilities: Vec<String>,
}

#[derive(Debug, Clone)]
struct DeviceInfo {
    device_type: String,
    measures: Option<String>,
    controls: Option<String>,
    action: Option<String>,
}

impl AISemanticInterpreter {
    pub fn new() -> Self {
        Self {
            capability_rules: Self::load_capability_rules(),
            device_ontology: Self::load_device_ontology(),
        }
    }
    
    fn load_capability_rules() -> Vec<CapabilityRule> {
        vec![
            CapabilityRule {
                condition: [("device_type".to_string(), "temperature_sensor".to_string())].iter().cloned().collect(),
                capabilities: vec!["measure_temperature".to_string(), "temperature_alert".to_string()],
            },
            CapabilityRule {
                condition: [("device_type".to_string(), "humidity_sensor".to_string())].iter().cloned().collect(),
                capabilities: vec!["measure_humidity".to_string(), "humidity_alert".to_string()],
            },
        ]
    }
    
    fn load_device_ontology() -> HashMap<String, DeviceInfo> {
        let mut ontology = HashMap::new();
        
        ontology.insert("temperature_sensor".to_string(), DeviceInfo {
            device_type: "sensor".to_string(),
            measures: Some("temperature".to_string()),
            controls: None,
            action: None,
        });
        
        ontology.insert("heater".to_string(), DeviceInfo {
            device_type: "actuator".to_string(),
            measures: None,
            controls: Some("temperature".to_string()),
            action: Some("heating".to_string()),
        });
        
        ontology
    }
    
    pub fn interpret_device_semantics(&self, device_info: &HashMap<String, String>) -> Result<SemanticInterpretationResult, String> {
        // 推理设备能力
        let capabilities = self.infer_capabilities(device_info);
        
        // 确定设备类型（简化实现）
        let device_type = device_info.get("device_type")
            .unwrap_or(&"unknown".to_string())
            .clone();
        
        // 计算置信度（简化实现）
        let confidence = if capabilities.is_empty() { 0.5 } else { 0.9 };
        
        Ok(SemanticInterpretationResult {
            device_type,
            confidence,
            capabilities,
            semantic_features: vec![0.0; 768], // 占位符
        })
    }
    
    fn infer_capabilities(&self, device_info: &HashMap<String, String>) -> Vec<String> {
        let mut capabilities = Vec::new();
        
        // 基于规则的推理
        for rule in &self.capability_rules {
            if self.matches_condition(device_info, &rule.condition) {
                capabilities.extend(rule.capabilities.clone());
            }
        }
        
        // 基于本体的推理
        if let Some(device_type) = device_info.get("device_type") {
            if let Some(device_info_ont) = self.device_ontology.get(device_type) {
                if let Some(measures) = &device_info_ont.measures {
                    capabilities.push(format!("measure_{}", measures));
                }
                
                if let (Some(controls), Some(action)) = (&device_info_ont.controls, &device_info_ont.action) {
                    capabilities.push(format!("{}_{}", action, controls));
                }
            }
        }
        
        capabilities.into_iter().collect::<std::collections::HashSet<_>>().into_iter().collect()
    }
    
    fn matches_condition(&self, device_info: &HashMap<String, String>, condition: &HashMap<String, String>) -> bool {
        for (key, value) in condition {
            if device_info.get(key) != Some(value) {
                return false;
            }
        }
        true
    }
}
```

## 5. 测试用例

```python
import unittest

class TestAISemanticInterpreter(unittest.TestCase):
    def setUp(self):
        self.interpreter = AISemanticInterpreter()
        self.nlp_pipeline = DeviceSemanticNLPPipeline()
    
    def test_device_classification(self):
        description = "Smart temperature sensor with WiFi connectivity"
        result = self.interpreter.classify_device_semantics(description)
        
        self.assertIsInstance(result, dict)
        self.assertIn("semantic_class", result)
        self.assertIn("device_type", result)
        self.assertGreater(result["semantic_confidence"], 0.0)
    
    def test_nlp_pipeline(self):
        description = "IoT temperature and humidity sensor with MQTT protocol"
        result = self.nlp_pipeline.process_device_description(description)
        
        self.assertIn("entities", result)
        self.assertIn("semantic_classification", result)
        self.assertIn("inferred_capabilities", result)
        
        entities = result["entities"]
        self.assertIn("temperature", str(entities))
        self.assertIn("humidity", str(entities))
        self.assertIn("mqtt", str(entities))
    
    def test_capability_inference(self):
        inference_engine = DeviceCapabilityInferenceEngine()
        device_info = {
            "device_type": "temperature_sensor",
            "protocol": "mqtt"
        }
        
        capabilities = inference_engine.infer_capabilities(device_info)
        
        self.assertIn("measure_temperature", capabilities)
        self.assertIn("publish_data", capabilities)

if __name__ == '__main__':
    unittest.main()
```

## 6. 总结

本模块提供了基于AI的设备语义解释功能，包括：

1. **深度学习模型**：使用BERT等预训练模型进行语义理解
2. **知识图谱集成**：结合领域知识进行推理
3. **自然语言处理**：处理设备描述文本
4. **能力推理**：自动推理设备功能和能力
5. **相似度计算**：基于语义的设备匹配

该模块为IoT设备的智能语义解释提供了先进的AI能力。
