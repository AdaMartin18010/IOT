# IoT语义互操作项目完整部署实施指南

## 1. 项目概述

本指南提供IoT多标准语义统一理论系统的完整部署实施方案，涵盖从环境准备到生产部署的全流程指导。

### 1.1 系统架构总览

```text
┌─────────────────────────────────────────────────────────────┐
│                     IoT语义互操作平台                        │
├─────────────────────────────────────────────────────────────┤
│  API网关层   │  语义处理层  │  推理引擎层  │  存储层        │
│  - REST API  │  - 协议适配  │  - 规则推理  │  - 知识图谱    │
│  - GraphQL   │  - 语义映射  │  - ML推理    │  - 缓存系统    │
│  - WebSocket │  - 标准转换  │  - 融合推理  │  - 时序数据    │
├─────────────────────────────────────────────────────────────┤
│  设备接入层  │  消息中间件  │  监控告警    │  配置管理      │
│  - MQTT      │  - Kafka     │  - Prometheus│  - 配置中心    │
│  - OPC UA    │  - RabbitMQ  │  - Grafana   │  - 动态配置    │
│  - CoAP      │  - 消息路由  │  - 告警系统  │  - 版本管理    │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 技术栈组件

- **后端服务**: Python (FastAPI), Rust (高性能组件)
- **前端界面**: React + TypeScript
- **数据存储**: PostgreSQL, Neo4j, Redis, InfluxDB
- **消息中间件**: Apache Kafka, RabbitMQ, MQTT Broker
- **容器化**: Docker, Kubernetes
- **监控**: Prometheus, Grafana, ELK Stack
- **AI/ML**: PyTorch, scikit-learn, Transformers

## 2. 环境准备

### 2.1 硬件要求

```yaml
开发环境:
  CPU: 4核心以上
  内存: 16GB以上
  存储: 100GB SSD
  网络: 千兆网卡

测试环境:
  CPU: 8核心以上
  内存: 32GB以上
  存储: 500GB SSD
  网络: 千兆网卡

生产环境:
  CPU: 16核心以上 (推荐32核心)
  内存: 64GB以上 (推荐128GB)
  存储: 2TB SSD (推荐NVMe)
  网络: 万兆网卡
  高可用: 至少3节点集群
```

### 2.2 软件依赖

```bash
# 基础软件安装
# Ubuntu 22.04 LTS

# 1. Docker安装
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# 2. Docker Compose安装
sudo curl -L "https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# 3. Kubernetes安装 (生产环境)
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl

# 4. Python环境
sudo apt-get install python3.11 python3.11-venv python3.11-dev
python3.11 -m venv venv
source venv/bin/activate

# 5. Rust环境
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env

# 6. Node.js环境
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs
```

## 3. 快速部署指南

### 3.1 一键部署脚本

```bash
#!/bin/bash
# deploy.sh - 一键部署脚本

set -e

echo "开始部署IoT语义互操作平台..."

# 1. 检查环境
check_environment() {
    echo "检查部署环境..."
    
    # 检查Docker
    if ! command -v docker &> /dev/null; then
        echo "错误: Docker未安装"
        exit 1
    fi
    
    # 检查Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        echo "错误: Docker Compose未安装"
        exit 1
    fi
    
    # 检查系统资源
    memory=$(free -g | awk 'NR==2{print $2}')
    if [ $memory -lt 8 ]; then
        echo "警告: 系统内存少于8GB，可能影响性能"
    fi
    
    echo "环境检查完成"
}

# 2. 准备配置文件
prepare_configs() {
    echo "准备配置文件..."
    
    # 创建配置目录
    mkdir -p config/postgres config/neo4j config/redis config/kafka
    
    # 生成环境配置
    cat > .env << EOF
# 数据库配置
POSTGRES_DB=iot_semantic
POSTGRES_USER=iot_user
POSTGRES_PASSWORD=$(openssl rand -base64 32)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Neo4j配置
NEO4J_AUTH=neo4j/$(openssl rand -base64 32)
NEO4J_HOST=neo4j
NEO4J_PORT=7687

# Redis配置
REDIS_URL=redis://redis:6379
REDIS_PASSWORD=$(openssl rand -base64 32)

# Kafka配置
KAFKA_BROKERS=kafka:9092
KAFKA_ZOOKEEPER=zookeeper:2181

# API配置
API_HOST=0.0.0.0
API_PORT=8080
JWT_SECRET=$(openssl rand -base64 64)
API_KEY=$(openssl rand -hex 32)

# 监控配置
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_ADMIN_PASSWORD=$(openssl rand -base64 32)
EOF
    
    echo "配置文件准备完成"
}

# 3. 启动基础服务
start_infrastructure() {
    echo "启动基础设施服务..."
    
    docker-compose -f docker-compose.infrastructure.yml up -d
    
    # 等待服务启动
    echo "等待服务启动..."
    sleep 30
    
    # 检查服务状态
    docker-compose -f docker-compose.infrastructure.yml ps
}

# 4. 初始化数据
initialize_data() {
    echo "初始化数据..."
    
    # 初始化PostgreSQL
    docker-compose exec postgres psql -U $POSTGRES_USER -d $POSTGRES_DB -f /docker-entrypoint-initdb.d/init.sql
    
    # 初始化Neo4j
    python scripts/init_knowledge_graph.py
    
    # 加载语义模型
    python scripts/load_semantic_models.py
    
    # 导入示例数据
    python scripts/import_sample_data.py
    
    echo "数据初始化完成"
}

# 5. 启动应用服务
start_applications() {
    echo "启动应用服务..."
    
    docker-compose -f docker-compose.applications.yml up -d
    
    # 等待服务启动
    sleep 30
    
    # 健康检查
    python scripts/health_check.py
}

# 6. 验证部署
verify_deployment() {
    echo "验证部署..."
    
    # 检查API端点
    curl -f http://localhost:8080/api/v1/health || {
        echo "错误: API服务未正常启动"
        exit 1
    }
    
    # 检查前端
    curl -f http://localhost:3000 || {
        echo "错误: 前端服务未正常启动"
        exit 1
    }
    
    # 运行基础测试
    python -m pytest tests/integration/ -v
    
    echo "部署验证完成"
}

# 主流程
main() {
    check_environment
    prepare_configs
    start_infrastructure
    initialize_data
    start_applications
    verify_deployment
    
    echo "========================================="
    echo "IoT语义互操作平台部署完成!"
    echo "========================================="
    echo "API服务: http://localhost:8080"
    echo "前端界面: http://localhost:3000"
    echo "监控面板: http://localhost:3000/monitoring"
    echo "API文档: http://localhost:8080/docs"
    echo ""
    echo "管理员账号信息已保存在 .env 文件中"
    echo "========================================="
}

# 执行部署
main "$@"
```

### 3.2 Docker Compose配置

#### 基础设施服务

```yaml
# docker-compose.infrastructure.yml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  neo4j:
    image: neo4j:5
    environment:
      NEO4J_AUTH: ${NEO4J_AUTH}
      NEO4J_apoc_export_file_enabled: true
      NEO4J_apoc_import_file_enabled: true
      NEO4J_apoc_import_file_use_neo4j_config: true
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    ports:
      - "7474:7474"
      - "7687:7687"

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "9092:9092"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

volumes:
  postgres_data:
  neo4j_data:
  neo4j_logs:
  redis_data:
  zookeeper_data:
  kafka_data:
  prometheus_data:
```

#### 应用服务

```yaml
# docker-compose.applications.yml
version: '3.8'

services:
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile.api-gateway
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - NEO4J_URL=bolt://neo4j:7687
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - JWT_SECRET=${JWT_SECRET}
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - neo4j
      - redis
      - kafka
    restart: unless-stopped

  semantic-processor:
    build:
      context: .
      dockerfile: Dockerfile.semantic-processor
    environment:
      - NEO4J_URL=bolt://neo4j:7687
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - ML_MODEL_PATH=/app/models
    volumes:
      - ./models:/app/models
    depends_on:
      - neo4j
      - kafka
    deploy:
      replicas: 2
    restart: unless-stopped

  reasoning-engine:
    build:
      context: .
      dockerfile: Dockerfile.reasoning-engine
    environment:
      - NEO4J_URL=bolt://neo4j:7687
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - ML_MODEL_PATH=/app/models
    volumes:
      - ./models:/app/models
    depends_on:
      - neo4j
      - redis
    deploy:
      replicas: 2
    restart: unless-stopped

  protocol-adapters:
    build:
      context: .
      dockerfile: Dockerfile.protocol-adapters
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
    ports:
      - "1883:1883"  # MQTT
      - "5683:5683"  # CoAP
      - "4840:4840"  # OPC UA
    depends_on:
      - kafka
      - redis
    restart: unless-stopped

  web-dashboard:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - REACT_APP_API_URL=http://localhost:8080/api/v1
    ports:
      - "3000:3000"
    depends_on:
      - api-gateway
    restart: unless-stopped

  monitoring:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

volumes:
  grafana_data:
```

## 4. 生产环境部署

### 4.1 Kubernetes部署配置

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: iot-semantic

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: iot-semantic-config
  namespace: iot-semantic
data:
  postgres.conf: |
    shared_preload_libraries = 'pg_stat_statements'
    max_connections = 200
    shared_buffers = 2GB
    effective_cache_size = 6GB
  
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
      - job_name: 'iot-semantic'
        static_configs:
          - targets: ['api-gateway:8080', 'semantic-processor:8081']

---
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: iot-semantic-secrets
  namespace: iot-semantic
type: Opaque
data:
  postgres-password: <base64-encoded-password>
  neo4j-password: <base64-encoded-password>
  redis-password: <base64-encoded-password>
  jwt-secret: <base64-encoded-secret>

---
# k8s/api-gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: iot-semantic
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: iot-semantic/api-gateway:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: iot-semantic-secrets
              key: database-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: iot-semantic-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: api-gateway-service
  namespace: iot-semantic
spec:
  selector:
    app: api-gateway
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer

---
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-gateway-hpa
  namespace: iot-semantic
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-gateway
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 4.2 生产环境优化配置

```yaml
# production-optimizations.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: production-config
data:
  # PostgreSQL优化
  postgres-config: |
    # 连接和认证
    max_connections = 500
    
    # 内存配置
    shared_buffers = 8GB
    effective_cache_size = 24GB
    work_mem = 64MB
    maintenance_work_mem = 1GB
    
    # 检查点配置
    checkpoint_completion_target = 0.9
    wal_buffers = 64MB
    
    # 查询优化
    random_page_cost = 1.1
    effective_io_concurrency = 200
    
    # 日志配置
    log_statement = 'mod'
    log_min_duration_statement = 1000

  # Redis配置
  redis-config: |
    # 内存优化
    maxmemory 4gb
    maxmemory-policy allkeys-lru
    
    # 持久化
    save 900 1
    save 300 10
    save 60 10000
    
    # 网络优化
    tcp-keepalive 300
    timeout 0
    
    # 安全配置
    requirepass ${REDIS_PASSWORD}
    
  # Kafka配置
  kafka-config: |
    # 性能优化
    num.network.threads=8
    num.io.threads=16
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    
    # 日志配置
    num.partitions=12
    default.replication.factor=3
    min.insync.replicas=2
    
    # 压缩配置
    compression.type=lz4
    
  # Neo4j配置
  neo4j-config: |
    # 内存配置
    dbms.memory.heap.initial_size=4g
    dbms.memory.heap.max_size=8g
    dbms.memory.pagecache.size=12g
    
    # 性能配置
    dbms.tx_log.rotation.retention_policy=7 days 2G
    dbms.checkpoint.interval.time=15m
    
    # 并发配置
    dbms.threads.worker_count=8
```

## 5. 监控与运维

### 5.1 监控配置

```yaml
# monitoring/prometheus-config.yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "iot_semantic_rules.yml"

scrape_configs:
  - job_name: 'iot-semantic-api'
    static_configs:
      - targets: ['api-gateway:8080']
    metrics_path: /metrics
    scrape_interval: 10s

  - job_name: 'iot-semantic-processor'
    static_configs:
      - targets: ['semantic-processor:8081']
    scrape_interval: 10s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:2004']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 5.2 告警规则

```yaml
# monitoring/alert-rules.yml
groups:
- name: iot_semantic_alerts
  rules:
  - alert: APIHighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "API错误率过高"
      description: "API在过去5分钟内错误率超过10%"

  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "内存使用率过高"
      description: "节点内存使用率超过90%"

  - alert: DatabaseConnectionsHigh
    expr: pg_stat_database_numbackends > 400
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "数据库连接数过高"
      description: "PostgreSQL连接数超过400"

  - alert: SemanticProcessingLatencyHigh
    expr: histogram_quantile(0.95, rate(semantic_processing_duration_seconds_bucket[5m])) > 1.0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "语义处理延迟过高"
      description: "95%的语义处理请求延迟超过1秒"
```

## 6. 安全配置

### 6.1 安全加固

```bash
#!/bin/bash
# security-hardening.sh

# 1. 网络安全
configure_firewall() {
    # 配置防火墙规则
    ufw default deny incoming
    ufw default allow outgoing
    
    # 允许必要端口
    ufw allow 22/tcp     # SSH
    ufw allow 80/tcp     # HTTP
    ufw allow 443/tcp    # HTTPS
    ufw allow 8080/tcp   # API Gateway
    
    # 内部服务端口仅允许集群内访问
    ufw allow from 10.0.0.0/8 to any port 5432  # PostgreSQL
    ufw allow from 10.0.0.0/8 to any port 7687  # Neo4j
    ufw allow from 10.0.0.0/8 to any port 6379  # Redis
    
    ufw enable
}

# 2. TLS/SSL配置
configure_tls() {
    # 生成自签名证书 (生产环境使用Let's Encrypt)
    openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
        -keyout /etc/ssl/private/iot-semantic.key \
        -out /etc/ssl/certs/iot-semantic.crt \
        -subj "/C=US/ST=State/L=City/O=Organization/CN=iot-semantic.local"
    
    # 配置Nginx SSL
    cat > /etc/nginx/sites-available/iot-semantic-ssl << EOF
server {
    listen 443 ssl http2;
    server_name iot-semantic.local;
    
    ssl_certificate /etc/ssl/certs/iot-semantic.crt;
    ssl_certificate_key /etc/ssl/private/iot-semantic.key;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;
    
    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
    }
}
EOF
}

# 3. 访问控制
configure_rbac() {
    # 创建RBAC策略
    cat > rbac-policy.yaml << EOF
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: iot-semantic
  name: iot-semantic-operator
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: iot-semantic-operator-binding
  namespace: iot-semantic
subjects:
- kind: ServiceAccount
  name: iot-semantic-service-account
  namespace: iot-semantic
roleRef:
  kind: Role
  name: iot-semantic-operator
  apiGroup: rbac.authorization.k8s.io
EOF
}
```

## 7. 运维脚本

### 7.1 备份恢复脚本

```bash
#!/bin/bash
# backup-restore.sh

BACKUP_DIR="/opt/iot-semantic/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# 数据库备份
backup_databases() {
    echo "开始数据库备份..."
    
    # PostgreSQL备份
    docker exec postgres pg_dump -U $POSTGRES_USER $POSTGRES_DB > $BACKUP_DIR/postgres_$DATE.sql
    
    # Neo4j备份
    docker exec neo4j neo4j-admin database dump --database=neo4j --to-path=/tmp
    docker cp neo4j:/tmp/neo4j.dump $BACKUP_DIR/neo4j_$DATE.dump
    
    # Redis备份
    docker exec redis redis-cli --rdb /tmp/dump.rdb
    docker cp redis:/tmp/dump.rdb $BACKUP_DIR/redis_$DATE.rdb
    
    echo "数据库备份完成"
}

# 配置备份
backup_configs() {
    echo "开始配置备份..."
    
    tar -czf $BACKUP_DIR/configs_$DATE.tar.gz \
        config/ \
        .env \
        docker-compose*.yml \
        k8s/
    
    echo "配置备份完成"
}

# 数据恢复
restore_databases() {
    local backup_date=$1
    
    echo "开始数据恢复: $backup_date"
    
    # PostgreSQL恢复
    docker exec -i postgres psql -U $POSTGRES_USER $POSTGRES_DB < $BACKUP_DIR/postgres_$backup_date.sql
    
    # Neo4j恢复
    docker cp $BACKUP_DIR/neo4j_$backup_date.dump neo4j:/tmp/
    docker exec neo4j neo4j-admin database load --from-path=/tmp --database=neo4j --overwrite-destination
    
    # Redis恢复
    docker cp $BACKUP_DIR/redis_$backup_date.rdb redis:/data/dump.rdb
    docker restart redis
    
    echo "数据恢复完成"
}

# 清理旧备份
cleanup_old_backups() {
    find $BACKUP_DIR -name "*.sql" -mtime +30 -delete
    find $BACKUP_DIR -name "*.dump" -mtime +30 -delete
    find $BACKUP_DIR -name "*.rdb" -mtime +30 -delete
    find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete
}

case "$1" in
    backup)
        backup_databases
        backup_configs
        cleanup_old_backups
        ;;
    restore)
        restore_databases $2
        ;;
    cleanup)
        cleanup_old_backups
        ;;
    *)
        echo "Usage: $0 {backup|restore|cleanup}"
        exit 1
        ;;
esac
```

### 7.2 健康检查脚本

```python
#!/usr/bin/env python3
# health_check.py

import asyncio
import aiohttp
import psycopg2
from neo4j import GraphDatabase
import redis
import json
import sys
from datetime import datetime

class HealthChecker:
    def __init__(self):
        self.results = {}
    
    async def check_api_gateway(self):
        """检查API网关"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('http://localhost:8080/health', timeout=10) as response:
                    if response.status == 200:
                        self.results['api_gateway'] = {'status': 'healthy', 'response_time': response.headers.get('X-Response-Time')}
                    else:
                        self.results['api_gateway'] = {'status': 'unhealthy', 'error': f'HTTP {response.status}'}
        except Exception as e:
            self.results['api_gateway'] = {'status': 'error', 'error': str(e)}
    
    def check_postgresql(self):
        """检查PostgreSQL"""
        try:
            conn = psycopg2.connect(
                host='localhost',
                port=5432,
                database='iot_semantic',
                user='iot_user',
                password='password'
            )
            cursor = conn.cursor()
            cursor.execute('SELECT 1')
            cursor.close()
            conn.close()
            self.results['postgresql'] = {'status': 'healthy'}
        except Exception as e:
            self.results['postgresql'] = {'status': 'error', 'error': str(e)}
    
    def check_neo4j(self):
        """检查Neo4j"""
        try:
            driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
            with driver.session() as session:
                result = session.run("RETURN 1")
                result.single()
            driver.close()
            self.results['neo4j'] = {'status': 'healthy'}
        except Exception as e:
            self.results['neo4j'] = {'status': 'error', 'error': str(e)}
    
    def check_redis(self):
        """检查Redis"""
        try:
            r = redis.Redis(host='localhost', port=6379, password='password')
            r.ping()
            self.results['redis'] = {'status': 'healthy'}
        except Exception as e:
            self.results['redis'] = {'status': 'error', 'error': str(e)}
    
    async def check_kafka(self):
        """检查Kafka"""
        try:
            # 简单的健康检查，实际应该检查broker状态
            import aiokafka
            producer = aiokafka.AIOKafkaProducer(bootstrap_servers='localhost:9092')
            await producer.start()
            await producer.stop()
            self.results['kafka'] = {'status': 'healthy'}
        except Exception as e:
            self.results['kafka'] = {'status': 'error', 'error': str(e)}
    
    async def run_all_checks(self):
        """运行所有健康检查"""
        print(f"开始健康检查 - {datetime.now()}")
        
        await asyncio.gather(
            self.check_api_gateway(),
            self.check_kafka(),
        )
        
        # 同步检查
        self.check_postgresql()
        self.check_neo4j()
        self.check_redis()
        
        return self.results
    
    def generate_report(self):
        """生成健康检查报告"""
        healthy_count = sum(1 for service in self.results.values() if service['status'] == 'healthy')
        total_count = len(self.results)
        
        print(f"\n健康检查报告 ({healthy_count}/{total_count} 服务正常)")
        print("=" * 50)
        
        for service, result in self.results.items():
            status = result['status']
            status_emoji = "✅" if status == 'healthy' else "❌"
            print(f"{status_emoji} {service.ljust(15)} : {status}")
            
            if 'error' in result:
                print(f"   错误: {result['error']}")
            if 'response_time' in result:
                print(f"   响应时间: {result['response_time']}")
        
        print("=" * 50)
        
        if healthy_count == total_count:
            print("✅ 所有服务运行正常")
            return 0
        else:
            print("❌ 部分服务存在问题")
            return 1

async def main():
    checker = HealthChecker()
    await checker.run_all_checks()
    exit_code = checker.generate_report()
    sys.exit(exit_code)

if __name__ == "__main__":
    asyncio.run(main())
```

## 8. 性能优化

### 8.1 系统调优

```bash
#!/bin/bash
# system-tuning.sh

# 内核参数优化
optimize_kernel() {
    cat >> /etc/sysctl.conf << EOF
# 网络优化
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 12582912 16777216
net.ipv4.tcp_wmem = 4096 12582912 16777216
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_window_scaling = 1

# 文件系统优化
fs.file-max = 2097152
vm.swappiness = 1
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# 进程优化
kernel.pid_max = 4194304
EOF

    sysctl -p
}

# 文件描述符限制
optimize_limits() {
    cat >> /etc/security/limits.conf << EOF
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535
EOF
}

# 数据库连接池优化
optimize_connection_pools() {
    # PostgreSQL连接池配置
    cat > config/pgbouncer.ini << EOF
[databases]
iot_semantic = host=postgres port=5432 dbname=iot_semantic

[pgbouncer]
listen_port = 6432
listen_addr = 127.0.0.1
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt
logfile = /var/log/pgbouncer/pgbouncer.log
pidfile = /var/run/pgbouncer/pgbouncer.pid
admin_users = postgres
pool_mode = transaction
server_reset_query = DISCARD ALL
max_client_conn = 1000
default_pool_size = 100
reserve_pool_size = 10
EOF
}

optimize_kernel
optimize_limits
optimize_connection_pools
```

## 9. 故障排除

### 9.1 常见问题解决

```bash
#!/bin/bash
# troubleshoot.sh

# 检查服务状态
check_services() {
    echo "检查Docker服务状态..."
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    
    echo -e "\n检查Kubernetes Pod状态..."
    kubectl get pods -n iot-semantic
    
    echo -e "\n检查服务日志..."
    docker-compose logs --tail=50 api-gateway
}

# 内存使用分析
analyze_memory() {
    echo "内存使用分析..."
    docker stats --no-stream --format "table {{.Container}}\t{{.MemUsage}}\t{{.MemPerc}}"
    
    echo -e "\n系统内存使用..."
    free -h
    
    echo -e "\n进程内存排序..."
    ps aux --sort=-%mem | head -20
}

# 网络连接检查
check_network() {
    echo "网络连接检查..."
    
    # 检查端口监听
    netstat -tlnp | grep -E ':(8080|5432|7687|6379|9092)'
    
    # 检查DNS解析
    nslookup postgres
    nslookup neo4j
    nslookup redis
}

# 磁盘空间检查
check_disk() {
    echo "磁盘空间检查..."
    df -h
    
    echo -e "\n大文件查找..."
    find /var/lib/docker -size +1G -exec ls -lh {} \;
    
    echo -e "\n日志文件大小..."
    du -sh /var/log/* | sort -rh | head -10
}

# 性能诊断
performance_diagnosis() {
    echo "性能诊断..."
    
    # CPU使用率
    top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1
    
    # 负载平均值
    uptime
    
    # I/O等待
    iostat -x 1 1
}

# 数据库连接检查
check_database_connections() {
    echo "数据库连接检查..."
    
    # PostgreSQL连接数
    docker exec postgres psql -U iot_user -d iot_semantic -c "SELECT count(*) FROM pg_stat_activity;"
    
    # Redis连接数
    docker exec redis redis-cli info clients
    
    # Neo4j连接数
    docker exec neo4j cypher-shell "CALL dbms.listConnections() YIELD connectionId, username, protocol, clientAddress"
}

case "$1" in
    services)
        check_services
        ;;
    memory)
        analyze_memory
        ;;
    network)
        check_network
        ;;
    disk)
        check_disk
        ;;
    performance)
        performance_diagnosis
        ;;
    database)
        check_database_connections
        ;;
    all)
        check_services
        analyze_memory
        check_network
        check_disk
        performance_diagnosis
        check_database_connections
        ;;
    *)
        echo "Usage: $0 {services|memory|network|disk|performance|database|all}"
        exit 1
        ;;
esac
```

## 10. 升级维护

### 10.1 滚动升级脚本

```bash
#!/bin/bash
# rolling-update.sh

VERSION=${1:-latest}
NAMESPACE=${2:-iot-semantic}

rolling_update() {
    local service=$1
    local new_image=$2
    
    echo "开始滚动升级 $service 到版本 $VERSION..."
    
    # 更新镜像
    kubectl set image deployment/$service $service=$new_image -n $NAMESPACE
    
    # 等待升级完成
    kubectl rollout status deployment/$service -n $NAMESPACE
    
    # 验证升级
    kubectl get pods -l app=$service -n $NAMESPACE
    
    echo "$service 升级完成"
}

# 升级API网关
rolling_update "api-gateway" "iot-semantic/api-gateway:$VERSION"

# 升级语义处理器
rolling_update "semantic-processor" "iot-semantic/semantic-processor:$VERSION"

# 升级推理引擎
rolling_update "reasoning-engine" "iot-semantic/reasoning-engine:$VERSION"

# 升级协议适配器
rolling_update "protocol-adapters" "iot-semantic/protocol-adapters:$VERSION"

echo "所有服务升级完成"

# 运行健康检查
python3 health_check.py
```

本指南提供了IoT语义互操作项目从开发到生产的完整部署方案，包含详细的配置文件、脚本和最佳实践，可以直接用于项目实施。
