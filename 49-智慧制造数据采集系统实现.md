# 智慧制造数据采集系统实现

## 1. 系统概述

### 1.1 数据采集架构

```text
设备接入层 → 协议转换层 → 数据处理层 → 存储展示层
• 多协议适配   • 统一数据格式  • 实时处理     • 数据仓库
• 设备发现     • 数据验证      • 流式计算     • 可视化展示
• 连接管理     • 格式转换      • 异常检测     • 历史查询
```

### 1.2 核心功能

- **多协议支持**: OPC-UA、Modbus、MQTT、HTTP等
- **实时采集**: 高频数据采集和缓存
- **数据处理**: 清洗、转换、聚合、分析
- **存储管理**: 时序数据库和关系数据库
- **监控告警**: 数据质量监控和异常告警

## 2. 核心组件实现

### 2.1 数据采集器

```rust
// src/manufacturing/data_collector.rs
use std::collections::HashMap;
use tokio::sync::{RwLock, mpsc};
use serde::{Deserialize, Serialize};
use std::sync::Arc;

#[derive(Debug, Clone)]
pub struct DataCollector {
    collectors: HashMap<String, Arc<RwLock<Box<dyn ProtocolCollector>>>>,
    data_processors: Vec<Arc<RwLock<DataProcessor>>>,
    data_storage: Arc<RwLock<DataStorage>>,
    config: CollectorConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollectorConfig {
    pub collection_interval: u64,
    pub batch_size: usize,
    pub max_retries: u32,
    pub timeout_seconds: u64,
    pub buffer_size: usize,
}

impl DataCollector {
    pub async fn new(config: CollectorConfig) -> Self {
        Self {
            collectors: HashMap::new(),
            data_processors: Vec::new(),
            data_storage: Arc::new(RwLock::new(DataStorage::new().await)),
            config,
        }
    }

    pub async fn register_collector(&mut self, id: String, collector: Box<dyn ProtocolCollector>) {
        self.collectors.insert(id, Arc::new(RwLock::new(collector)));
    }

    pub async fn start_collection(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut handles = Vec::new();
        
        for (id, collector) in &self.collectors {
            let collector_clone = collector.clone();
            let storage_clone = self.data_storage.clone();
            let config = self.config.clone();
            let id_clone = id.clone();
            
            let handle = tokio::spawn(async move {
                Self::collection_loop(id_clone, collector_clone, storage_clone, config).await
            });
            
            handles.push(handle);
        }

        // 等待所有采集任务完成
        for handle in handles {
            handle.await??;
        }

        Ok(())
    }

    async fn collection_loop(
        collector_id: String,
        collector: Arc<RwLock<Box<dyn ProtocolCollector>>>,
        storage: Arc<RwLock<DataStorage>>,
        config: CollectorConfig,
    ) {
        let mut interval = tokio::time::interval(
            tokio::time::Duration::from_millis(config.collection_interval)
        );

        loop {
            interval.tick().await;
            
            match Self::collect_data(&collector_id, &collector, &storage, &config).await {
                Ok(_) => {},
                Err(e) => {
                    eprintln!("Collection error for {}: {}", collector_id, e);
                }
            }
        }
    }

    async fn collect_data(
        collector_id: &str,
        collector: &Arc<RwLock<Box<dyn ProtocolCollector>>>,
        storage: &Arc<RwLock<DataStorage>>,
        config: &CollectorConfig,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let data_points = {
            let collector_guard = collector.read().await;
            collector_guard.collect_data().await?
        };

        if !data_points.is_empty() {
            let mut storage_guard = storage.write().await;
            storage_guard.store_data_points(collector_id, data_points).await?;
        }

        Ok(())
    }
}

pub trait ProtocolCollector: Send + Sync {
    async fn collect_data(&self) -> Result<Vec<DataPoint>, Box<dyn std::error::Error>>;
    async fn get_device_info(&self) -> DeviceInfo;
    async fn is_connected(&self) -> bool;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataPoint {
    pub device_id: String,
    pub tag_name: String,
    pub value: DataValue,
    pub quality: DataQuality,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub metadata: HashMap<String, String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataValue {
    Boolean(bool),
    Integer(i64),
    Float(f64),
    String(String),
    Binary(Vec<u8>),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DataQuality {
    Good,
    Bad,
    Uncertain,
    Stale,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceInfo {
    pub device_id: String,
    pub device_name: String,
    pub protocol: String,
    pub connection_string: String,
    pub tags: Vec<TagInfo>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TagInfo {
    pub name: String,
    pub data_type: String,
    pub address: String,
    pub description: String,
    pub unit: Option<String>,
    pub scale_factor: Option<f64>,
}
```

### 2.2 OPC-UA采集器

```rust
// src/manufacturing/opcua_collector.rs
use super::data_collector::*;
use std::collections::HashMap;

pub struct OpcUaCollector {
    endpoint_url: String,
    client: Option<OpcUaClient>,
    subscription_items: Vec<SubscriptionItem>,
    device_info: DeviceInfo,
}

impl OpcUaCollector {
    pub async fn new(endpoint_url: String, device_info: DeviceInfo) -> Self {
        Self {
            endpoint_url,
            client: None,
            subscription_items: Vec::new(),
            device_info,
        }
    }

    pub async fn connect(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        let client = OpcUaClient::new(&self.endpoint_url).await?;
        self.client = Some(client);
        self.setup_subscriptions().await?;
        Ok(())
    }

    async fn setup_subscriptions(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        if let Some(client) = &mut self.client {
            for tag in &self.device_info.tags {
                let item = SubscriptionItem {
                    node_id: tag.address.clone(),
                    tag_name: tag.name.clone(),
                    data_type: tag.data_type.clone(),
                };
                self.subscription_items.push(item);
                client.subscribe_to_node(&tag.address).await?;
            }
        }
        Ok(())
    }
}

impl ProtocolCollector for OpcUaCollector {
    async fn collect_data(&self) -> Result<Vec<DataPoint>, Box<dyn std::error::Error>> {
        let mut data_points = Vec::new();
        
        if let Some(client) = &self.client {
            for item in &self.subscription_items {
                match client.read_value(&item.node_id).await {
                    Ok(value) => {
                        let data_point = DataPoint {
                            device_id: self.device_info.device_id.clone(),
                            tag_name: item.tag_name.clone(),
                            value: self.convert_value(value, &item.data_type),
                            quality: DataQuality::Good,
                            timestamp: chrono::Utc::now(),
                            metadata: HashMap::new(),
                        };
                        data_points.push(data_point);
                    },
                    Err(e) => {
                        eprintln!("Failed to read {}: {}", item.tag_name, e);
                        let data_point = DataPoint {
                            device_id: self.device_info.device_id.clone(),
                            tag_name: item.tag_name.clone(),
                            value: DataValue::String("ERROR".to_string()),
                            quality: DataQuality::Bad,
                            timestamp: chrono::Utc::now(),
                            metadata: HashMap::new(),
                        };
                        data_points.push(data_point);
                    }
                }
            }
        }

        Ok(data_points)
    }

    async fn get_device_info(&self) -> DeviceInfo {
        self.device_info.clone()
    }

    async fn is_connected(&self) -> bool {
        self.client.is_some()
    }
}

impl OpcUaCollector {
    fn convert_value(&self, value: OpcUaValue, data_type: &str) -> DataValue {
        match data_type {
            "Boolean" => DataValue::Boolean(value.as_bool().unwrap_or(false)),
            "Int32" => DataValue::Integer(value.as_i32().unwrap_or(0) as i64),
            "Float" => DataValue::Float(value.as_f32().unwrap_or(0.0) as f64),
            "Double" => DataValue::Float(value.as_f64().unwrap_or(0.0)),
            "String" => DataValue::String(value.as_string().unwrap_or_default()),
            _ => DataValue::String(format!("{:?}", value)),
        }
    }
}

#[derive(Debug, Clone)]
struct SubscriptionItem {
    node_id: String,
    tag_name: String,
    data_type: String,
}

// 简化的OPC-UA客户端实现
struct OpcUaClient {
    endpoint_url: String,
    connected: bool,
}

impl OpcUaClient {
    async fn new(endpoint_url: &str) -> Result<Self, Box<dyn std::error::Error>> {
        Ok(Self {
            endpoint_url: endpoint_url.to_string(),
            connected: true,
        })
    }

    async fn subscribe_to_node(&mut self, node_id: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 实际实现中会创建OPC-UA订阅
        println!("Subscribed to node: {}", node_id);
        Ok(())
    }

    async fn read_value(&self, node_id: &str) -> Result<OpcUaValue, Box<dyn std::error::Error>> {
        // 实际实现中会读取OPC-UA节点值
        Ok(OpcUaValue::Float(42.0))
    }
}

#[derive(Debug, Clone)]
enum OpcUaValue {
    Boolean(bool),
    Int32(i32),
    Float(f32),
    Double(f64),
    String(String),
}

impl OpcUaValue {
    fn as_bool(&self) -> Option<bool> {
        match self {
            OpcUaValue::Boolean(b) => Some(*b),
            _ => None,
        }
    }

    fn as_i32(&self) -> Option<i32> {
        match self {
            OpcUaValue::Int32(i) => Some(*i),
            _ => None,
        }
    }

    fn as_f32(&self) -> Option<f32> {
        match self {
            OpcUaValue::Float(f) => Some(*f),
            _ => None,
        }
    }

    fn as_f64(&self) -> Option<f64> {
        match self {
            OpcUaValue::Double(d) => Some(*d),
            _ => None,
        }
    }

    fn as_string(&self) -> Option<String> {
        match self {
            OpcUaValue::String(s) => Some(s.clone()),
            _ => None,
        }
    }
}
```

### 2.3 Modbus采集器

```rust
// src/manufacturing/modbus_collector.rs
use super::data_collector::*;
use std::collections::HashMap;

pub struct ModbusCollector {
    host: String,
    port: u16,
    slave_id: u8,
    client: Option<ModbusClient>,
    register_map: Vec<RegisterMapping>,
    device_info: DeviceInfo,
}

impl ModbusCollector {
    pub async fn new(host: String, port: u16, slave_id: u8, device_info: DeviceInfo) -> Self {
        Self {
            host,
            port,
            slave_id,
            client: None,
            register_map: Vec::new(),
            device_info,
        }
    }

    pub async fn connect(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        let client = ModbusClient::new(&self.host, self.port, self.slave_id).await?;
        self.client = Some(client);
        self.setup_register_map().await;
        Ok(())
    }

    async fn setup_register_map(&mut self) {
        for tag in &self.device_info.tags {
            if let Ok(address) = tag.address.parse::<u16>() {
                let mapping = RegisterMapping {
                    tag_name: tag.name.clone(),
                    register_type: self.parse_register_type(&tag.data_type),
                    address,
                    data_type: tag.data_type.clone(),
                    scale_factor: tag.scale_factor.unwrap_or(1.0),
                };
                self.register_map.push(mapping);
            }
        }
    }

    fn parse_register_type(&self, data_type: &str) -> RegisterType {
        match data_type {
            "Coil" => RegisterType::Coil,
            "DiscreteInput" => RegisterType::DiscreteInput,
            "InputRegister" => RegisterType::InputRegister,
            _ => RegisterType::HoldingRegister,
        }
    }
}

impl ProtocolCollector for ModbusCollector {
    async fn collect_data(&self) -> Result<Vec<DataPoint>, Box<dyn std::error::Error>> {
        let mut data_points = Vec::new();
        
        if let Some(client) = &self.client {
            for mapping in &self.register_map {
                match self.read_register(client, mapping).await {
                    Ok(value) => {
                        let data_point = DataPoint {
                            device_id: self.device_info.device_id.clone(),
                            tag_name: mapping.tag_name.clone(),
                            value,
                            quality: DataQuality::Good,
                            timestamp: chrono::Utc::now(),
                            metadata: HashMap::new(),
                        };
                        data_points.push(data_point);
                    },
                    Err(e) => {
                        eprintln!("Failed to read register {}: {}", mapping.address, e);
                        let data_point = DataPoint {
                            device_id: self.device_info.device_id.clone(),
                            tag_name: mapping.tag_name.clone(),
                            value: DataValue::String("ERROR".to_string()),
                            quality: DataQuality::Bad,
                            timestamp: chrono::Utc::now(),
                            metadata: HashMap::new(),
                        };
                        data_points.push(data_point);
                    }
                }
            }
        }

        Ok(data_points)
    }

    async fn get_device_info(&self) -> DeviceInfo {
        self.device_info.clone()
    }

    async fn is_connected(&self) -> bool {
        self.client.is_some()
    }
}

impl ModbusCollector {
    async fn read_register(&self, client: &ModbusClient, mapping: &RegisterMapping) -> Result<DataValue, Box<dyn std::error::Error>> {
        match mapping.register_type {
            RegisterType::Coil => {
                let value = client.read_coil(mapping.address).await?;
                Ok(DataValue::Boolean(value))
            },
            RegisterType::DiscreteInput => {
                let value = client.read_discrete_input(mapping.address).await?;
                Ok(DataValue::Boolean(value))
            },
            RegisterType::InputRegister => {
                let value = client.read_input_register(mapping.address).await?;
                let scaled_value = value as f64 * mapping.scale_factor;
                Ok(DataValue::Float(scaled_value))
            },
            RegisterType::HoldingRegister => {
                let value = client.read_holding_register(mapping.address).await?;
                let scaled_value = value as f64 * mapping.scale_factor;
                Ok(DataValue::Float(scaled_value))
            },
        }
    }
}

#[derive(Debug, Clone)]
struct RegisterMapping {
    tag_name: String,
    register_type: RegisterType,
    address: u16,
    data_type: String,
    scale_factor: f64,
}

#[derive(Debug, Clone)]
enum RegisterType {
    Coil,
    DiscreteInput,
    InputRegister,
    HoldingRegister,
}

// 简化的Modbus客户端实现
struct ModbusClient {
    host: String,
    port: u16,
    slave_id: u8,
}

impl ModbusClient {
    async fn new(host: &str, port: u16, slave_id: u8) -> Result<Self, Box<dyn std::error::Error>> {
        Ok(Self {
            host: host.to_string(),
            port,
            slave_id,
        })
    }

    async fn read_coil(&self, address: u16) -> Result<bool, Box<dyn std::error::Error>> {
        // 实际实现中会通过Modbus协议读取线圈
        Ok(true)
    }

    async fn read_discrete_input(&self, address: u16) -> Result<bool, Box<dyn std::error::Error>> {
        // 实际实现中会通过Modbus协议读取离散输入
        Ok(false)
    }

    async fn read_input_register(&self, address: u16) -> Result<u16, Box<dyn std::error::Error>> {
        // 实际实现中会通过Modbus协议读取输入寄存器
        Ok(1234)
    }

    async fn read_holding_register(&self, address: u16) -> Result<u16, Box<dyn std::error::Error>> {
        // 实际实现中会通过Modbus协议读取保持寄存器
        Ok(5678)
    }
}
```

### 2.4 数据处理器

```rust
// src/manufacturing/data_processor.rs
use super::data_collector::*;
use std::collections::{HashMap, VecDeque};
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone)]
pub struct DataProcessor {
    processors: Vec<Box<dyn DataProcessorTrait>>,
    buffer: VecDeque<DataPoint>,
    config: ProcessorConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessorConfig {
    pub buffer_size: usize,
    pub processing_interval: u64,
    pub enable_filtering: bool,
    pub enable_aggregation: bool,
    pub enable_validation: bool,
}

impl DataProcessor {
    pub async fn new(config: ProcessorConfig) -> Self {
        let mut processors: Vec<Box<dyn DataProcessorTrait>> = Vec::new();
        
        if config.enable_filtering {
            processors.push(Box::new(DataFilter::new()));
        }
        
        if config.enable_validation {
            processors.push(Box::new(DataValidator::new()));
        }
        
        if config.enable_aggregation {
            processors.push(Box::new(DataAggregator::new()));
        }

        Self {
            processors,
            buffer: VecDeque::with_capacity(config.buffer_size),
            config,
        }
    }

    pub async fn process_data(&mut self, data_points: Vec<DataPoint>) -> Vec<DataPoint> {
        // 添加到缓冲区
        for point in data_points {
            if self.buffer.len() >= self.config.buffer_size {
                self.buffer.pop_front();
            }
            self.buffer.push_back(point);
        }

        // 处理数据
        let mut processed_data: Vec<DataPoint> = self.buffer.iter().cloned().collect();
        
        for processor in &self.processors {
            processed_data = processor.process(processed_data).await;
        }

        processed_data
    }
}

pub trait DataProcessorTrait: Send + Sync {
    async fn process(&self, data_points: Vec<DataPoint>) -> Vec<DataPoint>;
}

// 数据过滤器
pub struct DataFilter {
    filters: Vec<FilterRule>,
}

impl DataFilter {
    pub fn new() -> Self {
        Self {
            filters: vec![
                FilterRule::QualityFilter,
                FilterRule::RangeFilter { min: -1000.0, max: 10000.0 },
                FilterRule::DuplicateFilter,
            ],
        }
    }
}

impl DataProcessorTrait for DataFilter {
    async fn process(&self, data_points: Vec<DataPoint>) -> Vec<DataPoint> {
        let mut filtered_points = data_points;
        
        for filter in &self.filters {
            filtered_points = self.apply_filter(filtered_points, filter);
        }
        
        filtered_points
    }
}

impl DataFilter {
    fn apply_filter(&self, data_points: Vec<DataPoint>, filter: &FilterRule) -> Vec<DataPoint> {
        match filter {
            FilterRule::QualityFilter => {
                data_points.into_iter()
                    .filter(|point| matches!(point.quality, DataQuality::Good))
                    .collect()
            },
            FilterRule::RangeFilter { min, max } => {
                data_points.into_iter()
                    .filter(|point| {
                        match &point.value {
                            DataValue::Float(f) => f >= min && f <= max,
                            DataValue::Integer(i) => *i as f64 >= *min && (*i as f64) <= *max,
                            _ => true,
                        }
                    })
                    .collect()
            },
            FilterRule::DuplicateFilter => {
                let mut seen = HashMap::new();
                data_points.into_iter()
                    .filter(|point| {
                        let key = format!("{}_{}", point.device_id, point.tag_name);
                        let is_duplicate = seen.contains_key(&key);
                        seen.insert(key, point.timestamp);
                        !is_duplicate
                    })
                    .collect()
            },
        }
    }
}

#[derive(Debug, Clone)]
enum FilterRule {
    QualityFilter,
    RangeFilter { min: f64, max: f64 },
    DuplicateFilter,
}

// 数据验证器
pub struct DataValidator {
    validation_rules: Vec<ValidationRule>,
}

impl DataValidator {
    pub fn new() -> Self {
        Self {
            validation_rules: vec![
                ValidationRule::NotNull,
                ValidationRule::TypeConsistency,
                ValidationRule::TimestampValidation,
            ],
        }
    }
}

impl DataProcessorTrait for DataValidator {
    async fn process(&self, data_points: Vec<DataPoint>) -> Vec<DataPoint> {
        data_points.into_iter()
            .map(|mut point| {
                for rule in &self.validation_rules {
                    if !self.validate_point(&point, rule) {
                        point.quality = DataQuality::Bad;
                        break;
                    }
                }
                point
            })
            .collect()
    }
}

impl DataValidator {
    fn validate_point(&self, point: &DataPoint, rule: &ValidationRule) -> bool {
        match rule {
            ValidationRule::NotNull => {
                !matches!(point.value, DataValue::String(ref s) if s.is_empty())
            },
            ValidationRule::TypeConsistency => {
                // 检查数据类型一致性
                true // 简化实现
            },
            ValidationRule::TimestampValidation => {
                let now = chrono::Utc::now();
                let diff = (now - point.timestamp).num_seconds().abs();
                diff < 3600 // 1小时内的数据
            },
        }
    }
}

#[derive(Debug, Clone)]
enum ValidationRule {
    NotNull,
    TypeConsistency,
    TimestampValidation,
}

// 数据聚合器
pub struct DataAggregator {
    aggregation_window: chrono::Duration,
    aggregation_functions: Vec<AggregationFunction>,
}

impl DataAggregator {
    pub fn new() -> Self {
        Self {
            aggregation_window: chrono::Duration::minutes(1),
            aggregation_functions: vec![
                AggregationFunction::Average,
                AggregationFunction::Min,
                AggregationFunction::Max,
                AggregationFunction::Count,
            ],
        }
    }
}

impl DataProcessorTrait for DataAggregator {
    async fn process(&self, data_points: Vec<DataPoint>) -> Vec<DataPoint> {
        let mut aggregated_points = Vec::new();
        
        // 按设备和标签分组
        let mut groups: HashMap<String, Vec<DataPoint>> = HashMap::new();
        for point in data_points {
            let key = format!("{}_{}", point.device_id, point.tag_name);
            groups.entry(key).or_insert_with(Vec::new).push(point);
        }

        // 对每个组进行聚合
        for (key, points) in groups {
            if points.is_empty() {
                continue;
            }

            let device_id = points[0].device_id.clone();
            let tag_name = points[0].tag_name.clone();
            
            for func in &self.aggregation_functions {
                if let Some(aggregated_point) = self.aggregate_points(&points, func, &device_id, &tag_name) {
                    aggregated_points.push(aggregated_point);
                }
            }
        }

        aggregated_points
    }
}

impl DataAggregator {
    fn aggregate_points(&self, points: &[DataPoint], func: &AggregationFunction, device_id: &str, tag_name: &str) -> Option<DataPoint> {
        if points.is_empty() {
            return None;
        }

        let numeric_values: Vec<f64> = points.iter()
            .filter_map(|p| match &p.value {
                DataValue::Float(f) => Some(*f),
                DataValue::Integer(i) => Some(*i as f64),
                _ => None,
            })
            .collect();

        if numeric_values.is_empty() {
            return None;
        }

        let aggregated_value = match func {
            AggregationFunction::Average => {
                let sum: f64 = numeric_values.iter().sum();
                sum / numeric_values.len() as f64
            },
            AggregationFunction::Min => {
                numeric_values.iter().fold(f64::INFINITY, |a, &b| a.min(b))
            },
            AggregationFunction::Max => {
                numeric_values.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b))
            },
            AggregationFunction::Count => {
                numeric_values.len() as f64
            },
        };

        let aggregated_tag_name = format!("{}_{}", tag_name, func.to_string().to_lowercase());

        Some(DataPoint {
            device_id: device_id.to_string(),
            tag_name: aggregated_tag_name,
            value: DataValue::Float(aggregated_value),
            quality: DataQuality::Good,
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        })
    }
}

#[derive(Debug, Clone)]
enum AggregationFunction {
    Average,
    Min,
    Max,
    Count,
}

impl AggregationFunction {
    fn to_string(&self) -> &'static str {
        match self {
            AggregationFunction::Average => "AVG",
            AggregationFunction::Min => "MIN",
            AggregationFunction::Max => "MAX",
            AggregationFunction::Count => "COUNT",
        }
    }
}
```

### 2.5 数据存储

```rust
// src/manufacturing/data_storage.rs
use super::data_collector::*;
use std::collections::HashMap;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone)]
pub struct DataStorage {
    time_series_db: TimeSeriesDB,
    relational_db: RelationalDB,
    config: StorageConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageConfig {
    pub time_series_retention_days: u32,
    pub batch_size: usize,
    pub compression_enabled: bool,
    pub backup_enabled: bool,
}

impl DataStorage {
    pub async fn new() -> Self {
        Self {
            time_series_db: TimeSeriesDB::new().await,
            relational_db: RelationalDB::new().await,
            config: StorageConfig {
                time_series_retention_days: 365,
                batch_size: 1000,
                compression_enabled: true,
                backup_enabled: true,
            },
        }
    }

    pub async fn store_data_points(&mut self, collector_id: &str, data_points: Vec<DataPoint>) -> Result<(), Box<dyn std::error::Error>> {
        // 存储到时序数据库
        self.time_series_db.insert_data_points(data_points.clone()).await?;
        
        // 存储设备信息到关系数据库
        for point in &data_points {
            self.relational_db.update_device_status(&point.device_id, &point.timestamp).await?;
        }

        println!("Stored {} data points from collector {}", data_points.len(), collector_id);
        Ok(())
    }

    pub async fn query_data(&self, query: DataQuery) -> Result<Vec<DataPoint>, Box<dyn std::error::Error>> {
        self.time_series_db.query_data(query).await
    }

    pub async fn get_device_list(&self) -> Result<Vec<String>, Box<dyn std::error::Error>> {
        self.relational_db.get_device_list().await
    }
}

// 时序数据库
#[derive(Debug, Clone)]
pub struct TimeSeriesDB {
    // 实际实现中会连接到InfluxDB、TimescaleDB等
    data_store: HashMap<String, Vec<DataPoint>>,
}

impl TimeSeriesDB {
    pub async fn new() -> Self {
        Self {
            data_store: HashMap::new(),
        }
    }

    pub async fn insert_data_points(&mut self, data_points: Vec<DataPoint>) -> Result<(), Box<dyn std::error::Error>> {
        for point in data_points {
            let key = format!("{}_{}", point.device_id, point.tag_name);
            self.data_store.entry(key).or_insert_with(Vec::new).push(point);
        }
        Ok(())
    }

    pub async fn query_data(&self, query: DataQuery) -> Result<Vec<DataPoint>, Box<dyn std::error::Error>> {
        let mut results = Vec::new();
        
        for (key, points) in &self.data_store {
            if self.matches_query(key, &query) {
                for point in points {
                    if point.timestamp >= query.start_time && point.timestamp <= query.end_time {
                        results.push(point.clone());
                    }
                }
            }
        }

        // 按时间排序
        results.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));
        
        // 应用限制
        if let Some(limit) = query.limit {
            results.truncate(limit);
        }

        Ok(results)
    }

    fn matches_query(&self, key: &str, query: &DataQuery) -> bool {
        if let Some(device_id) = &query.device_id {
            if !key.starts_with(device_id) {
                return false;
            }
        }

        if let Some(tag_name) = &query.tag_name {
            if !key.ends_with(tag_name) {
                return false;
            }
        }

        true
    }
}

// 关系数据库
#[derive(Debug, Clone)]
pub struct RelationalDB {
    // 实际实现中会连接到PostgreSQL、MySQL等
    device_status: HashMap<String, DeviceStatus>,
}

impl RelationalDB {
    pub async fn new() -> Self {
        Self {
            device_status: HashMap::new(),
        }
    }

    pub async fn update_device_status(&mut self, device_id: &str, last_seen: &chrono::DateTime<chrono::Utc>) -> Result<(), Box<dyn std::error::Error>> {
        let status = self.device_status.entry(device_id.to_string()).or_insert_with(|| DeviceStatus {
            device_id: device_id.to_string(),
            is_online: true,
            last_seen: *last_seen,
            total_data_points: 0,
        });

        status.last_seen = *last_seen;
        status.total_data_points += 1;
        status.is_online = true;

        Ok(())
    }

    pub async fn get_device_list(&self) -> Result<Vec<String>, Box<dyn std::error::Error>> {
        Ok(self.device_status.keys().cloned().collect())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DataQuery {
    pub device_id: Option<String>,
    pub tag_name: Option<String>,
    pub start_time: chrono::DateTime<chrono::Utc>,
    pub end_time: chrono::DateTime<chrono::Utc>,
    pub limit: Option<usize>,
    pub aggregation: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceStatus {
    pub device_id: String,
    pub is_online: bool,
    pub last_seen: chrono::DateTime<chrono::Utc>,
    pub total_data_points: u64,
}
```

## 3. 配置文件

### 3.1 采集配置

```yaml
# config/data_collection.yaml
data_collection:
  collection_interval: 1000  # 毫秒
  batch_size: 100
  max_retries: 3
  timeout_seconds: 30
  buffer_size: 10000

  processors:
    enable_filtering: true
    enable_validation: true
    enable_aggregation: true
    processing_interval: 5000  # 毫秒

  storage:
    time_series_retention_days: 365
    batch_size: 1000
    compression_enabled: true
    backup_enabled: true

devices:
  - id: "plc_001"
    name: "PLC控制器1"
    protocol: "modbus_tcp"
    connection:
      host: "192.168.1.100"
      port: 502
      slave_id: 1
    tags:
      - name: "temperature"
        address: "40001"
        data_type: "HoldingRegister"
        unit: "celsius"
        scale_factor: 0.1
      - name: "pressure"
        address: "40002"
        data_type: "HoldingRegister"
        unit: "bar"
        scale_factor: 0.01

  - id: "opcua_server_001"
    name: "OPC-UA服务器1"
    protocol: "opcua"
    connection:
      endpoint_url: "opc.tcp://192.168.1.101:4840"
    tags:
      - name: "motor_speed"
        address: "ns=2;i=1001"
        data_type: "Float"
        unit: "rpm"
      - name: "motor_current"
        address: "ns=2;i=1002"
        data_type: "Float"
        unit: "ampere"
```

## 4. 测试验证

### 4.1 采集器测试

```rust
// tests/data_collection_tests.rs
#[cfg(test)]
mod tests {
    use super::*;
    use tokio_test;

    #[tokio::test]
    async fn test_data_collector_creation() {
        let config = CollectorConfig {
            collection_interval: 1000,
            batch_size: 100,
            max_retries: 3,
            timeout_seconds: 30,
            buffer_size: 1000,
        };

        let collector = DataCollector::new(config).await;
        assert_eq!(collector.collectors.len(), 0);
    }

    #[tokio::test]
    async fn test_modbus_collector() {
        let device_info = create_test_device_info();
        let mut collector = ModbusCollector::new(
            "127.0.0.1".to_string(),
            502,
            1,
            device_info
        ).await;

        // 测试连接（实际测试需要Modbus服务器）
        // let result = collector.connect().await;
        // assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_data_processor() {
        let config = ProcessorConfig {
            buffer_size: 1000,
            processing_interval: 1000,
            enable_filtering: true,
            enable_aggregation: true,
            enable_validation: true,
        };

        let mut processor = DataProcessor::new(config).await;
        let test_data = create_test_data_points();
        
        let processed_data = processor.process_data(test_data).await;
        assert!(!processed_data.is_empty());
    }

    #[tokio::test]
    async fn test_data_storage() {
        let mut storage = DataStorage::new().await;
        let test_data = create_test_data_points();
        
        let result = storage.store_data_points("test_collector", test_data).await;
        assert!(result.is_ok());

        let devices = storage.get_device_list().await.unwrap();
        assert!(!devices.is_empty());
    }

    fn create_test_device_info() -> DeviceInfo {
        DeviceInfo {
            device_id: "test_device".to_string(),
            device_name: "测试设备".to_string(),
            protocol: "modbus_tcp".to_string(),
            connection_string: "192.168.1.100:502".to_string(),
            tags: vec![
                TagInfo {
                    name: "temperature".to_string(),
                    data_type: "HoldingRegister".to_string(),
                    address: "40001".to_string(),
                    description: "温度传感器".to_string(),
                    unit: Some("celsius".to_string()),
                    scale_factor: Some(0.1),
                }
            ],
        }
    }

    fn create_test_data_points() -> Vec<DataPoint> {
        vec![
            DataPoint {
                device_id: "test_device".to_string(),
                tag_name: "temperature".to_string(),
                value: DataValue::Float(25.5),
                quality: DataQuality::Good,
                timestamp: chrono::Utc::now(),
                metadata: HashMap::new(),
            }
        ]
    }
}
```

## 5. API接口

### 5.1 数据采集API

```rust
// src/api/data_collection_api.rs
use axum::{
    routing::{get, post},
    Router, Json, extract::{Path, Query},
    response::Json as ResponseJson,
};
use serde::{Deserialize, Serialize};

pub fn create_data_collection_routes() -> Router {
    Router::new()
        .route("/api/data-collection/devices", get(list_devices).post(register_device))
        .route("/api/data-collection/devices/:id", get(get_device).delete(remove_device))
        .route("/api/data-collection/devices/:id/data", get(get_device_data))
        .route("/api/data-collection/data", get(query_data))
        .route("/api/data-collection/status", get(get_collection_status))
        .route("/api/data-collection/start", post(start_collection))
        .route("/api/data-collection/stop", post(stop_collection))
}

#[derive(Deserialize)]
struct DataQuery {
    device_id: Option<String>,
    tag_name: Option<String>,
    start_time: Option<String>,
    end_time: Option<String>,
    limit: Option<usize>,
}

async fn list_devices() -> ResponseJson<Vec<DeviceInfo>> {
    // 实现设备列表查询
    ResponseJson(vec![])
}

async fn register_device(Json(device_info): Json<DeviceInfo>) -> ResponseJson<String> {
    // 实现设备注册
    ResponseJson("设备注册成功".to_string())
}

async fn get_device(Path(id): Path<String>) -> ResponseJson<Option<DeviceInfo>> {
    // 实现获取单个设备信息
    ResponseJson(None)
}

async fn get_device_data(Path(id): Path<String>, Query(query): Query<DataQuery>) -> ResponseJson<Vec<DataPoint>> {
    // 实现设备数据查询
    ResponseJson(vec![])
}

async fn query_data(Query(query): Query<DataQuery>) -> ResponseJson<Vec<DataPoint>> {
    // 实现数据查询
    ResponseJson(vec![])
}

async fn get_collection_status() -> ResponseJson<CollectionStatus> {
    // 实现采集状态查询
    ResponseJson(CollectionStatus {
        total_devices: 0,
        online_devices: 0,
        total_data_points: 0,
        data_rate: 0.0,
    })
}

async fn start_collection() -> ResponseJson<String> {
    // 实现启动数据采集
    ResponseJson("数据采集已启动".to_string())
}

async fn stop_collection() -> ResponseJson<String> {
    // 实现停止数据采集
    ResponseJson("数据采集已停止".to_string())
}

#[derive(Serialize)]
struct CollectionStatus {
    total_devices: usize,
    online_devices: usize,
    total_data_points: u64,
    data_rate: f64,
}
```

## 6. 总结

智慧制造数据采集系统实现了：

1. **多协议支持**: OPC-UA、Modbus、MQTT等工业协议
2. **实时数据处理**: 过滤、验证、聚合等数据处理功能
3. **高效存储**: 时序数据库和关系数据库的混合存储
4. **可扩展架构**: 插件式的协议采集器和数据处理器
5. **监控告警**: 数据质量监控和设备状态监控
6. **RESTful API**: 完整的数据查询和管理接口

该系统为智慧制造提供了可靠的数据基础，支持实时监控、历史分析和智能决策。
