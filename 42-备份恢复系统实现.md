# IoT系统备份恢复详细实现

## 1. 系统架构

### 1.1 备份架构

```
数据源层 → 备份处理层 → 存储层 → 恢复验证层
• 数据库    • 备份调度   • 本地存储  • 完整性检查
• 文件系统  • 增量备份   • 云存储    • 恢复测试
• 配置文件  • 压缩加密   • 异地备份  • 监控告警
```

### 1.2 备份策略

- **全量备份**: 每周一次完整数据备份
- **增量备份**: 每日增量数据备份
- **实时备份**: 关键数据实时同步
- **配置备份**: 系统配置定期备份

## 2. 核心组件实现

### 2.1 备份管理器

```rust
// src/backup/backup_manager.rs
use serde::{Serialize, Deserialize};
use tokio::time::{interval, Duration};
use std::collections::HashMap;
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackupType {
    Full,
    Incremental,
    Differential,
    Configuration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BackupStatus {
    Pending,
    Running,
    Completed,
    Failed,
    Cancelled,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackupJob {
    pub id: String,
    pub name: String,
    pub backup_type: BackupType,
    pub source_path: String,
    pub destination: String,
    pub schedule: String, // Cron expression
    pub retention_days: u32,
    pub compression: bool,
    pub encryption: bool,
    pub enabled: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BackupRecord {
    pub id: String,
    pub job_id: String,
    pub backup_type: BackupType,
    pub start_time: DateTime<Utc>,
    pub end_time: Option<DateTime<Utc>>,
    pub status: BackupStatus,
    pub file_path: String,
    pub file_size: u64,
    pub checksum: String,
    pub error_message: Option<String>,
}

pub struct BackupManager {
    jobs: HashMap<String, BackupJob>,
    records: Vec<BackupRecord>,
    storage_backends: HashMap<String, Box<dyn StorageBackend>>,
    scheduler: BackupScheduler,
}

impl BackupManager {
    pub fn new() -> Self {
        BackupManager {
            jobs: HashMap::new(),
            records: Vec::new(),
            storage_backends: HashMap::new(),
            scheduler: BackupScheduler::new(),
        }
    }
    
    pub fn add_job(&mut self, job: BackupJob) -> Result<(), Box<dyn std::error::Error>> {
        self.scheduler.schedule_job(&job)?;
        self.jobs.insert(job.id.clone(), job);
        Ok(())
    }
    
    pub fn remove_job(&mut self, job_id: &str) -> Result<(), Box<dyn std::error::Error>> {
        if let Some(job) = self.jobs.remove(job_id) {
            self.scheduler.unschedule_job(&job)?;
        }
        Ok(())
    }
    
    pub async fn execute_backup(&mut self, job_id: &str) -> Result<String, Box<dyn std::error::Error>> {
        let job = self.jobs.get(job_id)
            .ok_or("备份任务不存在")?
            .clone();
        
        let record_id = uuid::Uuid::new_v4().to_string();
        let mut record = BackupRecord {
            id: record_id.clone(),
            job_id: job.id.clone(),
            backup_type: job.backup_type.clone(),
            start_time: Utc::now(),
            end_time: None,
            status: BackupStatus::Running,
            file_path: String::new(),
            file_size: 0,
            checksum: String::new(),
            error_message: None,
        };
        
        println!("开始执行备份任务: {}", job.name);
        
        match self.perform_backup(&job, &mut record).await {
            Ok(()) => {
                record.status = BackupStatus::Completed;
                record.end_time = Some(Utc::now());
                println!("备份任务完成: {}", job.name);
            }
            Err(e) => {
                record.status = BackupStatus::Failed;
                record.end_time = Some(Utc::now());
                record.error_message = Some(e.to_string());
                eprintln!("备份任务失败: {} - {}", job.name, e);
            }
        }
        
        self.records.push(record);
        self.cleanup_old_backups(&job).await?;
        
        Ok(record_id)
    }
    
    async fn perform_backup(&self, job: &BackupJob, record: &mut BackupRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 创建备份文件名
        let timestamp = Utc::now().format("%Y%m%d_%H%M%S");
        let backup_filename = format!("{}_{}.tar.gz", job.name, timestamp);
        let backup_path = format!("{}/{}", job.destination, backup_filename);
        
        // 执行备份
        match job.backup_type {
            BackupType::Full => self.full_backup(&job.source_path, &backup_path, job.compression).await?,
            BackupType::Incremental => self.incremental_backup(&job.source_path, &backup_path).await?,
            BackupType::Differential => self.differential_backup(&job.source_path, &backup_path).await?,
            BackupType::Configuration => self.config_backup(&job.source_path, &backup_path).await?,
        }
        
        // 获取文件信息
        let metadata = tokio::fs::metadata(&backup_path).await?;
        record.file_path = backup_path.clone();
        record.file_size = metadata.len();
        
        // 计算校验和
        record.checksum = self.calculate_checksum(&backup_path).await?;
        
        // 加密（如果启用）
        if job.encryption {
            self.encrypt_backup(&backup_path).await?;
        }
        
        // 上传到远程存储
        if let Some(backend) = self.storage_backends.get("remote") {
            backend.upload(&backup_path, &backup_filename).await?;
        }
        
        Ok(())
    }
    
    async fn full_backup(&self, source: &str, destination: &str, compress: bool) -> Result<(), Box<dyn std::error::Error>> {
        let mut cmd = tokio::process::Command::new("tar");
        
        if compress {
            cmd.arg("-czf");
        } else {
            cmd.arg("-cf");
        }
        
        cmd.arg(destination).arg("-C").arg(source).arg(".");
        
        let output = cmd.output().await?;
        
        if !output.status.success() {
            return Err(format!("备份失败: {}", String::from_utf8_lossy(&output.stderr)).into());
        }
        
        Ok(())
    }
    
    async fn incremental_backup(&self, source: &str, destination: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 查找上次备份时间
        let last_backup_time = self.get_last_backup_time(source).await?;
        
        let cmd = tokio::process::Command::new("find")
            .arg(source)
            .arg("-newer")
            .arg(format!("@{}", last_backup_time.timestamp()))
            .arg("-type")
            .arg("f")
            .output()
            .await?;
        
        if !cmd.status.success() {
            return Err("查找增量文件失败".into());
        }
        
        let files = String::from_utf8(cmd.stdout)?;
        if files.trim().is_empty() {
            println!("没有需要增量备份的文件");
            return Ok(());
        }
        
        // 创建增量备份
        let tar_cmd = tokio::process::Command::new("tar")
            .arg("-czf")
            .arg(destination)
            .arg("-T")
            .arg("-")
            .stdin(std::process::Stdio::piped())
            .spawn()?;
        
        // 写入文件列表
        if let Some(mut stdin) = tar_cmd.stdin.take() {
            use tokio::io::AsyncWriteExt;
            stdin.write_all(files.as_bytes()).await?;
        }
        
        Ok(())
    }
    
    async fn differential_backup(&self, source: &str, destination: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 查找上次全量备份时间
        let last_full_backup = self.get_last_full_backup_time(source).await?;
        
        let cmd = tokio::process::Command::new("find")
            .arg(source)
            .arg("-newer")
            .arg(format!("@{}", last_full_backup.timestamp()))
            .arg("-type")
            .arg("f")
            .output()
            .await?;
        
        let files = String::from_utf8(cmd.stdout)?;
        
        // 创建差异备份
        let tar_cmd = tokio::process::Command::new("tar")
            .arg("-czf")
            .arg(destination)
            .arg("-T")
            .arg("-")
            .stdin(std::process::Stdio::piped())
            .spawn()?;
        
        if let Some(mut stdin) = tar_cmd.stdin.take() {
            use tokio::io::AsyncWriteExt;
            stdin.write_all(files.as_bytes()).await?;
        }
        
        Ok(())
    }
    
    async fn config_backup(&self, source: &str, destination: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 备份配置文件
        let config_files = vec![
            "config/",
            "secrets/",
            "k8s/",
            ".env",
            "docker-compose.yml",
        ];
        
        let mut cmd = tokio::process::Command::new("tar");
        cmd.arg("-czf").arg(destination);
        
        for file in config_files {
            let path = format!("{}/{}", source, file);
            if tokio::fs::metadata(&path).await.is_ok() {
                cmd.arg(&path);
            }
        }
        
        let output = cmd.output().await?;
        
        if !output.status.success() {
            return Err(format!("配置备份失败: {}", String::from_utf8_lossy(&output.stderr)).into());
        }
        
        Ok(())
    }
    
    async fn calculate_checksum(&self, file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let output = tokio::process::Command::new("sha256sum")
            .arg(file_path)
            .output()
            .await?;
        
        if !output.status.success() {
            return Err("计算校验和失败".into());
        }
        
        let checksum = String::from_utf8(output.stdout)?;
        Ok(checksum.split_whitespace().next().unwrap_or("").to_string())
    }
    
    async fn encrypt_backup(&self, file_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        let encrypted_path = format!("{}.enc", file_path);
        
        let output = tokio::process::Command::new("gpg")
            .arg("--symmetric")
            .arg("--cipher-algo")
            .arg("AES256")
            .arg("--output")
            .arg(&encrypted_path)
            .arg(file_path)
            .output()
            .await?;
        
        if !output.status.success() {
            return Err("加密失败".into());
        }
        
        // 删除原始文件
        tokio::fs::remove_file(file_path).await?;
        tokio::fs::rename(&encrypted_path, file_path).await?;
        
        Ok(())
    }
    
    async fn cleanup_old_backups(&self, job: &BackupJob) -> Result<(), Box<dyn std::error::Error>> {
        let cutoff_time = Utc::now() - chrono::Duration::days(job.retention_days as i64);
        
        let mut dir = tokio::fs::read_dir(&job.destination).await?;
        while let Some(entry) = dir.next_entry().await? {
            let metadata = entry.metadata().await?;
            if let Ok(modified) = metadata.modified() {
                let modified_time: DateTime<Utc> = modified.into();
                if modified_time < cutoff_time {
                    tokio::fs::remove_file(entry.path()).await?;
                    println!("删除过期备份: {:?}", entry.path());
                }
            }
        }
        
        Ok(())
    }
    
    async fn get_last_backup_time(&self, _source: &str) -> Result<DateTime<Utc>, Box<dyn std::error::Error>> {
        // 从记录中查找上次备份时间
        let last_backup = self.records
            .iter()
            .filter(|r| r.status == BackupStatus::Completed)
            .max_by_key(|r| r.start_time);
        
        Ok(last_backup.map(|r| r.start_time).unwrap_or_else(|| Utc::now() - chrono::Duration::days(1)))
    }
    
    async fn get_last_full_backup_time(&self, _source: &str) -> Result<DateTime<Utc>, Box<dyn std::error::Error>> {
        let last_full_backup = self.records
            .iter()
            .filter(|r| r.status == BackupStatus::Completed && matches!(r.backup_type, BackupType::Full))
            .max_by_key(|r| r.start_time);
        
        Ok(last_full_backup.map(|r| r.start_time).unwrap_or_else(|| Utc::now() - chrono::Duration::days(7)))
    }
}
```

### 2.2 恢复管理器

```rust
// src/backup/restore_manager.rs
use serde::{Serialize, Deserialize};
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RestoreType {
    Full,
    Selective,
    PointInTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RestoreJob {
    pub id: String,
    pub backup_id: String,
    pub restore_type: RestoreType,
    pub source_backup: String,
    pub destination: String,
    pub files_to_restore: Option<Vec<String>>,
    pub point_in_time: Option<DateTime<Utc>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RestoreRecord {
    pub id: String,
    pub job_id: String,
    pub start_time: DateTime<Utc>,
    pub end_time: Option<DateTime<Utc>>,
    pub status: BackupStatus,
    pub files_restored: u32,
    pub bytes_restored: u64,
    pub error_message: Option<String>,
}

pub struct RestoreManager {
    restore_records: Vec<RestoreRecord>,
}

impl RestoreManager {
    pub fn new() -> Self {
        RestoreManager {
            restore_records: Vec::new(),
        }
    }
    
    pub async fn execute_restore(&mut self, job: RestoreJob) -> Result<String, Box<dyn std::error::Error>> {
        let record_id = uuid::Uuid::new_v4().to_string();
        let mut record = RestoreRecord {
            id: record_id.clone(),
            job_id: job.id.clone(),
            start_time: Utc::now(),
            end_time: None,
            status: BackupStatus::Running,
            files_restored: 0,
            bytes_restored: 0,
            error_message: None,
        };
        
        println!("开始执行恢复任务: {}", job.id);
        
        // 验证备份文件
        self.verify_backup(&job.source_backup).await?;
        
        match self.perform_restore(&job, &mut record).await {
            Ok(()) => {
                record.status = BackupStatus::Completed;
                record.end_time = Some(Utc::now());
                println!("恢复任务完成: {}", job.id);
            }
            Err(e) => {
                record.status = BackupStatus::Failed;
                record.end_time = Some(Utc::now());
                record.error_message = Some(e.to_string());
                eprintln!("恢复任务失败: {} - {}", job.id, e);
            }
        }
        
        self.restore_records.push(record);
        Ok(record_id)
    }
    
    async fn verify_backup(&self, backup_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        // 检查文件是否存在
        if !tokio::fs::metadata(backup_path).await.is_ok() {
            return Err("备份文件不存在".into());
        }
        
        // 验证备份文件完整性
        let output = tokio::process::Command::new("tar")
            .arg("-tzf")
            .arg(backup_path)
            .output()
            .await?;
        
        if !output.status.success() {
            return Err("备份文件损坏".into());
        }
        
        println!("备份文件验证通过: {}", backup_path);
        Ok(())
    }
    
    async fn perform_restore(&self, job: &RestoreJob, record: &mut RestoreRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 解密（如果需要）
        let backup_path = if job.source_backup.ends_with(".enc") {
            self.decrypt_backup(&job.source_backup).await?
        } else {
            job.source_backup.clone()
        };
        
        match job.restore_type {
            RestoreType::Full => self.full_restore(&backup_path, &job.destination, record).await?,
            RestoreType::Selective => {
                if let Some(files) = &job.files_to_restore {
                    self.selective_restore(&backup_path, &job.destination, files, record).await?;
                }
            }
            RestoreType::PointInTime => {
                if let Some(point_in_time) = job.point_in_time {
                    self.point_in_time_restore(&backup_path, &job.destination, point_in_time, record).await?;
                }
            }
        }
        
        Ok(())
    }
    
    async fn full_restore(&self, backup_path: &str, destination: &str, record: &mut RestoreRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 创建目标目录
        tokio::fs::create_dir_all(destination).await?;
        
        let output = tokio::process::Command::new("tar")
            .arg("-xzf")
            .arg(backup_path)
            .arg("-C")
            .arg(destination)
            .output()
            .await?;
        
        if !output.status.success() {
            return Err(format!("恢复失败: {}", String::from_utf8_lossy(&output.stderr)).into());
        }
        
        // 统计恢复信息
        record.files_restored = self.count_files(destination).await?;
        record.bytes_restored = self.calculate_directory_size(destination).await?;
        
        Ok(())
    }
    
    async fn selective_restore(&self, backup_path: &str, destination: &str, files: &[String], record: &mut RestoreRecord) -> Result<(), Box<dyn std::error::Error>> {
        tokio::fs::create_dir_all(destination).await?;
        
        let mut cmd = tokio::process::Command::new("tar");
        cmd.arg("-xzf").arg(backup_path).arg("-C").arg(destination);
        
        for file in files {
            cmd.arg(file);
        }
        
        let output = cmd.output().await?;
        
        if !output.status.success() {
            return Err(format!("选择性恢复失败: {}", String::from_utf8_lossy(&output.stderr)).into());
        }
        
        record.files_restored = files.len() as u32;
        record.bytes_restored = self.calculate_directory_size(destination).await?;
        
        Ok(())
    }
    
    async fn point_in_time_restore(&self, _backup_path: &str, _destination: &str, _point_in_time: DateTime<Utc>, _record: &mut RestoreRecord) -> Result<(), Box<dyn std::error::Error>> {
        // 实现时间点恢复逻辑
        // 这通常需要结合数据库的事务日志
        println!("时间点恢复功能待实现");
        Ok(())
    }
    
    async fn decrypt_backup(&self, encrypted_path: &str) -> Result<String, Box<dyn std::error::Error>> {
        let decrypted_path = encrypted_path.replace(".enc", "");
        
        let output = tokio::process::Command::new("gpg")
            .arg("--decrypt")
            .arg("--output")
            .arg(&decrypted_path)
            .arg(encrypted_path)
            .output()
            .await?;
        
        if !output.status.success() {
            return Err("解密失败".into());
        }
        
        Ok(decrypted_path)
    }
    
    async fn count_files(&self, directory: &str) -> Result<u32, Box<dyn std::error::Error>> {
        let output = tokio::process::Command::new("find")
            .arg(directory)
            .arg("-type")
            .arg("f")
            .arg("-exec")
            .arg("echo")
            .arg("1")
            .arg(";")
            .output()
            .await?;
        
        let count = String::from_utf8(output.stdout)?
            .lines()
            .count() as u32;
        
        Ok(count)
    }
    
    async fn calculate_directory_size(&self, directory: &str) -> Result<u64, Box<dyn std::error::Error>> {
        let output = tokio::process::Command::new("du")
            .arg("-sb")
            .arg(directory)
            .output()
            .await?;
        
        let size_str = String::from_utf8(output.stdout)?;
        let size = size_str
            .split_whitespace()
            .next()
            .unwrap_or("0")
            .parse::<u64>()?;
        
        Ok(size)
    }
}
```

## 3. 存储后端实现

### 3.1 存储后端接口

```rust
// src/backup/storage_backend.rs
use async_trait::async_trait;

#[async_trait]
pub trait StorageBackend: Send + Sync {
    async fn upload(&self, local_path: &str, remote_path: &str) -> Result<(), Box<dyn std::error::Error>>;
    async fn download(&self, remote_path: &str, local_path: &str) -> Result<(), Box<dyn std::error::Error>>;
    async fn delete(&self, remote_path: &str) -> Result<(), Box<dyn std::error::Error>>;
    async fn list(&self, prefix: &str) -> Result<Vec<String>, Box<dyn std::error::Error>>;
}

// S3存储后端
pub struct S3Backend {
    client: aws_sdk_s3::Client,
    bucket: String,
}

impl S3Backend {
    pub async fn new(bucket: String) -> Result<Self, Box<dyn std::error::Error>> {
        let config = aws_config::load_from_env().await;
        let client = aws_sdk_s3::Client::new(&config);
        
        Ok(S3Backend { client, bucket })
    }
}

#[async_trait]
impl StorageBackend for S3Backend {
    async fn upload(&self, local_path: &str, remote_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        let body = aws_sdk_s3::primitives::ByteStream::from_path(local_path).await?;
        
        self.client
            .put_object()
            .bucket(&self.bucket)
            .key(remote_path)
            .body(body)
            .send()
            .await?;
        
        println!("上传到S3成功: {}", remote_path);
        Ok(())
    }
    
    async fn download(&self, remote_path: &str, local_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client
            .get_object()
            .bucket(&self.bucket)
            .key(remote_path)
            .send()
            .await?;
        
        let data = response.body.collect().await?;
        tokio::fs::write(local_path, data.into_bytes()).await?;
        
        println!("从S3下载成功: {}", local_path);
        Ok(())
    }
    
    async fn delete(&self, remote_path: &str) -> Result<(), Box<dyn std::error::Error>> {
        self.client
            .delete_object()
            .bucket(&self.bucket)
            .key(remote_path)
            .send()
            .await?;
        
        Ok(())
    }
    
    async fn list(&self, prefix: &str) -> Result<Vec<String>, Box<dyn std::error::Error>> {
        let response = self.client
            .list_objects_v2()
            .bucket(&self.bucket)
            .prefix(prefix)
            .send()
            .await?;
        
        let keys = response
            .contents()
            .unwrap_or_default()
            .iter()
            .filter_map(|obj| obj.key().map(|k| k.to_string()))
            .collect();
        
        Ok(keys)
    }
}
```

## 4. 配置文件

### 4.1 备份配置

```yaml
# config/backup.yml
backup:
  storage:
    local:
      path: "/var/backups/iot"
      retention_days: 30
    
    s3:
      bucket: "iot-backups"
      region: "us-west-2"
      retention_days: 90
    
    azure:
      container: "iot-backups"
      retention_days: 90

  jobs:
    - id: "database-full"
      name: "数据库全量备份"
      type: "full"
      source: "/var/lib/postgresql/data"
      schedule: "0 2 * * 0"  # 每周日凌晨2点
      compression: true
      encryption: true
      retention_days: 90
      enabled: true
    
    - id: "database-incremental"
      name: "数据库增量备份"
      type: "incremental"
      source: "/var/lib/postgresql/data"
      schedule: "0 2 * * 1-6"  # 周一到周六凌晨2点
      compression: true
      encryption: true
      retention_days: 30
      enabled: true
    
    - id: "config-backup"
      name: "配置文件备份"
      type: "configuration"
      source: "/opt/iot-system"
      schedule: "0 1 * * *"  # 每天凌晨1点
      compression: true
      encryption: false
      retention_days: 30
      enabled: true

  notifications:
    email:
      enabled: true
      smtp_server: "smtp.example.com"
      recipients: ["admin@example.com"]
    
    slack:
      enabled: true
      webhook_url: "https://hooks.slack.com/services/..."
      channel: "#ops-alerts"
```

## 5. 部署配置

### 5.1 Docker配置

```yaml
# docker-compose.backup.yml
version: '3.8'

services:
  backup-manager:
    build:
      context: .
      dockerfile: docker/Dockerfile.backup
    volumes:
      - /var/lib/postgresql/data:/data/postgresql:ro
      - /opt/iot-system:/data/config:ro
      - backup_storage:/backups
      - ./config/backup.yml:/app/config/backup.yml:ro
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - BACKUP_ENCRYPTION_KEY=${BACKUP_ENCRYPTION_KEY}
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  # 备份验证服务
  backup-verifier:
    build:
      context: .
      dockerfile: docker/Dockerfile.verifier
    volumes:
      - backup_storage:/backups:ro
    environment:
      - VERIFICATION_SCHEDULE=0 4 * * *  # 每天凌晨4点验证
    restart: unless-stopped

volumes:
  backup_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/backups/iot
```

### 5.2 Kubernetes部署

```yaml
# k8s/backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: iot-backup-full
  namespace: iot-system
spec:
  schedule: "0 2 * * 0"  # 每周日凌晨2点
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: iot-system/backup-manager:latest
            command: ["/app/backup-manager", "execute", "database-full"]
            volumeMounts:
            - name: data-volume
              mountPath: /data
              readOnly: true
            - name: backup-volume
              mountPath: /backups
            - name: config-volume
              mountPath: /app/config
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: backup-secrets
                  key: aws-access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: backup-secrets
                  key: aws-secret-access-key
          volumes:
          - name: data-volume
            persistentVolumeClaim:
              claimName: postgres-data-pvc
          - name: backup-volume
            persistentVolumeClaim:
              claimName: backup-storage-pvc
          - name: config-volume
            configMap:
              name: backup-config
          restartPolicy: OnFailure
```

## 6. 监控和告警

### 6.1 备份监控

```rust
// src/backup/monitoring.rs
use prometheus::{Counter, Gauge, Histogram};

pub struct BackupMetrics {
    pub backup_jobs_total: Counter,
    pub backup_jobs_failed: Counter,
    pub backup_duration_seconds: Histogram,
    pub backup_size_bytes: Gauge,
    pub last_backup_timestamp: Gauge,
}

impl BackupMetrics {
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        Ok(BackupMetrics {
            backup_jobs_total: Counter::new("backup_jobs_total", "备份任务总数")?,
            backup_jobs_failed: Counter::new("backup_jobs_failed_total", "失败的备份任务数")?,
            backup_duration_seconds: Histogram::new("backup_duration_seconds", "备份持续时间")?,
            backup_size_bytes: Gauge::new("backup_size_bytes", "备份文件大小")?,
            last_backup_timestamp: Gauge::new("last_backup_timestamp", "最后备份时间戳")?,
        })
    }
    
    pub fn record_backup_completion(&self, duration: f64, size: u64) {
        self.backup_jobs_total.inc();
        self.backup_duration_seconds.observe(duration);
        self.backup_size_bytes.set(size as f64);
        self.last_backup_timestamp.set(chrono::Utc::now().timestamp() as f64);
    }
    
    pub fn record_backup_failure(&self) {
        self.backup_jobs_failed.inc();
    }
}
```

## 7. 使用示例

### 7.1 创建备份任务

```rust
// examples/backup_example.rs
use iot_backup::{BackupManager, BackupJob, BackupType};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let mut backup_manager = BackupManager::new();
    
    // 创建全量备份任务
    let job = BackupJob {
        id: "db-full-backup".to_string(),
        name: "数据库全量备份".to_string(),
        backup_type: BackupType::Full,
        source_path: "/var/lib/postgresql/data".to_string(),
        destination: "/backups".to_string(),
        schedule: "0 2 * * 0".to_string(),
        retention_days: 30,
        compression: true,
        encryption: true,
        enabled: true,
    };
    
    backup_manager.add_job(job)?;
    
    // 执行备份
    let backup_id = backup_manager.execute_backup("db-full-backup").await?;
    println!("备份完成，ID: {}", backup_id);
    
    Ok(())
}
```

这个备份恢复系统提供了完整的数据保护解决方案，支持多种备份类型、存储后端、加密压缩、监控告警等功能，确保IoT系统数据的安全性和可恢复性。
