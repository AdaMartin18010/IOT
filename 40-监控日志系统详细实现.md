# IoT监控日志系统详细实现

## 1. 系统架构

### 1.1 整体架构

```text
数据采集层 → 数据处理层 → 展示告警层
• Metrics收集   • 数据聚合     • Grafana仪表板
• 日志收集      • 实时计算     • AlertManager
• 链路追踪      • 异常检测     • 通知推送
```

### 1.2 技术栈

- **指标**: Prometheus + Node Exporter
- **日志**: ELK Stack (Elasticsearch + Logstash + Kibana)
- **追踪**: Jaeger + OpenTelemetry
- **可视化**: Grafana
- **告警**: AlertManager

## 2. 核心组件实现

### 2.1 指标收集器

```rust
// src/monitoring/metrics_collector.rs
use prometheus::{Counter, Gauge, Histogram, Registry};
use tokio::time::{interval, Duration};
use std::sync::Arc;

pub struct MetricsCollector {
    registry: Registry,
    
    // 系统指标
    cpu_usage: Gauge,
    memory_usage: Gauge,
    disk_usage: Gauge,
    
    // 业务指标
    device_count: Gauge,
    message_rate: Counter,
    error_count: Counter,
    response_time: Histogram,
    
    // IoT特定指标
    protocol_usage: Counter,
    semantic_conversion_rate: Counter,
    gateway_throughput: Histogram,
}

impl MetricsCollector {
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        let registry = Registry::new();
        
        // 创建并注册指标
        let cpu_usage = Gauge::new("system_cpu_usage_percent", "CPU使用率")?;
        let memory_usage = Gauge::new("system_memory_usage_bytes", "内存使用量")?;
        let device_count = Gauge::new("iot_device_count", "设备数量")?;
        let message_rate = Counter::new("iot_message_total", "消息总数")?;
        
        registry.register(Box::new(cpu_usage.clone()))?;
        registry.register(Box::new(memory_usage.clone()))?;
        registry.register(Box::new(device_count.clone()))?;
        registry.register(Box::new(message_rate.clone()))?;
        
        Ok(MetricsCollector {
            registry,
            cpu_usage,
            memory_usage,
            disk_usage: Gauge::new("system_disk_usage_bytes", "磁盘使用量")?,
            device_count,
            message_rate,
            error_count: Counter::new("iot_error_total", "错误总数")?,
            response_time: Histogram::new("iot_response_time_seconds", "响应时间")?,
            protocol_usage: Counter::new("iot_protocol_usage_total", "协议使用")?,
            semantic_conversion_rate: Counter::new("iot_semantic_conversion_total", "语义转换")?,
            gateway_throughput: Histogram::new("iot_gateway_throughput_mbps", "网关吞吐量")?,
        })
    }
    
    pub async fn start_collection(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut interval = interval(Duration::from_secs(15));
        
        loop {
            interval.tick().await;
            self.collect_metrics().await?;
        }
    }
    
    async fn collect_metrics(&self) -> Result<(), Box<dyn std::error::Error>> {
        // 收集系统指标
        self.cpu_usage.set(self.get_cpu_usage().await?);
        self.memory_usage.set(self.get_memory_usage().await? as f64);
        
        // 收集业务指标
        self.device_count.set(self.get_device_count().await? as f64);
        self.message_rate.inc_by(self.get_message_count().await? as f64);
        
        Ok(())
    }
    
    async fn get_cpu_usage(&self) -> Result<f64, Box<dyn std::error::Error>> {
        Ok(45.2) // 示例实现
    }
    
    async fn get_memory_usage(&self) -> Result<u64, Box<dyn std::error::Error>> {
        Ok(1024 * 1024 * 512) // 512MB
    }
    
    async fn get_device_count(&self) -> Result<u32, Box<dyn std::error::Error>> {
        Ok(150)
    }
    
    async fn get_message_count(&self) -> Result<u32, Box<dyn std::error::Error>> {
        Ok(1000)
    }
}
```

### 2.2 日志聚合系统

```rust
// src/monitoring/log_aggregator.rs
use serde::{Serialize, Deserialize};
use tokio::sync::mpsc;
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogLevel {
    Info, Warn, Error, Debug,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogEntry {
    pub timestamp: DateTime<Utc>,
    pub level: LogLevel,
    pub service: String,
    pub component: String,
    pub message: String,
    pub trace_id: Option<String>,
}

pub struct LogAggregator {
    log_receiver: mpsc::Receiver<LogEntry>,
    log_sender: mpsc::Sender<LogEntry>,
    buffer: Vec<LogEntry>,
    batch_size: usize,
}

impl LogAggregator {
    pub fn new(batch_size: usize) -> Self {
        let (log_sender, log_receiver) = mpsc::channel(1000);
        
        LogAggregator {
            log_receiver,
            log_sender,
            buffer: Vec::new(),
            batch_size,
        }
    }
    
    pub async fn start_processing(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        while let Some(log_entry) = self.log_receiver.recv().await {
            self.buffer.push(log_entry);
            
            if self.buffer.len() >= self.batch_size {
                self.flush_logs().await?;
            }
        }
        Ok(())
    }
    
    async fn flush_logs(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        let logs = std::mem::take(&mut self.buffer);
        self.send_to_elasticsearch(logs).await?;
        Ok(())
    }
    
    async fn send_to_elasticsearch(&self, logs: Vec<LogEntry>) -> Result<(), Box<dyn std::error::Error>> {
        // 发送到Elasticsearch的实现
        println!("发送 {} 条日志到Elasticsearch", logs.len());
        Ok(())
    }
}
```

### 2.3 告警引擎

```rust
// src/monitoring/alert_engine.rs
use serde::{Serialize, Deserialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertSeverity {
    Info, Warning, Critical, Fatal,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlertRule {
    pub id: String,
    pub name: String,
    pub metric_name: String,
    pub threshold: f64,
    pub severity: AlertSeverity,
    pub enabled: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Alert {
    pub id: String,
    pub rule_id: String,
    pub severity: AlertSeverity,
    pub title: String,
    pub description: String,
    pub start_time: chrono::DateTime<chrono::Utc>,
}

pub struct AlertEngine {
    rules: HashMap<String, AlertRule>,
    active_alerts: HashMap<String, Alert>,
}

impl AlertEngine {
    pub fn new() -> Self {
        AlertEngine {
            rules: HashMap::new(),
            active_alerts: HashMap::new(),
        }
    }
    
    pub fn add_rule(&mut self, rule: AlertRule) {
        self.rules.insert(rule.id.clone(), rule);
    }
    
    pub async fn evaluate_rules(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        for rule in self.rules.values() {
            if !rule.enabled {
                continue;
            }
            
            let should_fire = self.evaluate_rule(rule).await?;
            if should_fire {
                self.fire_alert(rule).await?;
            }
        }
        Ok(())
    }
    
    async fn evaluate_rule(&self, rule: &AlertRule) -> Result<bool, Box<dyn std::error::Error>> {
        let metric_value = self.get_metric_value(&rule.metric_name).await?;
        Ok(metric_value > rule.threshold)
    }
    
    async fn fire_alert(&mut self, rule: &AlertRule) -> Result<(), Box<dyn std::error::Error>> {
        let alert = Alert {
            id: format!("{}_{}", rule.id, chrono::Utc::now().timestamp()),
            rule_id: rule.id.clone(),
            severity: rule.severity.clone(),
            title: rule.name.clone(),
            description: format!("指标 {} 超过阈值 {}", rule.metric_name, rule.threshold),
            start_time: chrono::Utc::now(),
        };
        
        self.active_alerts.insert(alert.id.clone(), alert.clone());
        self.send_notification(&alert).await?;
        
        Ok(())
    }
    
    async fn get_metric_value(&self, _metric_name: &str) -> Result<f64, Box<dyn std::error::Error>> {
        Ok(75.0) // 示例实现
    }
    
    async fn send_notification(&self, alert: &Alert) -> Result<(), Box<dyn std::error::Error>> {
        println!("发送告警通知: {} - {}", alert.title, alert.description);
        Ok(())
    }
}
```

## 3. 配置文件

### 3.1 Prometheus配置

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'iot-gateway'
    static_configs:
      - targets: ['localhost:8080']
    scrape_interval: 5s
    
  - job_name: 'iot-devices'
    static_configs:
      - targets: ['localhost:8081']
```

### 3.2 Grafana仪表板

```json
{
  "dashboard": {
    "title": "IoT系统监控",
    "panels": [
      {
        "title": "设备数量",
        "type": "stat",
        "targets": [{"expr": "iot_device_count"}]
      },
      {
        "title": "消息处理速率",
        "type": "graph",
        "targets": [{"expr": "rate(iot_message_total[5m])"}]
      }
    ]
  }
}
```

## 4. 部署配置

### 4.1 Docker Compose

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
```

## 5. 使用示例

### 5.1 启动监控系统

```bash
# 启动所有组件
docker-compose -f docker-compose.monitoring.yml up -d

# 访问界面
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin123)
# Kibana: http://localhost:5601
```

### 5.2 集成到IoT系统

```rust
// 在IoT网关中集成监控
use crate::monitoring::{MetricsCollector, LogAggregator};

pub struct IoTGateway {
    metrics_collector: Arc<MetricsCollector>,
    log_sender: mpsc::Sender<LogEntry>,
}

impl IoTGateway {
    pub async fn process_message(&self, message: &Message) -> Result<(), Box<dyn std::error::Error>> {
        // 记录指标
        self.metrics_collector.message_rate.inc();
        
        // 记录日志
        let log_entry = LogEntry {
            timestamp: Utc::now(),
            level: LogLevel::Info,
            service: "iot-gateway".to_string(),
            component: "message-processor".to_string(),
            message: format!("处理消息: {}", message.id),
            trace_id: Some(message.trace_id.clone()),
        };
        self.log_sender.send(log_entry).await?;
        
        Ok(())
    }
}
```

## 6. 性能优化

### 6.1 指标优化

- 使用采样策略减少高频指标收集
- 配置合适的保留策略
- 实现指标聚合减少存储

### 6.2 日志优化

- 实现日志级别过滤
- 使用异步批量处理
- 配置合适的缓冲区大小

### 6.3 告警优化

- 实现告警抑制策略
- 配置适当的评估间隔
- 使用智能降噪减少误报

这个监控日志系统提供了完整的可观测性解决方案，支持指标收集、日志聚合、告警处理和可视化展示。
